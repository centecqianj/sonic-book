msgid ""
msgstr ""
"Project-Id-Version: SONiC入门指南\n"
"POT-Creation-Date: \n"
"PO-Revision-Date: 2023-06-25 20:04-0700\n"
"Last-Translator: r12f <r12f.code@gmail.com>\n"
"Language-Team: English\n"
"Language: en\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

#: src/SUMMARY.md:3
msgid "SONiC入门指南"
msgstr "Getting Started with SONiC"

#: src/SUMMARY.md:4
msgid "安装"
msgstr "Installation"

#: src/SUMMARY.md:5
msgid "虚拟测试环境"
msgstr "Hello world! Virtually."

#: src/SUMMARY.md:6
msgid "常用命令"
msgstr "Command cheatsheet"

#: src/SUMMARY.md:7
msgid "核心组件"
msgstr "Key components"

#: src/SUMMARY.md:8
msgid "Redis数据库"
msgstr "Redis database"

#: src/SUMMARY.md:9
msgid "服务与控制流"
msgstr "Services"

#: src/SUMMARY.md:10
msgid "核心容器"
msgstr "Key containers"

#: src/SUMMARY.md:11
msgid "SAI"
msgstr "SAI"

#: src/SUMMARY.md:12
msgid "开发上手指南"
msgstr "Dev Guide"

#: src/SUMMARY.md:13
msgid "代码仓库"
msgstr "Code Repo"

#: src/SUMMARY.md:14
msgid "编译"
msgstr "Compilation"

#: src/SUMMARY.md:15
msgid "调试"
msgstr "Debugging"

#: src/SUMMARY.md:16
msgid "通信机制"
msgstr "Communications"

#: src/SUMMARY.md:17
msgid "与内核的通信"
msgstr "Communication with kernel"

#: src/SUMMARY.md:18
msgid "命令行调用"
msgstr "Command line calls"

#: src/SUMMARY.md:19
msgid "Netlink"
msgstr "Netlink"

#: src/SUMMARY.md:20
msgid "基于Redis的通信"
msgstr "Redis-based communications"

#: src/SUMMARY.md:21
msgid "Redis封装"
msgstr "Redis wrappers"

#: src/SUMMARY.md:22
msgid "通信层 - PubSub"
msgstr "Redis messaging layer"

#: src/SUMMARY.md:23
msgid "服务层 - Orch"
msgstr "Service layer - Orch"

#: src/SUMMARY.md:24
msgid "事件分发和错误处理"
msgstr "Event dispatch and error handling"

#: src/SUMMARY.md:25
msgid "工作流"
msgstr "Workflows"

#: src/SUMMARY.md:26
msgid "Syncd-SAI工作流"
msgstr "Syncd-SAI workflows"

#: src/SUMMARY.md:27
msgid "BGP工作流"
msgstr "BGP workflows"

#: src/SUMMARY.md:28
msgid "启动流程"
msgstr "Boot"

#: src/SUMMARY.md:29
msgid "正常启动"
msgstr "Cold boot"

#: src/SUMMARY.md:30
msgid "快速启动"
msgstr "Fast boot"

#: src/SUMMARY.md:31
msgid "热启动"
msgstr "Warm boot"

#: src/1-intro.md:1
msgid "# SONiC入门指南"
msgstr "# SONiC入门指南"

#: src/1-intro.md:3
msgid "## 为什么要做SONiC"
msgstr "## 为什么要做SONiC"

#: src/1-intro.md:5
msgid ""
"我们知道交换机内部都有一套可大可小的操作系统，用于配置和查看交换机的状态。但"
"是，从1986年第一台交换机面世开始，虽然各个厂商都在进行着相关的开发，到现在为"
"止种类也相当的多，但是依然存在一些问题，比如："
msgstr ""
"我们知道交换机内部都有一套可大可小的操作系统，用于配置和查看交换机的状态。但"
"是，从1986年第一台交换机面世开始，虽然各个厂商都在进行着相关的开发，到现在为"
"止种类也相当的多，但是依然存在一些问题，比如："

#: src/1-intro.md:7
msgid ""
"1. 生态封闭，不开源，主要是为了支持自家的硬件，无法很好的兼容其他厂商的设备\n"
"2. 支持的场景很有限，难以使用同一套系统去支撑大规模的数据中心中复杂多变的场"
"景\n"
"3. 升级可能会导致网络中断，难以实现无缝升级，这对于云提供商来说有时候是致命"
"的\n"
"4. 设备功能升级缓慢，难以很好的支持快速的产品迭代"
msgstr ""
"1. 生态封闭，不开源，主要是为了支持自家的硬件，无法很好的兼容其他厂商的设备\n"
"2. 支持的场景很有限，难以使用同一套系统去支撑大规模的数据中心中复杂多变的场"
"景\n"
"3. 升级可能会导致网络中断，难以实现无缝升级，这对于云提供商来说有时候是致命"
"的\n"
"4. 设备功能升级缓慢，难以很好的支持快速的产品迭代"

#: src/1-intro.md:12
msgid ""
"所以，微软在2016年发起了开源项目SONiC，希望能够通过开源的方式，让SONiC能够成"
"为一个通用的网络操作系统，从而解决上面的问题。而且，由于微软在Azure中大范围的"
"使用SONiC，也保证了SONiC的实现确实能够承受大规模的生产环境的考验，这也是SONiC"
"的一个优势。"
msgstr ""
"所以，微软在2016年发起了开源项目SONiC，希望能够通过开源的方式，让SONiC能够成"
"为一个通用的网络操作系统，从而解决上面的问题。而且，由于微软在Azure中大范围的"
"使用SONiC，也保证了SONiC的实现确实能够承受大规模的生产环境的考验，这也是SONiC"
"的一个优势。"

#: src/1-intro.md:14
msgid "## 主体架构"
msgstr "## 主体架构"

#: src/1-intro.md:16
msgid ""
"SONiC是微软开发的基于debian的开源的网络操作系统，它的设计核心思想有三个："
msgstr ""
"SONiC是微软开发的基于debian的开源的网络操作系统，它的设计核心思想有三个："

#: src/1-intro.md:18
msgid ""
"1. **硬件和软件解耦**：通过SAI（Switch Abstraction Interface）将硬件的操作抽"
"象出来，从而使得SONiC能够支持多种硬件平台。这一层抽象层由SONiC定义，由各个厂"
"商来实现。\n"
"2. **使用docker容器将软件微服务化**：SONiC上的主要功能都被拆分成了一个个的"
"docker容器，和传统的网络操作系统不同，升级系统可以只对其中的某个容器进行升"
"级，而不需要整体升级和重启，这样就可以很方便的进行升级和维护，支持快速的开发"
"和迭代。\n"
"3. **使用redis作为中心数据库对服务进行解耦**：绝大部分服务的配置和状态最后都"
"被存储到中心的redis数据库中，这样不仅使得所有的服务可以很轻松的进行协作（数据"
"存储和pubsub），也可以让我们很方便的在上面开发工具，使用统一的方法对各个服务"
"进行操作和查询，而不用担心状态丢失和协议兼容问题，最后还可以很方便的进行状态"
"的备份和恢复。"
msgstr ""
"1. **硬件和软件解耦**：通过SAI（Switch Abstraction Interface）将硬件的操作抽"
"象出来，从而使得SONiC能够支持多种硬件平台。这一层抽象层由SONiC定义，由各个厂"
"商来实现。\n"
"2. **使用docker容器将软件微服务化**：SONiC上的主要功能都被拆分成了一个个的"
"docker容器，和传统的网络操作系统不同，升级系统可以只对其中的某个容器进行升"
"级，而不需要整体升级和重启，这样就可以很方便的进行升级和维护，支持快速的开发"
"和迭代。\n"
"3. **使用redis作为中心数据库对服务进行解耦**：绝大部分服务的配置和状态最后都"
"被存储到中心的redis数据库中，这样不仅使得所有的服务可以很轻松的进行协作（数据"
"存储和pubsub），也可以让我们很方便的在上面开发工具，使用统一的方法对各个服务"
"进行操作和查询，而不用担心状态丢失和协议兼容问题，最后还可以很方便的进行状态"
"的备份和恢复。"

#: src/1-intro.md:22
msgid ""
"这让SONiC拥有了非常开放的生态（[Community][SONiCLanding]，[Workgroups]"
"[SONiCWG]，[Devices][SONiCDevices]），总体而言，SONiC的架构如下图所示："
msgstr ""
"这让SONiC拥有了非常开放的生态（[Community][SONiCLanding]，[Workgroups]"
"[SONiCWG]，[Devices][SONiCDevices]），总体而言，SONiC的架构如下图所示："

#: src/1-intro.md:26 src/2-components.md:17
msgid "_(Source: [SONiC Wiki - Architecture][SONiCArch])_"
msgstr "_(Source: [SONiC Wiki - Architecture][SONiCArch])_"

#: src/1-intro.md:28
msgid ""
"当然，这样的设计也有一些缺点，比如：对磁盘的占用会变大，不过，现在一点点存储"
"空间并不是什么很大的问题，而且这个问题也都可以通过一些方法来解决。"
msgstr ""
"当然，这样的设计也有一些缺点，比如：对磁盘的占用会变大，不过，现在一点点存储"
"空间并不是什么很大的问题，而且这个问题也都可以通过一些方法来解决。"

#: src/1-intro.md:30
msgid "## 发展方向"
msgstr "## 发展方向"

#: src/1-intro.md:32
msgid ""
"虽然交换机已经发展很多很多年了，但是随着现在云的发展，对网络的要求也越来越"
"高，不管是直观的需求，比如更大的带宽，更大的容量，还是最新的研究，比如，带内"
"计算，端网融合等等，都对交换机的发展提出了更高的要求和挑战，也促使着各大厂商"
"和研究机构不断的进行创新。SONiC也一样，随着时间的发展，需求一点没有减少。"
msgstr ""
"虽然交换机已经发展很多很多年了，但是随着现在云的发展，对网络的要求也越来越"
"高，不管是直观的需求，比如更大的带宽，更大的容量，还是最新的研究，比如，带内"
"计算，端网融合等等，都对交换机的发展提出了更高的要求和挑战，也促使着各大厂商"
"和研究机构不断的进行创新。SONiC也一样，随着时间的发展，需求一点没有减少。"

#: src/1-intro.md:34
msgid ""
"关于SONiC的发展方向，我们可以在它的[Roadmap][SONiCPlanning]中看到。如果大家对"
"最新的动态感兴趣，也可以关注它的Workshop，比如，最近的[OCP Global Summit "
"2022 - SONiC Workshop][SONiCWorkshop]。这里就不展开了。"
msgstr ""
"关于SONiC的发展方向，我们可以在它的[Roadmap][SONiCPlanning]中看到。如果大家对"
"最新的动态感兴趣，也可以关注它的Workshop，比如，最近的[OCP Global Summit "
"2022 - SONiC Workshop][SONiCWorkshop]。这里就不展开了。"

#: src/1-intro.md:36
msgid "## 感谢"
msgstr "## 感谢"

#: src/1-intro.md:38
msgid "感谢以下朋友的帮助和贡献，没有你们也就没有这本入门指南！"
msgstr "感谢以下朋友的帮助和贡献，没有你们也就没有这本入门指南！"

#: src/1-intro.md:40
msgid "[@bingwang-ms](https://github.com/bingwang-ms)"
msgstr "[@bingwang-ms](https://github.com/bingwang-ms)"

#: src/1-intro.md:42
msgid "# License"
msgstr "# License"

#: src/1-intro.md:44
msgid ""
"本书使用 [署名-非商业性使用-相同方式共享（CC BY-NC-SA）4.0 许可协议](https://"
"creativecommons.org/licenses/by-nc-sa/4.0/)。"
msgstr ""
"本书使用 [署名-非商业性使用-相同方式共享（CC BY-NC-SA）4.0 许可协议](https://"
"creativecommons.org/licenses/by-nc-sa/4.0/)。"

#: src/1-intro.md:46 src/1-1-install.md:164
#: src/1-2-hello-world-virtually.md:189 src/1-3-command-cheatsheet.md:184
#: src/2-components.md:19 src/2-1-database.md:74 src/2-2-services-intro.md:74
#: src/2-3-key-containers.md:179 src/2-4-sai-intro.md:164
#: src/3-1-code-repos.md:131 src/3-2-compile.md:202 src/4-communications.md:12
#: src/4-1-1-exec.md:36 src/4-1-2-netlink.md:70 src/4-2-1-redis-wrappers.md:33
#: src/4-2-2-redis-messaging-layer.md:318 src/4-2-3-orch-layer.md:34
#: src/4-3-event-polling-and-error-handling.md:119
#: src/5-1-syncd-sai-workflow.md:803 src/5-2-bgp-workflow.md:7
msgid "# 参考资料"
msgstr "# 参考资料"

#: src/1-intro.md:48
msgid ""
"1. [SONiC Wiki - Architecture][SONiCArch]\n"
"2. [SONiC Wiki - Roadmap Planning][SONiCPlanning]\n"
"3. [SONiC Landing Page][SONiCLanding]\n"
"4. [SONiC Workgroups][SONiCWG]\n"
"5. [SONiC Supported Devices and Platforms][SONiCDevices]\n"
"6. [SONiC User Manual][SONiCManual]\n"
"7. [OCP Global Summit 2022 - SONiC Workshop][SONiCWorkshop]"
msgstr ""
"1. [SONiC Wiki - Architecture][SONiCArch]\n"
"2. [SONiC Wiki - Roadmap Planning][SONiCPlanning]\n"
"3. [SONiC Landing Page][SONiCLanding]\n"
"4. [SONiC Workgroups][SONiCWG]\n"
"5. [SONiC Supported Devices and Platforms][SONiCDevices]\n"
"6. [SONiC User Manual][SONiCManual]\n"
"7. [OCP Global Summit 2022 - SONiC Workshop][SONiCWorkshop]"

#: src/1-1-install.md:1
msgid "# 安装"
msgstr "# 安装"

#: src/1-1-install.md:3
msgid ""
"如果你自己就拥有一台交换机，或者想购买一台交换机，在上面安装SONiC，那么请认真"
"阅读这一小节，否则可以自行跳过。:D"
msgstr ""
"如果你自己就拥有一台交换机，或者想购买一台交换机，在上面安装SONiC，那么请认真"
"阅读这一小节，否则可以自行跳过。:D"

#: src/1-1-install.md:5
msgid "## 交换机选择和SONiC安装"
msgstr "## 交换机选择和SONiC安装"

#: src/1-1-install.md:7
msgid ""
"首先，请确认你的交换机是否支持SONiC，SONiC目前支持的交换机型号可以在[这里]"
"[SONiCDevices]找到，如果你的交换机型号不在列表中，那么就需要联系厂商，看看是"
"否有支持SONiC的计划。有很多交换机是不支持SONiC的，比如："
msgstr ""
"首先，请确认你的交换机是否支持SONiC，SONiC目前支持的交换机型号可以在[这里]"
"[SONiCDevices]找到，如果你的交换机型号不在列表中，那么就需要联系厂商，看看是"
"否有支持SONiC的计划。有很多交换机是不支持SONiC的，比如："

#: src/1-1-install.md:9
msgid ""
"1. 普通针对家用的交换机，这些交换机的硬件配置都比较低（即便支持的带宽很高，比"
"如[MikroTik CRS504-4XQ-IN][MikroTik100G]，虽然它支持100GbE网络，但是它只有"
"16MB的Flash存储和64MB的RAM，所以基本只能跑它自己的RouterOS了）。\n"
"2. 有些虽然是数据中心用的交换机，但是可能由于型号老旧，厂商并没有计划支持"
"SONiC。"
msgstr ""
"1. 普通针对家用的交换机，这些交换机的硬件配置都比较低（即便支持的带宽很高，比"
"如[MikroTik CRS504-4XQ-IN][MikroTik100G]，虽然它支持100GbE网络，但是它只有"
"16MB的Flash存储和64MB的RAM，所以基本只能跑它自己的RouterOS了）。\n"
"2. 有些虽然是数据中心用的交换机，但是可能由于型号老旧，厂商并没有计划支持"
"SONiC。"

#: src/1-1-install.md:12
msgid ""
"对于安装过程，由于每一家厂商的交换机设计不同，其底层接口各有差别，所以，其安"
"装方法也都有所差别，这些差别主要集中在两个地方："
msgstr ""
"对于安装过程，由于每一家厂商的交换机设计不同，其底层接口各有差别，所以，其安"
"装方法也都有所差别，这些差别主要集中在两个地方："

#: src/1-1-install.md:14
msgid ""
"1. 每个厂商都会有自己的[SONiC Build][SONiCDevices]，还有的厂商会在SONiC的基础"
"之上进行扩展开发，为自己的交换机支持更多的功能，比如：[Dell Enterprise SONiC]"
"[DellSonic]，[EdgeCore Enterprise SONiC][EdgeCoreSONiC]，所以需要根据自己的交"
"换机选择对应的版本。\n"
"2. 每个厂商的交换机也会支持不同的安装方式，有一些是直接使用USB对ROM进行"
"Flash，有一些是通过ONIE进行安装，这也需要根据自己的交换机来进行配置。"
msgstr ""
"1. 每个厂商都会有自己的[SONiC Build][SONiCDevices]，还有的厂商会在SONiC的基础"
"之上进行扩展开发，为自己的交换机支持更多的功能，比如：[Dell Enterprise SONiC]"
"[DellSonic]，[EdgeCore Enterprise SONiC][EdgeCoreSONiC]，所以需要根据自己的交"
"换机选择对应的版本。\n"
"2. 每个厂商的交换机也会支持不同的安装方式，有一些是直接使用USB对ROM进行"
"Flash，有一些是通过ONIE进行安装，这也需要根据自己的交换机来进行配置。"

#: src/1-1-install.md:17
msgid ""
"所以，虽然安装方法各有差别，但是总体而言，安装的步骤都是差不多的。请联系自己"
"的厂商，获取对应的安装文档，然后按照文档进行安装即可。"
msgstr ""
"所以，虽然安装方法各有差别，但是总体而言，安装的步骤都是差不多的。请联系自己"
"的厂商，获取对应的安装文档，然后按照文档进行安装即可。"

#: src/1-1-install.md:19
msgid "## 配置交换机"
msgstr "## 配置交换机"

#: src/1-1-install.md:21
msgid ""
"安装好之后，我们需要进行一些基础设置，部分设置是通用的，我们在这里简单总结一"
"下。"
msgstr ""
"安装好之后，我们需要进行一些基础设置，部分设置是通用的，我们在这里简单总结一"
"下。"

#: src/1-1-install.md:23
msgid "### 设置admin密码"
msgstr "### 设置admin密码"

#: src/1-1-install.md:25
msgid "默认SONiC的账号密码是admin:YourPaSsWoRd，使用默认密码显然不安全："
msgstr "默认SONiC的账号密码是admin:YourPaSsWoRd，使用默认密码显然不安全："

#: src/1-1-install.md:27
msgid ""
"```bash\n"
"sudo passwd admin\n"
"```"
msgstr ""
"```bash\n"
"sudo passwd admin\n"
"```"

#: src/1-1-install.md:31
msgid "### 设置风扇转速"
msgstr "### 设置风扇转速"

#: src/1-1-install.md:33
msgid ""
"数据中心用的交换机风扇声音都特别的大！比如，我用的交换机是Arista 7050QX-32S，"
"上面有4个风扇，最高能到每分钟17000转，放在车库中，高频的啸叫即便是在二楼隔着3"
"面墙还是能听得到，所以如果你是在家使用的话，建议对其进行一些设置，将转速调"
"低。"
msgstr ""
"数据中心用的交换机风扇声音都特别的大！比如，我用的交换机是Arista 7050QX-32S，"
"上面有4个风扇，最高能到每分钟17000转，放在车库中，高频的啸叫即便是在二楼隔着3"
"面墙还是能听得到，所以如果你是在家使用的话，建议对其进行一些设置，将转速调"
"低。"

#: src/1-1-install.md:35
msgid ""
"可惜，[由于SONiC并没有cli对风扇转速的规则进行控制][SONiCThermal]，所以我们需"
"要通过手动修改pmon容器中的配置文件的方式来进行设置。"
msgstr ""
"可惜，[由于SONiC并没有cli对风扇转速的规则进行控制][SONiCThermal]，所以我们需"
"要通过手动修改pmon容器中的配置文件的方式来进行设置。"

#: src/1-1-install.md:37
msgid ""
"```bash\n"
"# Enter pmon container\n"
"sudo docker exec -it pmon bash\n"
"\n"
"# Use pwmconfig to detect all pwm fans and create configuration file. The "
"configuration file will be created at /etc/fancontrol.\n"
"pwmconfig\n"
"\n"
"# Start fancontrol and make sure it works. If it doesn't work, you can run "
"fancontrol directly to see what's wrong.\n"
"VERBOSE=1 /etc/init.d/fancontrol start\n"
"VERBOSE=1 /etc/init.d/fancontrol status\n"
"\n"
"# Exit pmon container\n"
"exit\n"
"\n"
"# Copy the configuration file from the container to the host, so that the "
"configuration will not be lost after reboot.\n"
"# This command needs to know what is the model of your switch, for example, "
"the command I need to run here is as follows. If your switch model is "
"different, please modify it yourself.\n"
"sudo docker cp pmon:/etc/fancontrol /usr/share/sonic/device/x86_64-"
"arista_7050_qx32s/fancontrol\n"
"```"
msgstr ""
"```bash\n"
"# Enter pmon container\n"
"sudo docker exec -it pmon bash\n"
"\n"
"# Use pwmconfig to detect all pwm fans and create configuration file. The "
"configuration file will be created at /etc/fancontrol.\n"
"pwmconfig\n"
"\n"
"# Start fancontrol and make sure it works. If it doesn't work, you can run "
"fancontrol directly to see what's wrong.\n"
"VERBOSE=1 /etc/init.d/fancontrol start\n"
"VERBOSE=1 /etc/init.d/fancontrol status\n"
"\n"
"# Exit pmon container\n"
"exit\n"
"\n"
"# Copy the configuration file from the container to the host, so that the "
"configuration will not be lost after reboot.\n"
"# This command needs to know what is the model of your switch, for example, "
"the command I need to run here is as follows. If your switch model is "
"different, please modify it yourself.\n"
"sudo docker cp pmon:/etc/fancontrol /usr/share/sonic/device/x86_64-"
"arista_7050_qx32s/fancontrol\n"
"```"

#: src/1-1-install.md:56
msgid "### 设置交换机Management Port IP"
msgstr "### 设置交换机Management Port IP"

#: src/1-1-install.md:58
msgid ""
"一般的数据中心用的交换机都提供了Serial Console连接的方式，但是其速度实在是太"
"慢了，所以我们在安装完成之后，都会尽快的把Management Port给设置好，然后通过"
"SSH的方式来进行管理。"
msgstr ""
"一般的数据中心用的交换机都提供了Serial Console连接的方式，但是其速度实在是太"
"慢了，所以我们在安装完成之后，都会尽快的把Management Port给设置好，然后通过"
"SSH的方式来进行管理。"

#: src/1-1-install.md:60
msgid ""
"一般来说，management port的设备名是eth0，所以我们可以通过SONiC的配置命令来进"
"行设置："
msgstr ""
"一般来说，management port的设备名是eth0，所以我们可以通过SONiC的配置命令来进"
"行设置："

#: src/1-1-install.md:62
msgid ""
"```bash\n"
"# sudo config interface ip add eth0 <ip-cidr> <gateway>\n"
"# IPv4\n"
"sudo config interface ip add eth0 192.168.1.2/24 192.168.1.1\n"
"\n"
"# IPv6\n"
"sudo config interface ip add eth0 2001::8/64 2001::1\n"
"```"
msgstr ""
"```bash\n"
"# sudo config interface ip add eth0 <ip-cidr> <gateway>\n"
"# IPv4\n"
"sudo config interface ip add eth0 192.168.1.2/24 192.168.1.1\n"
"\n"
"# IPv6\n"
"sudo config interface ip add eth0 2001::8/64 2001::1\n"
"```"

#: src/1-1-install.md:71
msgid "### 创建网络配置"
msgstr "### 创建网络配置"

#: src/1-1-install.md:73
msgid ""
"新安装完的SONiC交换机会有一个默认的网络配置，这个配置有很多问题，比如对于"
"10.0.0.0的IP的使用，如下："
msgstr ""
"新安装完的SONiC交换机会有一个默认的网络配置，这个配置有很多问题，比如对于"
"10.0.0.0的IP的使用，如下："

#: src/1-1-install.md:75 src/1-2-hello-world-virtually.md:120
msgid ""
"```bash\n"
"admin@sonic:~$ show ip interfaces\n"
"Interface    Master    IPv4 address/mask    Admin/Oper    BGP Neighbor    "
"Neighbor IP\n"
"-----------  --------  -------------------  ------------  --------------  "
"-------------\n"
"Ethernet0              10.0.0.0/31          up/up         ARISTA01T2      "
"10.0.0.1\n"
"Ethernet4              10.0.0.2/31          up/up         ARISTA02T2      "
"10.0.0.3\n"
"Ethernet8              10.0.0.4/31          up/up         ARISTA03T2      "
"10.0.0.5\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ show ip interfaces\n"
"Interface    Master    IPv4 address/mask    Admin/Oper    BGP Neighbor    "
"Neighbor IP\n"
"-----------  --------  -------------------  ------------  --------------  "
"-------------\n"
"Ethernet0              10.0.0.0/31          up/up         ARISTA01T2      "
"10.0.0.1\n"
"Ethernet4              10.0.0.2/31          up/up         ARISTA02T2      "
"10.0.0.3\n"
"Ethernet8              10.0.0.4/31          up/up         ARISTA03T2      "
"10.0.0.5\n"
"```"

#: src/1-1-install.md:84
msgid ""
"所以我们需要创建一个新的网络配置，然后将我们使用的Port都放入到这个网络配置"
"中。这里简单的方法就是创建一个VLAN，使用VLAN Routing："
msgstr ""
"所以我们需要创建一个新的网络配置，然后将我们使用的Port都放入到这个网络配置"
"中。这里简单的方法就是创建一个VLAN，使用VLAN Routing："

#: src/1-1-install.md:86
msgid ""
"```bash\n"
"# Create untagged vlan\n"
"sudo config vlan add 2\n"
"\n"
"# Add IP to vlan\n"
"sudo config interface ip add Vlan2 10.2.0.0/24\n"
"\n"
"# Remove all default IP settings\n"
"show ip interfaces | tail -n +3 | grep Ethernet | awk '{print \"sudo config "
"interface ip remove\", $1, $2}' > oobe.sh; chmod +x oobe.sh; ./oobe.sh\n"
"\n"
"# Add all ports to the new vlan\n"
"show interfaces status | tail -n +3 | grep Ethernet | awk '{print \"sudo "
"config vlan member add -u 2\", $1}' > oobe.sh; chmod +x oobe.sh; ./oobe.sh\n"
"\n"
"# Enable proxy arp, so switch can respond to arp requests from hosts\n"
"sudo config vlan proxy_arp 2 enabled\n"
"\n"
"# Save config, so it will be persistent after reboot\n"
"sudo config save -y\n"
"```"
msgstr ""
"```bash\n"
"# Create untagged vlan\n"
"sudo config vlan add 2\n"
"\n"
"# Add IP to vlan\n"
"sudo config interface ip add Vlan2 10.2.0.0/24\n"
"\n"
"# Remove all default IP settings\n"
"show ip interfaces | tail -n +3 | grep Ethernet | awk '{print \"sudo config "
"interface ip remove\", $1, $2}' > oobe.sh; chmod +x oobe.sh; ./oobe.sh\n"
"\n"
"# Add all ports to the new vlan\n"
"show interfaces status | tail -n +3 | grep Ethernet | awk '{print \"sudo "
"config vlan member add -u 2\", $1}' > oobe.sh; chmod +x oobe.sh; ./oobe.sh\n"
"\n"
"# Enable proxy arp, so switch can respond to arp requests from hosts\n"
"sudo config vlan proxy_arp 2 enabled\n"
"\n"
"# Save config, so it will be persistent after reboot\n"
"sudo config save -y\n"
"```"

#: src/1-1-install.md:106
msgid "这样就完成了，我们可以通过show vlan brief来查看一下："
msgstr "这样就完成了，我们可以通过show vlan brief来查看一下："

#: src/1-1-install.md:108
msgid ""
"```\n"
"admin@sonic:~$ show vlan brief\n"
"+-----------+--------------+-------------+----------------+-------------"
"+-----------------------+\n"
"|   VLAN ID | IP Address   | Ports       | Port Tagging   | Proxy ARP   | "
"DHCP Helper Address   |\n"
"+===========+==============+=============+================+=============+=======================+\n"
"|         2 | 10.2.0.0/24  | Ethernet0   | untagged       | enabled     "
"|                       |\n"
"...\n"
"|           |              | Ethernet124 | untagged       |             "
"|                       |\n"
"+-----------+--------------+-------------+----------------+-------------"
"+-----------------------+\n"
"```"
msgstr ""
"```\n"
"admin@sonic:~$ show vlan brief\n"
"+-----------+--------------+-------------+----------------+-------------"
"+-----------------------+\n"
"|   VLAN ID | IP Address   | Ports       | Port Tagging   | Proxy ARP   | "
"DHCP Helper Address   |\n"
"+===========+==============+=============+================+=============+=======================+\n"
"|         2 | 10.2.0.0/24  | Ethernet0   | untagged       | enabled     "
"|                       |\n"
"...\n"
"|           |              | Ethernet124 | untagged       |             "
"|                       |\n"
"+-----------+--------------+-------------+----------------+-------------"
"+-----------------------+\n"
"```"

#: src/1-1-install.md:119
msgid "### 配置主机"
msgstr "### 配置主机"

#: src/1-1-install.md:121
msgid ""
"如果你家里只有一台主机使用多网口连接交换机进行测试，那么我们还需要在主机上进"
"行一些配置，以保证流量会通过网卡，流经交换机，否则，请跳过这一步。"
msgstr ""
"如果你家里只有一台主机使用多网口连接交换机进行测试，那么我们还需要在主机上进"
"行一些配置，以保证流量会通过网卡，流经交换机，否则，请跳过这一步。"

#: src/1-1-install.md:123
msgid ""
"这里网上的攻略很多，比如使用iptables中的DNAT和SNAT创建一个虚拟地址，但是过程"
"非常繁琐，经过一些实验，我发现最简单的办法就是将其中一个网口移动到一个新的网"
"络命名空间中，就可以了，即便使用的是同一个网段的IP，也不会有问题。"
msgstr ""
"这里网上的攻略很多，比如使用iptables中的DNAT和SNAT创建一个虚拟地址，但是过程"
"非常繁琐，经过一些实验，我发现最简单的办法就是将其中一个网口移动到一个新的网"
"络命名空间中，就可以了，即便使用的是同一个网段的IP，也不会有问题。"

#: src/1-1-install.md:125
msgid ""
"比如，我家使用的是Netronome Agilio CX 2x40GbE，它会创建两个interface："
"`enp66s0np0`和`enp66s0np1`，我们这里可以将`enp66s0np1`移动到一个新的网络命名"
"空间中，再配置好ip地址就可以了："
msgstr ""
"比如，我家使用的是Netronome Agilio CX 2x40GbE，它会创建两个interface："
"`enp66s0np0`和`enp66s0np1`，我们这里可以将`enp66s0np1`移动到一个新的网络命名"
"空间中，再配置好ip地址就可以了："

#: src/1-1-install.md:127
msgid ""
"```bash\n"
"# Create a new network namespace\n"
"sudo ip netns add toy-ns-1\n"
"\n"
"# Move the interface to the new namespace\n"
"sudo ip link set enp66s0np1 netns toy-ns-1\n"
"\n"
"# Setting up IP and default routes\n"
"sudo ip netns exec toy-ns-1 ip addr add 10.2.0.11/24 dev enp66s0np1\n"
"sudo ip netns exec toy-ns-1 ip link set enp66s0np1 up\n"
"sudo ip netns exec toy-ns-1 ip route add default via 10.2.0.1\n"
"```"
msgstr ""
"```bash\n"
"# Create a new network namespace\n"
"sudo ip netns add toy-ns-1\n"
"\n"
"# Move the interface to the new namespace\n"
"sudo ip link set enp66s0np1 netns toy-ns-1\n"
"\n"
"# Setting up IP and default routes\n"
"sudo ip netns exec toy-ns-1 ip addr add 10.2.0.11/24 dev enp66s0np1\n"
"sudo ip netns exec toy-ns-1 ip link set enp66s0np1 up\n"
"sudo ip netns exec toy-ns-1 ip route add default via 10.2.0.1\n"
"```"

#: src/1-1-install.md:140
msgid "这样就可以了，我们可以通过iperf来测试一下，并在交换机上进行确认："
msgstr "这样就可以了，我们可以通过iperf来测试一下，并在交换机上进行确认："

#: src/1-1-install.md:142
msgid ""
"```bash\n"
"# On the host (enp66s0np0 has ip 10.2.0.10 assigned)\n"
"$ iperf -s --bind 10.2.0.10\n"
"\n"
"# Test within the new network namespace\n"
"$ sudo ip netns exec toy-ns-1 iperf -c 10.2.0.10 -i 1 -P 16\n"
"------------------------------------------------------------\n"
"Client connecting to 10.2.0.10, TCP port 5001\n"
"TCP window size: 85.0 KByte (default)\n"
"------------------------------------------------------------\n"
"...\n"
"[SUM] 0.0000-10.0301 sec  30.7 GBytes  26.3 Gbits/sec\n"
"[ CT] final connect times (min/avg/max/stdev) = 0.288/0.465/0.647/0.095 ms "
"(tot/err) = 16/0\n"
"\n"
"# Confirm on switch\n"
"admin@sonic:~$ show interfaces counters\n"
"      IFACE    STATE       RX_OK        RX_BPS    RX_UTIL    RX_ERR    "
"RX_DRP    RX_OVR       TX_OK        TX_BPS    TX_UTIL    TX_ERR    TX_DRP    "
"TX_OVR\n"
"-----------  -------  ----------  ------------  ---------  --------  "
"--------  --------  ----------  ------------  ---------  --------  --------  "
"--------\n"
"  Ethernet4        U   2,580,140  6190.34 KB/s      0.12%         0     "
"3,783         0  51,263,535  2086.64 MB/s     41.73%         0         "
"0         0\n"
" Ethernet12        U  51,261,888  2086.79 MB/s     41.74%         0         "
"1         0   2,580,317  6191.00 KB/s      0.12%         0         0         "
"0\n"
"```"
msgstr ""
"```bash\n"
"# On the host (enp66s0np0 has ip 10.2.0.10 assigned)\n"
"$ iperf -s --bind 10.2.0.10\n"
"\n"
"# Test within the new network namespace\n"
"$ sudo ip netns exec toy-ns-1 iperf -c 10.2.0.10 -i 1 -P 16\n"
"------------------------------------------------------------\n"
"Client connecting to 10.2.0.10, TCP port 5001\n"
"TCP window size: 85.0 KByte (default)\n"
"------------------------------------------------------------\n"
"...\n"
"[SUM] 0.0000-10.0301 sec  30.7 GBytes  26.3 Gbits/sec\n"
"[ CT] final connect times (min/avg/max/stdev) = 0.288/0.465/0.647/0.095 ms "
"(tot/err) = 16/0\n"
"\n"
"# Confirm on switch\n"
"admin@sonic:~$ show interfaces counters\n"
"      IFACE    STATE       RX_OK        RX_BPS    RX_UTIL    RX_ERR    "
"RX_DRP    RX_OVR       TX_OK        TX_BPS    TX_UTIL    TX_ERR    TX_DRP    "
"TX_OVR\n"
"-----------  -------  ----------  ------------  ---------  --------  "
"--------  --------  ----------  ------------  ---------  --------  --------  "
"--------\n"
"  Ethernet4        U   2,580,140  6190.34 KB/s      0.12%         0     "
"3,783         0  51,263,535  2086.64 MB/s     41.73%         0         "
"0         0\n"
" Ethernet12        U  51,261,888  2086.79 MB/s     41.74%         0         "
"1         0   2,580,317  6191.00 KB/s      0.12%         0         0         "
"0\n"
"```"

#: src/1-1-install.md:166
msgid ""
"1. [SONiC Supported Devices and Platforms][SONiCDevices]\n"
"2. [SONiC Thermal Control Design][SONiCThermal]\n"
"3. [Dell Enterprise SONiC Distribution][DellSONiC]\n"
"4. [Edgecore Enterprise SONiC  Distribution][EdgeCoreSONiC]\n"
"5. [Mikrotik CRS504-4XQ-IN][MikroTik100G]"
msgstr ""
"1. [SONiC Supported Devices and Platforms][SONiCDevices]\n"
"2. [SONiC Thermal Control Design][SONiCThermal]\n"
"3. [Dell Enterprise SONiC Distribution][DellSONiC]\n"
"4. [Edgecore Enterprise SONiC  Distribution][EdgeCoreSONiC]\n"
"5. [Mikrotik CRS504-4XQ-IN][MikroTik100G]"

#: src/1-2-hello-world-virtually.md:1
msgid "# 虚拟测试环境"
msgstr "# 虚拟测试环境"

#: src/1-2-hello-world-virtually.md:3
msgid ""
"虽然SONiC功能强大，但是大部分时候一台能够支持SONiC系统的交换机价格并不便宜，"
"如果你只是想试一试SONiC，但是又不想花钱买一台SONiC的硬件设备，那么这一章一定"
"不能错过，这一章会总结一下如何通过GNS3在本地搭建一个虚拟的SONiC的Lab，让你可"
"以很快的在本地体验一把SONiC的基本功能。"
msgstr ""
"虽然SONiC功能强大，但是大部分时候一台能够支持SONiC系统的交换机价格并不便宜，"
"如果你只是想试一试SONiC，但是又不想花钱买一台SONiC的硬件设备，那么这一章一定"
"不能错过，这一章会总结一下如何通过GNS3在本地搭建一个虚拟的SONiC的Lab，让你可"
"以很快的在本地体验一把SONiC的基本功能。"

#: src/1-2-hello-world-virtually.md:5
msgid ""
"在本地运行SONiC的方法很好几种，比如docker + vswitch，p4软交换机等等，对于初次"
"使用而言，用GNS3可能是最方便快捷的了，所以本文就以GNS3为例，介绍一下如何在本"
"地搭建一个SONiC的Lab。那么，我们就开始吧！"
msgstr ""
"在本地运行SONiC的方法很好几种，比如docker + vswitch，p4软交换机等等，对于初次"
"使用而言，用GNS3可能是最方便快捷的了，所以本文就以GNS3为例，介绍一下如何在本"
"地搭建一个SONiC的Lab。那么，我们就开始吧！"

#: src/1-2-hello-world-virtually.md:7
msgid "## 安装GNS3"
msgstr "## 安装GNS3"

#: src/1-2-hello-world-virtually.md:9
msgid ""
"首先，为了让我们方便而且直观的建立测试用的虚拟网络，我们需要先来安装一下"
"GNS3。"
msgstr ""
"首先，为了让我们方便而且直观的建立测试用的虚拟网络，我们需要先来安装一下"
"GNS3。"

#: src/1-2-hello-world-virtually.md:11
msgid ""
"[GNS3，全称为Graphical Network Simulator 3，是一个图形化的网络仿真软件]"
"[GNS3]。它支持多种不同的虚拟化技术，比如：QEMU、VMware、VirtualBox等等。这"
"样，我们在等会搭建虚拟网络的时候，就不需要手动的运行很多命令，或者写脚本了，"
"大部分的工作都可以通过图形界面来完成了。"
msgstr ""
"[GNS3，全称为Graphical Network Simulator 3，是一个图形化的网络仿真软件]"
"[GNS3]。它支持多种不同的虚拟化技术，比如：QEMU、VMware、VirtualBox等等。这"
"样，我们在等会搭建虚拟网络的时候，就不需要手动的运行很多命令，或者写脚本了，"
"大部分的工作都可以通过图形界面来完成了。"

#: src/1-2-hello-world-virtually.md:13
msgid "### 安装依赖"
msgstr "### 安装依赖"

#: src/1-2-hello-world-virtually.md:15
msgid ""
"安装它之前，我们需要先安装几个其他的软件：docker, wireshark, putty, qemu, "
"ubridge, libvirt和bridge-utils，已经装好的小伙伴可以自行跳过。"
msgstr ""
"安装它之前，我们需要先安装几个其他的软件：docker, wireshark, putty, qemu, "
"ubridge, libvirt和bridge-utils，已经装好的小伙伴可以自行跳过。"

#: src/1-2-hello-world-virtually.md:17
msgid ""
"首先是Docker，它们的安装过程，大家可以自己通过下面的传送门去安装：[https://"
"docs.docker.com/engine/install/](https://docs.docker.com/engine/install/)"
msgstr ""
"首先是Docker，它们的安装过程，大家可以自己通过下面的传送门去安装：[https://"
"docs.docker.com/engine/install/](https://docs.docker.com/engine/install/)"

#: src/1-2-hello-world-virtually.md:19
msgid ""
"其他的在ubuntu上安装都非常简单，只需要执行下面的命令就可以了。这里安装时要注"
"意，ubridge和Wireshark的安装过程中会询问是不是要创建wireshark用户组来bypass "
"sudo，这里一定要选择Yes。"
msgstr ""
"其他的在ubuntu上安装都非常简单，只需要执行下面的命令就可以了。这里安装时要注"
"意，ubridge和Wireshark的安装过程中会询问是不是要创建wireshark用户组来bypass "
"sudo，这里一定要选择Yes。"

#: src/1-2-hello-world-virtually.md:21
msgid ""
"```\n"
"sudo apt-get install qemu-kvm libvirt-daemon-system libvirt-clients bridge-"
"utils wireshark putty ubridge\n"
"```"
msgstr ""
"```\n"
"sudo apt-get install qemu-kvm libvirt-daemon-system libvirt-clients bridge-"
"utils wireshark putty ubridge\n"
"```"

#: src/1-2-hello-world-virtually.md:25
msgid "安装好了之后，我们就可以来安装GNS3了。"
msgstr "安装好了之后，我们就可以来安装GNS3了。"

#: src/1-2-hello-world-virtually.md:27
msgid "### 安装GNS3"
msgstr "### 安装GNS3"

#: src/1-2-hello-world-virtually.md:29
msgid "在Ubuntu上，GNS3的安装非常简单，只需要执行下面的命令就可以了。"
msgstr "在Ubuntu上，GNS3的安装非常简单，只需要执行下面的命令就可以了。"

#: src/1-2-hello-world-virtually.md:31
msgid ""
"```bash\n"
"sudo add-apt-repository ppa:gns3/ppa\n"
"sudo apt update                                \n"
"sudo apt install gns3-gui gns3-server\n"
"```"
msgstr ""
"```bash\n"
"sudo add-apt-repository ppa:gns3/ppa\n"
"sudo apt update                                \n"
"sudo apt install gns3-gui gns3-server\n"
"```"

#: src/1-2-hello-world-virtually.md:37
msgid ""
"然后把你的用户加入到如下的组中，这样GNS3就可以去访问docker，wireshark等功能而"
"不用sudo了。"
msgstr ""
"然后把你的用户加入到如下的组中，这样GNS3就可以去访问docker，wireshark等功能而"
"不用sudo了。"

#: src/1-2-hello-world-virtually.md:39
msgid ""
"```bash\n"
"for g in ubridge libvirt kvm wireshark docker; do\n"
"    sudo usermod -aG $g <user-name>\n"
"done\n"
"```"
msgstr ""
"```bash\n"
"for g in ubridge libvirt kvm wireshark docker; do\n"
"    sudo usermod -aG $g <user-name>\n"
"done\n"
"```"

#: src/1-2-hello-world-virtually.md:45
msgid ""
"如果你使用的不是Ubuntu，更详细的安装文档可以参考[他们的官方文档]"
"[GNS3Install]。"
msgstr ""
"如果你使用的不是Ubuntu，更详细的安装文档可以参考[他们的官方文档]"
"[GNS3Install]。"

#: src/1-2-hello-world-virtually.md:47
msgid "## 准备SONiC的镜像"
msgstr "## 准备SONiC的镜像"

#: src/1-2-hello-world-virtually.md:49
msgid ""
"在测试之前，我们还需要一个SONiC的镜像。由于需要支持大量不同的厂商，而每个厂商"
"的底层实现都不一样，所以最后每个厂商都会编译一个自己的镜像。这里因为我们在创"
"建虚拟的环境，所以我们需要使用基于VSwitch的镜像来创建虚拟交换机：sonic-vs."
"img.gz。"
msgstr ""
"在测试之前，我们还需要一个SONiC的镜像。由于需要支持大量不同的厂商，而每个厂商"
"的底层实现都不一样，所以最后每个厂商都会编译一个自己的镜像。这里因为我们在创"
"建虚拟的环境，所以我们需要使用基于VSwitch的镜像来创建虚拟交换机：sonic-vs."
"img.gz。"

#: src/1-2-hello-world-virtually.md:51
msgid ""
"[SONiC镜像的项目在这里](https://github.com/sonic-net/sonic-buildimage)，虽然"
"我们可以自己去编译，但是速度实在有点慢，所以为了节省时间，我们可以直接[去这里"
"下载最新的镜像](https://sonic-build.azurewebsites.net/ui/sonic/pipelines/142/"
"builds?branchName=master)。只要找一个最新的成功的Build就行，在Artifacts中找到"
"sonic-vs.img.gz，下载就可以了。"
msgstr ""
"[SONiC镜像的项目在这里](https://github.com/sonic-net/sonic-buildimage)，虽然"
"我们可以自己去编译，但是速度实在有点慢，所以为了节省时间，我们可以直接[去这里"
"下载最新的镜像](https://sonic-build.azurewebsites.net/ui/sonic/pipelines/142/"
"builds?branchName=master)。只要找一个最新的成功的Build就行，在Artifacts中找到"
"sonic-vs.img.gz，下载就可以了。"

#: src/1-2-hello-world-virtually.md:53
msgid "然后，我们来准备一下项目："
msgstr "然后，我们来准备一下项目："

#: src/1-2-hello-world-virtually.md:55
msgid ""
"```bash\n"
"git clone --recurse-submodules https://github.com/sonic-net/sonic-buildimage."
"git\n"
"cd sonic-buildimage/platform/vs\n"
"\n"
"# 将下载的镜像放在这个目录下，然后运行下面这个命令进行解压缩。\n"
"gzip -d sonic-vs.img.gz\n"
"\n"
"# 下面这个命令会生成GNS3的镜像配置文件\n"
"./sonic-gns3a.sh\n"
"```"
msgstr ""
"```bash\n"
"git clone --recurse-submodules https://github.com/sonic-net/sonic-buildimage."
"git\n"
"cd sonic-buildimage/platform/vs\n"
"\n"
"# 将下载的镜像放在这个目录下，然后运行下面这个命令进行解压缩。\n"
"gzip -d sonic-vs.img.gz\n"
"\n"
"# 下面这个命令会生成GNS3的镜像配置文件\n"
"./sonic-gns3a.sh\n"
"```"

#: src/1-2-hello-world-virtually.md:66
msgid "执行完成之后，我们运行`ls`命令就可以看到我们需要的镜像文件了。"
msgstr "执行完成之后，我们运行`ls`命令就可以看到我们需要的镜像文件了。"

#: src/1-2-hello-world-virtually.md:68
msgid ""
"```bash\n"
"r12f@r12f-svr:~/code/sonic/sonic-buildimage/platform/vs\n"
"$ l\n"
"total 2.8G\n"
"...\n"
"-rw-rw-r--  1 r12f r12f 1.1K Apr 18 16:36 SONiC-latest.gns3a  # <= 这个是GNS3"
"的镜像配置文件\n"
"-rw-rw-r--  1 r12f r12f 2.8G Apr 18 16:32 sonic-vs.img        # <= 这个是我们"
"解压出来的镜像\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"r12f@r12f-svr:~/code/sonic/sonic-buildimage/platform/vs\n"
"$ l\n"
"total 2.8G\n"
"...\n"
"-rw-rw-r--  1 r12f r12f 1.1K Apr 18 16:36 SONiC-latest.gns3a  # <= 这个是GNS3"
"的镜像配置文件\n"
"-rw-rw-r--  1 r12f r12f 2.8G Apr 18 16:32 sonic-vs.img        # <= 这个是我们"
"解压出来的镜像\n"
"...\n"
"```"

#: src/1-2-hello-world-virtually.md:78
msgid "## 导入镜像"
msgstr "## 导入镜像"

#: src/1-2-hello-world-virtually.md:80
msgid ""
"现在，在命令行里面输入`gns3`，就可以启动GNS3了。如果你是ssh到另外一台机器上，"
"可以试着启用X11转发，这样就可以在远程运行GNS3，但是图形界面显示在本地了。我就"
"是这样，将GNS3运行在了远程的服务器上，但是图形界面通过MobaXterm显示在了本地的"
"Windows机器上。"
msgstr ""
"现在，在命令行里面输入`gns3`，就可以启动GNS3了。如果你是ssh到另外一台机器上，"
"可以试着启用X11转发，这样就可以在远程运行GNS3，但是图形界面显示在本地了。我就"
"是这样，将GNS3运行在了远程的服务器上，但是图形界面通过MobaXterm显示在了本地的"
"Windows机器上。"

#: src/1-2-hello-world-virtually.md:82
msgid ""
"运行起来之后，GNS3会让我们创建一个项目，很简单，填个目录地址就好。如果你是使"
"用的X11转发，请注意，这个目录是在你远程服务器上，而不是本地。"
msgstr ""
"运行起来之后，GNS3会让我们创建一个项目，很简单，填个目录地址就好。如果你是使"
"用的X11转发，请注意，这个目录是在你远程服务器上，而不是本地。"

#: src/1-2-hello-world-virtually.md:86
msgid ""
"然后，我们就可以通过`File -> Import appliance`来导入我们刚刚生成的镜像了。"
msgstr ""
"然后，我们就可以通过`File -> Import appliance`来导入我们刚刚生成的镜像了。"

#: src/1-2-hello-world-virtually.md:90
msgid "选择我们刚刚生成的`SONiC-latest.gns3a`镜像配置文件，然后点击`Next`。"
msgstr "选择我们刚刚生成的`SONiC-latest.gns3a`镜像配置文件，然后点击`Next`。"

#: src/1-2-hello-world-virtually.md:94
msgid "这个时候就可以看到我们的ji镜像了，点击`Next`。"
msgstr "这个时候就可以看到我们的ji镜像了，点击`Next`。"

#: src/1-2-hello-world-virtually.md:98
msgid ""
"这个时候会开始导入镜像，这个过程可能会比较慢，因为GNS3需要将镜像转换成qcow2格"
"式，放入我们的项目目录中。导入完成之后，我们就可以看到我们的镜像了。"
msgstr ""
"这个时候会开始导入镜像，这个过程可能会比较慢，因为GNS3需要将镜像转换成qcow2格"
"式，放入我们的项目目录中。导入完成之后，我们就可以看到我们的镜像了。"

#: src/1-2-hello-world-virtually.md:102
msgid "好的！完成！"
msgstr "好的！完成！"

#: src/1-2-hello-world-virtually.md:104
msgid "## 创建网络"
msgstr "## 创建网络"

#: src/1-2-hello-world-virtually.md:106
msgid "好了！现在一切就绪，我们还是创建一个虚拟的网络吧！"
msgstr "好了！现在一切就绪，我们还是创建一个虚拟的网络吧！"

#: src/1-2-hello-world-virtually.md:108
msgid ""
"GNS3的图形界面非常的好用，基本上就是打开侧边栏，把交换机拖进来，把VPC拖进来，"
"然后把线连起来就可以了。连接好之后记得点上面的Play按钮开始网络模拟。这里我们"
"就不多说了，直接上图。"
msgstr ""
"GNS3的图形界面非常的好用，基本上就是打开侧边栏，把交换机拖进来，把VPC拖进来，"
"然后把线连起来就可以了。连接好之后记得点上面的Play按钮开始网络模拟。这里我们"
"就不多说了，直接上图。"

#: src/1-2-hello-world-virtually.md:112
msgid ""
"接着，在交换机上点击右键，选择`Custom Console`，再选择Putty，就可以打开我们的"
"上面看到的交换机的Console了。这里，SONiC的默认用户名和密码是`admin`和"
"`YourPaSsWoRd`。登录进去之后，我们就可以运行熟悉的命令，用`show interfaces "
"status`或者`show ip interface`来查看网络的状态了。我们这里也可以看到，前面两"
"个我们连接好了的Interface的状态都是`up`的了。"
msgstr ""
"接着，在交换机上点击右键，选择`Custom Console`，再选择Putty，就可以打开我们的"
"上面看到的交换机的Console了。这里，SONiC的默认用户名和密码是`admin`和"
"`YourPaSsWoRd`。登录进去之后，我们就可以运行熟悉的命令，用`show interfaces "
"status`或者`show ip interface`来查看网络的状态了。我们这里也可以看到，前面两"
"个我们连接好了的Interface的状态都是`up`的了。"

#: src/1-2-hello-world-virtually.md:114
msgid ""
"除了这种简单的网络以外，GNS3还可以创建非常复杂的网络，比如多层ECMP结构等等。"
"这里就不多说了，有兴趣的可以自己去试一试~"
msgstr ""
"除了这种简单的网络以外，GNS3还可以创建非常复杂的网络，比如多层ECMP结构等等。"
"这里就不多说了，有兴趣的可以自己去试一试~"

#: src/1-2-hello-world-virtually.md:116
msgid "## 配置网络"
msgstr "## 配置网络"

#: src/1-2-hello-world-virtually.md:118
msgid ""
"SONiC软交换机下，默认的端口使用的是10.0.0.x的子网（如下），而且都是eth pair："
msgstr ""
"SONiC软交换机下，默认的端口使用的是10.0.0.x的子网（如下），而且都是eth pair："

#: src/1-2-hello-world-virtually.md:129
msgid ""
"这里，我们比较方便的做法是创建一个小的vlan，把我们的端口都包在里面（我们这里"
"用的是Ethernet4和Ethernet8）："
msgstr ""
"这里，我们比较方便的做法是创建一个小的vlan，把我们的端口都包在里面（我们这里"
"用的是Ethernet4和Ethernet8）："

#: src/1-2-hello-world-virtually.md:131
msgid ""
"```bash\n"
"# Remove old config\n"
"sudo config interface ip remove Ethernet4 10.0.0.2/31\n"
"sudo config interface ip remove Ethernet8 10.0.0.4/31\n"
"\n"
"# Create VLAN with id 2\n"
"sudo config vlan add 2\n"
"\n"
"# Add ports to VLAN\n"
"sudo config vlan member add -u 2 Ethernet4\n"
"sudo config vlan member add -u 2 Ethernet8\n"
"\n"
"# Add IP address to VLAN\n"
"sudo config interface ip add Vlan2 10.0.0.0/24\n"
"```"
msgstr ""
"```bash\n"
"# Remove old config\n"
"sudo config interface ip remove Ethernet4 10.0.0.2/31\n"
"sudo config interface ip remove Ethernet8 10.0.0.4/31\n"
"\n"
"# Create VLAN with id 2\n"
"sudo config vlan add 2\n"
"\n"
"# Add ports to VLAN\n"
"sudo config vlan member add -u 2 Ethernet4\n"
"sudo config vlan member add -u 2 Ethernet8\n"
"\n"
"# Add IP address to VLAN\n"
"sudo config interface ip add Vlan2 10.0.0.0/24\n"
"```"

#: src/1-2-hello-world-virtually.md:147
msgid "这样，我们的vlan就创建好了，我们可以通过`show vlan brief`来查看一下："
msgstr "这样，我们的vlan就创建好了，我们可以通过`show vlan brief`来查看一下："

#: src/1-2-hello-world-virtually.md:149
msgid ""
"```bash\n"
"admin@sonic:~$ show vlan brief\n"
"+-----------+--------------+-----------+----------------+-------------"
"+-----------------------+\n"
"|   VLAN ID | IP Address   | Ports     | Port Tagging   | Proxy ARP   | DHCP "
"Helper Address   |\n"
"+===========+==============+===========+================+=============+=======================+\n"
"|         2 | 10.0.0.0/24  | Ethernet4 | untagged       | disabled    "
"|                       |\n"
"|           |              | Ethernet8 | untagged       |             "
"|                       |\n"
"+-----------+--------------+-----------+----------------+-------------"
"+-----------------------+\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ show vlan brief\n"
"+-----------+--------------+-----------+----------------+-------------"
"+-----------------------+\n"
"|   VLAN ID | IP Address   | Ports     | Port Tagging   | Proxy ARP   | DHCP "
"Helper Address   |\n"
"+===========+==============+===========+================+=============+=======================+\n"
"|         2 | 10.0.0.0/24  | Ethernet4 | untagged       | disabled    "
"|                       |\n"
"|           |              | Ethernet8 | untagged       |             "
"|                       |\n"
"+-----------+--------------+-----------+----------------+-------------"
"+-----------------------+\n"
"```"

#: src/1-2-hello-world-virtually.md:159
msgid "然后，我们就可以给所有的主机配置一个10.0.0.x的IP地址了。"
msgstr "然后，我们就可以给所有的主机配置一个10.0.0.x的IP地址了。"

#: src/1-2-hello-world-virtually.md:161
msgid ""
"```bash\n"
"# VPC1\n"
"ip 10.0.0.2 255.0.0.0 10.0.0.1\n"
"\n"
"# VPC2\n"
"ip 10.0.0.3 255.0.0.0 10.0.0.1\n"
"```"
msgstr ""
"```bash\n"
"# VPC1\n"
"ip 10.0.0.2 255.0.0.0 10.0.0.1\n"
"\n"
"# VPC2\n"
"ip 10.0.0.3 255.0.0.0 10.0.0.1\n"
"```"

#: src/1-2-hello-world-virtually.md:169
msgid "好的，现在我们来Ping一下吧！"
msgstr "好的，现在我们来Ping一下吧！"

#: src/1-2-hello-world-virtually.md:173
msgid "通了！"
msgstr "通了！"

#: src/1-2-hello-world-virtually.md:175
msgid "## 抓包"
msgstr "## 抓包"

#: src/1-2-hello-world-virtually.md:177
msgid ""
"上面，我们安装GNS3前，我们特意安装了Wireshark，这样我们就可以在GNS3里面抓包"
"了。我们只需要右键点击图中我们想抓包的Link上，然后选择`Start capture`，就可以"
"开始抓包了。"
msgstr ""
"上面，我们安装GNS3前，我们特意安装了Wireshark，这样我们就可以在GNS3里面抓包"
"了。我们只需要右键点击图中我们想抓包的Link上，然后选择`Start capture`，就可以"
"开始抓包了。"

#: src/1-2-hello-world-virtually.md:181
msgid "稍等一下，Wireshark就会自动打开，实时的显示所有的包，非常的方便："
msgstr "稍等一下，Wireshark就会自动打开，实时的显示所有的包，非常的方便："

#: src/1-2-hello-world-virtually.md:185
msgid "## 更多的网络"
msgstr "## 更多的网络"

#: src/1-2-hello-world-virtually.md:187
msgid ""
"除了上面这种最简单的网络搭建，我们其实可以用GNS3搭建很多非常复杂的网络来进行"
"测试，比如多层ECMP + eBGP等等。XFlow Research发布了一篇非常详细的文档来介绍这"
"些内容，感兴趣的小伙伴可以去传送到这篇文档去看看：[SONiC Deployment and "
"Testing Using GNS3][SONiCWithGNS3]。"
msgstr ""
"除了上面这种最简单的网络搭建，我们其实可以用GNS3搭建很多非常复杂的网络来进行"
"测试，比如多层ECMP + eBGP等等。XFlow Research发布了一篇非常详细的文档来介绍这"
"些内容，感兴趣的小伙伴可以去传送到这篇文档去看看：[SONiC Deployment and "
"Testing Using GNS3][SONiCWithGNS3]。"

#: src/1-2-hello-world-virtually.md:191
msgid ""
"1. [GNS3][GNS3]\n"
"2. [GNS3 Linux Install][GNS3Install]\n"
"3. [SONiC Deployment and Testing Using GNS3][SONiCWithGNS3]"
msgstr ""
"1. [GNS3][GNS3]\n"
"2. [GNS3 Linux Install][GNS3Install]\n"
"3. [SONiC Deployment and Testing Using GNS3][SONiCWithGNS3]"

#: src/1-3-command-cheatsheet.md:1
msgid "# 常用命令"
msgstr "# 常用命令"

#: src/1-3-command-cheatsheet.md:3
msgid ""
"为了帮助我们查看和配置SONiC的状态，SONiC提供了大量的CLI命令供我们调用。这些命"
"令大多分为两类：`show`和`config`，他们的格式基本类似，大多都符合下面的格式："
msgstr ""
"为了帮助我们查看和配置SONiC的状态，SONiC提供了大量的CLI命令供我们调用。这些命"
"令大多分为两类：`show`和`config`，他们的格式基本类似，大多都符合下面的格式："

#: src/1-3-command-cheatsheet.md:5
msgid ""
"```bash\n"
"show <object> [options]\n"
"config <object> [options]\n"
"```"
msgstr ""
"```bash\n"
"show <object> [options]\n"
"config <object> [options]\n"
"```"

#: src/1-3-command-cheatsheet.md:10
msgid ""
"SONiC的文档提供了非常详细的命令列表：[SONiC Command Line Interface Guide]"
"[SONiCCommands]，但是由于其命令众多，不便于我们初期的学习和使用，所以列出了一"
"些平时最常用的命令和解释，供大家参考。"
msgstr ""
"SONiC的文档提供了非常详细的命令列表：[SONiC Command Line Interface Guide]"
"[SONiCCommands]，但是由于其命令众多，不便于我们初期的学习和使用，所以列出了一"
"些平时最常用的命令和解释，供大家参考。"

#: src/1-3-command-cheatsheet.md:12
msgid ""
"```admonish info\n"
"SONiC中的所有命令的子命令都可以只打前三个字母，来帮助我们有效的节约输入命令的"
"时间，比如：\n"
"\n"
"    show interface transceiver error-status\n"
"    \n"
"和下面这条命令是等价的：\n"
"\n"
"    show int tra err\n"
"\n"
"为了帮助大家记忆和查找，下面的命令列表都用的全名，但是大家在实际使用的时候，"
"可以大胆的使用缩写来减少工作量。\n"
"```"
msgstr ""
"```admonish info\n"
"SONiC中的所有命令的子命令都可以只打前三个字母，来帮助我们有效的节约输入命令的"
"时间，比如：\n"
"\n"
"    show interface transceiver error-status\n"
"    \n"
"和下面这条命令是等价的：\n"
"\n"
"    show int tra err\n"
"\n"
"为了帮助大家记忆和查找，下面的命令列表都用的全名，但是大家在实际使用的时候，"
"可以大胆的使用缩写来减少工作量。\n"
"```"

#: src/1-3-command-cheatsheet.md:24
msgid ""
"```admonish info\n"
"如果遇到不熟悉的命令，都可以通过输入`-h`或者`--help`来查看帮助信息，比如：\n"
"\n"
"    show -h\n"
"    show interface --help\n"
"    show interface transceiver --help\n"
"\n"
"```"
msgstr ""
"```admonish info\n"
"如果遇到不熟悉的命令，都可以通过输入`-h`或者`--help`来查看帮助信息，比如：\n"
"\n"
"    show -h\n"
"    show interface --help\n"
"    show interface transceiver --help\n"
"\n"
"```"

#: src/1-3-command-cheatsheet.md:33
msgid "## General"
msgstr "## General"

#: src/1-3-command-cheatsheet.md:35
msgid ""
"```bash\n"
"show version\n"
"\n"
"show uptime\n"
"\n"
"show platform summary\n"
"```"
msgstr ""
"```bash\n"
"show version\n"
"\n"
"show uptime\n"
"\n"
"show platform summary\n"
"```"

#: src/1-3-command-cheatsheet.md:43
msgid "## Config"
msgstr "## Config"

#: src/1-3-command-cheatsheet.md:45
msgid ""
"```bash\n"
"sudo config reload\n"
"sudo config load_minigraph\n"
"sudo config save -y\n"
"```"
msgstr ""
"```bash\n"
"sudo config reload\n"
"sudo config load_minigraph\n"
"sudo config save -y\n"
"```"

#: src/1-3-command-cheatsheet.md:51
msgid "## Docker相关"
msgstr "## Docker相关"

#: src/1-3-command-cheatsheet.md:53
msgid ""
"```bash\n"
"docker ps\n"
"```"
msgstr ""
"```bash\n"
"docker ps\n"
"```"

#: src/1-3-command-cheatsheet.md:57
msgid ""
"```bash\n"
"docker top <container_id>|<container_name>\n"
"```"
msgstr ""
"```bash\n"
"docker top <container_id>|<container_name>\n"
"```"

#: src/1-3-command-cheatsheet.md:61
msgid ""
"```admonish note\n"
"\n"
"如果我们想对所有的docker container进行某个操作，我们可以通过`docker ps`命令来"
"获取所有的container id，然后pipe到`tail -n +2`来去掉第一行的标题，从而实现批"
"量调用。\n"
"\n"
"比如，我们可以通过如下命令来查看所有container中正在运行的所有线程：\n"
"\n"
"    $ for id in `docker ps | tail -n +2 | awk '{print $1}'`; do docker top "
"$id; done\n"
"    UID                 PID                 PPID                "
"C                   STIME               TTY                 "
"TIME                CMD\n"
"    root                7126                7103                "
"0                   Jun09               pts/0               "
"00:02:24            /usr/bin/python3 /usr/local/bin/supervisord\n"
"    root                7390                7126                "
"0                   Jun09               pts/0               "
"00:00:24            python3 /usr/bin/supervisor-proc-exit-listener --"
"container-name telemetry\n"
"    ...\n"
"```"
msgstr ""
"```admonish note\n"
"\n"
"如果我们想对所有的docker container进行某个操作，我们可以通过`docker ps`命令来"
"获取所有的container id，然后pipe到`tail -n +2`来去掉第一行的标题，从而实现批"
"量调用。\n"
"\n"
"比如，我们可以通过如下命令来查看所有container中正在运行的所有线程：\n"
"\n"
"    $ for id in `docker ps | tail -n +2 | awk '{print $1}'`; do docker top "
"$id; done\n"
"    UID                 PID                 PPID                "
"C                   STIME               TTY                 "
"TIME                CMD\n"
"    root                7126                7103                "
"0                   Jun09               pts/0               "
"00:02:24            /usr/bin/python3 /usr/local/bin/supervisord\n"
"    root                7390                7126                "
"0                   Jun09               pts/0               "
"00:00:24            python3 /usr/bin/supervisor-proc-exit-listener --"
"container-name telemetry\n"
"    ...\n"
"```"

#: src/1-3-command-cheatsheet.md:74
msgid "## Interfaces / IPs"
msgstr "## Interfaces / IPs"

#: src/1-3-command-cheatsheet.md:76
msgid ""
"```bash\n"
"show interface status\n"
"show interface counters\n"
"show interface portchannel\n"
"show interface transceiver info\n"
"show interface transceiver error-status\n"
"sonic-clear counters\n"
"\n"
"TODO: config\n"
"```"
msgstr ""
"```bash\n"
"show interface status\n"
"show interface counters\n"
"show interface portchannel\n"
"show interface transceiver info\n"
"show interface transceiver error-status\n"
"sonic-clear counters\n"
"\n"
"TODO: config\n"
"```"

#: src/1-3-command-cheatsheet.md:87
msgid "## MAC / ARP / NDP"
msgstr "## MAC / ARP / NDP"

#: src/1-3-command-cheatsheet.md:89
msgid ""
"```bash\n"
"# Show MAC (FDB) entries\n"
"show mac\n"
"\n"
"# Show IP ARP table\n"
"show arp\n"
"\n"
"# Show IPv6 NDP table\n"
"show ndp\n"
"```"
msgstr ""
"```bash\n"
"# Show MAC (FDB) entries\n"
"show mac\n"
"\n"
"# Show IP ARP table\n"
"show arp\n"
"\n"
"# Show IPv6 NDP table\n"
"show ndp\n"
"```"

#: src/1-3-command-cheatsheet.md:100
msgid "## BGP / Routes"
msgstr "## BGP / Routes"

#: src/1-3-command-cheatsheet.md:102
msgid ""
"```bash\n"
"show ip/ipv6 bgp summary\n"
"show ip/ipv6 bgp network\n"
"\n"
"show ip/ipv6 bgp neighbors [IP]\n"
"\n"
"show ip/ipv6 route\n"
"\n"
"TODO: add\n"
"config bgp shutdown neighbor <IP>\n"
"config bgp shutdown all\n"
"\n"
"TODO: IPv6\n"
"```"
msgstr ""
"```bash\n"
"show ip/ipv6 bgp summary\n"
"show ip/ipv6 bgp network\n"
"\n"
"show ip/ipv6 bgp neighbors [IP]\n"
"\n"
"show ip/ipv6 route\n"
"\n"
"TODO: add\n"
"config bgp shutdown neighbor <IP>\n"
"config bgp shutdown all\n"
"\n"
"TODO: IPv6\n"
"```"

#: src/1-3-command-cheatsheet.md:117
msgid "## LLDP"
msgstr "## LLDP"

#: src/1-3-command-cheatsheet.md:119
msgid ""
"```bash\n"
"# Show LLDP neighbors in table format\n"
"show lldp table\n"
"\n"
"# Show LLDP neighbors details\n"
"show lldp neighbors\n"
"```"
msgstr ""
"```bash\n"
"# Show LLDP neighbors in table format\n"
"show lldp table\n"
"\n"
"# Show LLDP neighbors details\n"
"show lldp neighbors\n"
"```"

#: src/1-3-command-cheatsheet.md:127
msgid "## VLAN"
msgstr "## VLAN"

#: src/1-3-command-cheatsheet.md:129
msgid ""
"```bash\n"
"show vlan brief\n"
"```"
msgstr ""
"```bash\n"
"show vlan brief\n"
"```"

#: src/1-3-command-cheatsheet.md:133
msgid "## QoS相关"
msgstr "## QoS相关"

#: src/1-3-command-cheatsheet.md:135
msgid ""
"```bash\n"
"# Show PFC watchdog stats\n"
"show pfcwd stats\n"
"show queue counter\n"
"```"
msgstr ""
"```bash\n"
"# Show PFC watchdog stats\n"
"show pfcwd stats\n"
"show queue counter\n"
"```"

#: src/1-3-command-cheatsheet.md:141
msgid "## ACL"
msgstr "## ACL"

#: src/1-3-command-cheatsheet.md:143
msgid ""
"```bash\n"
"show acl table\n"
"show acl rule\n"
"```"
msgstr ""
"```bash\n"
"show acl table\n"
"show acl rule\n"
"```"

#: src/1-3-command-cheatsheet.md:148
msgid "## MUXcable / Dual ToR"
msgstr "## MUXcable / Dual ToR"

#: src/1-3-command-cheatsheet.md:150
msgid "### Muxcable mode"
msgstr "### Muxcable mode"

#: src/1-3-command-cheatsheet.md:152
msgid ""
"```bash\n"
"config muxcable mode {active} {<portname>|all} [--json]\n"
"config muxcable mode active Ethernet4 [--json]\n"
"```"
msgstr ""
"```bash\n"
"config muxcable mode {active} {<portname>|all} [--json]\n"
"config muxcable mode active Ethernet4 [--json]\n"
"```"

#: src/1-3-command-cheatsheet.md:157
msgid "### Muxcable config"
msgstr "### Muxcable config"

#: src/1-3-command-cheatsheet.md:159
msgid ""
"```bash\n"
"show muxcable config [portname] [--json]\n"
"```"
msgstr ""
"```bash\n"
"show muxcable config [portname] [--json]\n"
"```"

#: src/1-3-command-cheatsheet.md:163
msgid "### Muxcable status"
msgstr "### Muxcable status"

#: src/1-3-command-cheatsheet.md:165
msgid ""
"```bash\n"
"show muxcable status [portname] [--json] \n"
"```"
msgstr ""
"```bash\n"
"show muxcable status [portname] [--json] \n"
"```"

#: src/1-3-command-cheatsheet.md:169
msgid "### Muxcable firmware"
msgstr "### Muxcable firmware"

#: src/1-3-command-cheatsheet.md:171
msgid ""
"```bash\n"
"# Firmware version:\n"
"show muxcable firmware version <port>\n"
"\n"
"# Firmware download\n"
"# config muxcable firmware download <firmware_file> <port_name> \n"
"sudo config muxcable firmware download AEC_WYOMING_B52Yb0_MS_0.6_20201218."
"bin Ethernet0\n"
"\n"
"# Rollback:\n"
"# config muxcable firmware rollback <port_name>\n"
"sudo config muxcable firmware rollback Ethernet0\n"
"```"
msgstr ""
"```bash\n"
"# Firmware version:\n"
"show muxcable firmware version <port>\n"
"\n"
"# Firmware download\n"
"# config muxcable firmware download <firmware_file> <port_name> \n"
"sudo config muxcable firmware download AEC_WYOMING_B52Yb0_MS_0.6_20201218."
"bin Ethernet0\n"
"\n"
"# Rollback:\n"
"# config muxcable firmware rollback <port_name>\n"
"sudo config muxcable firmware rollback Ethernet0\n"
"```"

#: src/1-3-command-cheatsheet.md:186
msgid "1. [SONiC Command Line Interface Guide][SONiCCommands]"
msgstr "1. [SONiC Command Line Interface Guide][SONiCCommands]"

#: src/2-components.md:1
msgid "# 核心组件"
msgstr "# 核心组件"

#: src/2-components.md:3
msgid ""
"我们也许会觉得交换机是一个很简单的网络设备，但是实际上交换机上的组件非常的"
"多，而且由于SONiC中Redis的解耦，我们很难简单的对代码进行跟踪来理解服务之间的"
"关系，这就需要我们先建立一个比较抽线的整体模型，然后再去深入的学习每个组件的"
"细节。所以在深入其他部分之前，我们这里先对每个组件都做一个点到为止的介绍，帮"
"助大家建立一个大概的整体模型。"
msgstr ""
"我们也许会觉得交换机是一个很简单的网络设备，但是实际上交换机上的组件非常的"
"多，而且由于SONiC中Redis的解耦，我们很难简单的对代码进行跟踪来理解服务之间的"
"关系，这就需要我们先建立一个比较抽线的整体模型，然后再去深入的学习每个组件的"
"细节。所以在深入其他部分之前，我们这里先对每个组件都做一个点到为止的介绍，帮"
"助大家建立一个大概的整体模型。"

#: src/2-components.md:5
msgid ""
"```admonish info\n"
"在阅读本章之前，有两个名词会经常在本章和SONiC的官方文档中出现：ASIC"
"（Application-Specific Integrated Circuit）和ASIC状态（State）。它们指的是交"
"换机中用来进行包处理的Pipeline的状态，比如，ACL，转发方式等等，这个和其他交换"
"机的硬件状态，比如，端口状态（端口速度，接口类型），IP信息等等硬件状态是非常"
"不同的。\n"
"\n"
"如果大家有兴趣了解更深入的细节，可以先移步阅读两个相关资料：[SAI (Switch "
"Abstraction Interface) API][SAIAPI]和一篇RMT（Reprogrammable Match Table）的"
"相关论文：[Forwarding Metamorphosis: Fast Programmable Match-Action "
"Processing in Hardware for SDN][PISA]。\n"
"\n"
"这些都会对我们阅读SONiC的文档有很大的帮助。\n"
"```"
msgstr ""
"```admonish info\n"
"在阅读本章之前，有两个名词会经常在本章和SONiC的官方文档中出现：ASIC"
"（Application-Specific Integrated Circuit）和ASIC状态（State）。它们指的是交"
"换机中用来进行包处理的Pipeline的状态，比如，ACL，转发方式等等，这个和其他交换"
"机的硬件状态，比如，端口状态（端口速度，接口类型），IP信息等等硬件状态是非常"
"不同的。\n"
"\n"
"如果大家有兴趣了解更深入的细节，可以先移步阅读两个相关资料：[SAI (Switch "
"Abstraction Interface) API][SAIAPI]和一篇RMT（Reprogrammable Match Table）的"
"相关论文：[Forwarding Metamorphosis: Fast Programmable Match-Action "
"Processing in Hardware for SDN][PISA]。\n"
"\n"
"这些都会对我们阅读SONiC的文档有很大的帮助。\n"
"```"

#: src/2-components.md:13
msgid ""
"另外为了方便我们的理解和阅读，我们也把SONiC架构图在这里放在这一章的开头，作为"
"引用："
msgstr ""
"另外为了方便我们的理解和阅读，我们也把SONiC架构图在这里放在这一章的开头，作为"
"引用："

#: src/2-components.md:21
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SAI API][SAIAPI]\n"
"3. [Forwarding Metamorphosis: Fast Programmable Match-Action Processing in "
"Hardware for SDN][PISA]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SAI API][SAIAPI]\n"
"3. [Forwarding Metamorphosis: Fast Programmable Match-Action Processing in "
"Hardware for SDN][PISA]"

#: src/2-1-database.md:1
msgid "# Redis数据库"
msgstr "# Redis数据库"

#: src/2-1-database.md:3
msgid ""
"首先，在SONiC里面最核心的服务，自然是当之无愧的中心数据库Redis了！它的主要目"
"的有两个：存储所有服务的配置和状态，并且为各个服务提供通信的媒介。"
msgstr ""
"首先，在SONiC里面最核心的服务，自然是当之无愧的中心数据库Redis了！它的主要目"
"的有两个：存储所有服务的配置和状态，并且为各个服务提供通信的媒介。"

#: src/2-1-database.md:5
msgid ""
"为了提供这些功能，SONiC会在Redis中创建一个名为`sonic-db`的数据库，其配置和分"
"库信息我们可以在`/var/run/redis/sonic-db/database_config.json`中找到："
msgstr ""
"为了提供这些功能，SONiC会在Redis中创建一个名为`sonic-db`的数据库，其配置和分"
"库信息我们可以在`/var/run/redis/sonic-db/database_config.json`中找到："

#: src/2-1-database.md:7
msgid ""
"```bash\n"
"admin@sonic:~$ cat /var/run/redis/sonic-db/database_config.json\n"
"{\n"
"    \"INSTANCES\": {\n"
"        \"redis\": {\n"
"            \"hostname\": \"127.0.0.1\",\n"
"            \"port\": 6379,\n"
"            \"unix_socket_path\": \"/var/run/redis/redis.sock\",\n"
"            \"persistence_for_warm_boot\": \"yes\"\n"
"        }\n"
"    },\n"
"    \"DATABASES\": {\n"
"        \"APPL_DB\": { \"id\": 0, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"ASIC_DB\": { \"id\": 1, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"COUNTERS_DB\": { \"id\": 2, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"LOGLEVEL_DB\": { \"id\": 3, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"CONFIG_DB\": { \"id\": 4, \"separator\": \"|\", \"instance\": "
"\"redis\" },\n"
"        \"PFC_WD_DB\": { \"id\": 5, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"FLEX_COUNTER_DB\": { \"id\": 5, \"separator\": \":\", "
"\"instance\": \"redis\" },\n"
"        \"STATE_DB\": { \"id\": 6, \"separator\": \"|\", \"instance\": "
"\"redis\" },\n"
"        \"SNMP_OVERLAY_DB\": { \"id\": 7, \"separator\": \"|\", "
"\"instance\": \"redis\" },\n"
"        \"RESTAPI_DB\": { \"id\": 8, \"separator\": \"|\", \"instance\": "
"\"redis\" },\n"
"        \"GB_ASIC_DB\": { \"id\": 9, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"GB_COUNTERS_DB\": { \"id\": 10, \"separator\": \":\", "
"\"instance\": \"redis\" },\n"
"        \"GB_FLEX_COUNTER_DB\": { \"id\": 11, \"separator\": \":\", "
"\"instance\": \"redis\" },\n"
"        \"APPL_STATE_DB\": { \"id\": 14, \"separator\": \":\", \"instance\": "
"\"redis\" }\n"
"    },\n"
"    \"VERSION\": \"1.0\"\n"
"}\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ cat /var/run/redis/sonic-db/database_config.json\n"
"{\n"
"    \"INSTANCES\": {\n"
"        \"redis\": {\n"
"            \"hostname\": \"127.0.0.1\",\n"
"            \"port\": 6379,\n"
"            \"unix_socket_path\": \"/var/run/redis/redis.sock\",\n"
"            \"persistence_for_warm_boot\": \"yes\"\n"
"        }\n"
"    },\n"
"    \"DATABASES\": {\n"
"        \"APPL_DB\": { \"id\": 0, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"ASIC_DB\": { \"id\": 1, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"COUNTERS_DB\": { \"id\": 2, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"LOGLEVEL_DB\": { \"id\": 3, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"CONFIG_DB\": { \"id\": 4, \"separator\": \"|\", \"instance\": "
"\"redis\" },\n"
"        \"PFC_WD_DB\": { \"id\": 5, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"FLEX_COUNTER_DB\": { \"id\": 5, \"separator\": \":\", "
"\"instance\": \"redis\" },\n"
"        \"STATE_DB\": { \"id\": 6, \"separator\": \"|\", \"instance\": "
"\"redis\" },\n"
"        \"SNMP_OVERLAY_DB\": { \"id\": 7, \"separator\": \"|\", "
"\"instance\": \"redis\" },\n"
"        \"RESTAPI_DB\": { \"id\": 8, \"separator\": \"|\", \"instance\": "
"\"redis\" },\n"
"        \"GB_ASIC_DB\": { \"id\": 9, \"separator\": \":\", \"instance\": "
"\"redis\" },\n"
"        \"GB_COUNTERS_DB\": { \"id\": 10, \"separator\": \":\", "
"\"instance\": \"redis\" },\n"
"        \"GB_FLEX_COUNTER_DB\": { \"id\": 11, \"separator\": \":\", "
"\"instance\": \"redis\" },\n"
"        \"APPL_STATE_DB\": { \"id\": 14, \"separator\": \":\", \"instance\": "
"\"redis\" }\n"
"    },\n"
"    \"VERSION\": \"1.0\"\n"
"}\n"
"```"

#: src/2-1-database.md:38
msgid ""
"虽然我们可以看到SONiC中的数据库有十来个，但是我们大部分时候只需要关注以下几个"
"最重要的数据库就可以了："
msgstr ""
"虽然我们可以看到SONiC中的数据库有十来个，但是我们大部分时候只需要关注以下几个"
"最重要的数据库就可以了："

#: src/2-1-database.md:40
msgid ""
"- **CONFIG_DB**：ID为4，存储所有服务的**配置信息**，比如端口配置，VLAN配置等"
"等。它代表着**用户想要交换机达到的状态**的数据模型，这也是所有CLI和外部应用程"
"序修改配置时的主要操作对象。\n"
"- **APPL_DB（Application DB）**：ID为0，存储**所有服务的内部状态信息**。这些"
"信息有两种：一种是各个服务在读取了CONFIG_DB的配置信息后，自己计算出来的。我们"
"可以理解为**各个服务想要交换机达到的状态**（Goal State），还有一种是当最终硬"
"件状态发生变化被写回时，有些服务会直接写回到APPL_DB，而不是我们下面马上要介绍"
"的STATE_DB。这些信息我们可以理解为**各个服务认为交换机当前的状态**（Current "
"State）。\n"
"- **STATE_DB**：ID为6，存储着交换机**各个部件当前的状态**（Current State）。"
"当SONiC中的服务收到了STATE_DB的状态变化，但是发现和Goal State不一致的时候，"
"SONiC就会重新下发配置，直到两者一致。（当然，对于那些回写到APPL_DB状态，服务"
"就会监听APPL_DB的变化，而不是STATE_DB了。）\n"
"- **ASIC_DB**：ID为1，存储着**SONiC想要交换机ASIC达到状态信息**，比如，ACL，"
"转发方式等等。和APPL_DB不同，这个数据库里面的数据模型是面向ASIC设计的，而不是"
"面向服务抽象的。这样做的目的是为了方便各个厂商进行SAI和ASIC驱动的开发。"
msgstr ""
"- **CONFIG_DB**：ID为4，存储所有服务的**配置信息**，比如端口配置，VLAN配置等"
"等。它代表着**用户想要交换机达到的状态**的数据模型，这也是所有CLI和外部应用程"
"序修改配置时的主要操作对象。\n"
"- **APPL_DB（Application DB）**：ID为0，存储**所有服务的内部状态信息**。这些"
"信息有两种：一种是各个服务在读取了CONFIG_DB的配置信息后，自己计算出来的。我们"
"可以理解为**各个服务想要交换机达到的状态**（Goal State），还有一种是当最终硬"
"件状态发生变化被写回时，有些服务会直接写回到APPL_DB，而不是我们下面马上要介绍"
"的STATE_DB。这些信息我们可以理解为**各个服务认为交换机当前的状态**（Current "
"State）。\n"
"- **STATE_DB**：ID为6，存储着交换机**各个部件当前的状态**（Current State）。"
"当SONiC中的服务收到了STATE_DB的状态变化，但是发现和Goal State不一致的时候，"
"SONiC就会重新下发配置，直到两者一致。（当然，对于那些回写到APPL_DB状态，服务"
"就会监听APPL_DB的变化，而不是STATE_DB了。）\n"
"- **ASIC_DB**：ID为1，存储着**SONiC想要交换机ASIC达到状态信息**，比如，ACL，"
"转发方式等等。和APPL_DB不同，这个数据库里面的数据模型是面向ASIC设计的，而不是"
"面向服务抽象的。这样做的目的是为了方便各个厂商进行SAI和ASIC驱动的开发。"

#: src/2-1-database.md:45
msgid ""
"这里，我们会发现一个很直观的问题：交换机里面这么多服务，难道所有的配置和状态"
"都放在一个数据库里面没有隔离的么？如果两个服务用了同一个Redis Key怎么办呢？这"
"个问题非常的好，SONiC的解决也很直接，那就是在每个数据库里面继续分表！"
msgstr ""
"这里，我们会发现一个很直观的问题：交换机里面这么多服务，难道所有的配置和状态"
"都放在一个数据库里面没有隔离的么？如果两个服务用了同一个Redis Key怎么办呢？这"
"个问题非常的好，SONiC的解决也很直接，那就是在每个数据库里面继续分表！"

#: src/2-1-database.md:47
msgid ""
"我们知道Redis在每个数据库里面并没有表的概念，而是使用key-value的方式来存储数"
"据。所以，为了进一步分表，SONiC的解决方法是将表的名字放入key中，并且使用分隔"
"符将表和key隔开。上面的配置文件中`separator`字段就是做这个了。比如：`APPL_DB`"
"中的`PORT_TABLE`表中的`Ethernet4`端口的状态，我们可以通过`PORT_TABLE:"
"Ethernet4`来获取，如下："
msgstr ""
"我们知道Redis在每个数据库里面并没有表的概念，而是使用key-value的方式来存储数"
"据。所以，为了进一步分表，SONiC的解决方法是将表的名字放入key中，并且使用分隔"
"符将表和key隔开。上面的配置文件中`separator`字段就是做这个了。比如：`APPL_DB`"
"中的`PORT_TABLE`表中的`Ethernet4`端口的状态，我们可以通过`PORT_TABLE:"
"Ethernet4`来获取，如下："

#: src/2-1-database.md:49
msgid ""
"```bash\n"
"127.0.0.1:6379> select 0\n"
"OK\n"
"\n"
"127.0.0.1:6379> hgetall PORT_TABLE:Ethernet4\n"
" 1) \"admin_status\"\n"
" 2) \"up\"\n"
" 3) \"alias\"\n"
" 4) \"Ethernet6/1\"\n"
" 5) \"index\"\n"
" 6) \"6\"\n"
" 7) \"lanes\"\n"
" 8) \"13,14,15,16\"\n"
" 9) \"mtu\"\n"
"10) \"9100\"\n"
"11) \"speed\"\n"
"12) \"40000\"\n"
"13) \"description\"\n"
"14) \"\"\n"
"15) \"oper_status\"\n"
"16) \"up\"\n"
"```"
msgstr ""
"```bash\n"
"127.0.0.1:6379> select 0\n"
"OK\n"
"\n"
"127.0.0.1:6379> hgetall PORT_TABLE:Ethernet4\n"
" 1) \"admin_status\"\n"
" 2) \"up\"\n"
" 3) \"alias\"\n"
" 4) \"Ethernet6/1\"\n"
" 5) \"index\"\n"
" 6) \"6\"\n"
" 7) \"lanes\"\n"
" 8) \"13,14,15,16\"\n"
" 9) \"mtu\"\n"
"10) \"9100\"\n"
"11) \"speed\"\n"
"12) \"40000\"\n"
"13) \"description\"\n"
"14) \"\"\n"
"15) \"oper_status\"\n"
"16) \"up\"\n"
"```"

#: src/2-1-database.md:72
msgid ""
"当然在SONiC中，不仅仅是数据模型，包括通信机制，都是使用类似的方法来实现“表”级"
"别的隔离的。"
msgstr ""
"当然在SONiC中，不仅仅是数据模型，包括通信机制，都是使用类似的方法来实现“表”级"
"别的隔离的。"

#: src/2-1-database.md:76 src/2-2-services-intro.md:76
msgid "1. [SONiC Architecture][SONiCArch]"
msgstr "1. [SONiC Architecture][SONiCArch]"

#: src/2-2-services-intro.md:1
msgid "# 服务与控制流"
msgstr "# 服务与控制流"

#: src/2-2-services-intro.md:3
msgid ""
"SONiC里面的服务（常驻进程）非常的多，有二三十种，它们会在随着交换机启动而启"
"动，并一直保持运行，直到交换机关机。如果我们想快速掌握SONiC，一个一个服务的去"
"了解，会很容易陷入细节的泥潭，所以，我们最好把这些服务和控制流进行一个大的分"
"类，以帮助我们建立一个宏观的概念。"
msgstr ""
"SONiC里面的服务（常驻进程）非常的多，有二三十种，它们会在随着交换机启动而启"
"动，并一直保持运行，直到交换机关机。如果我们想快速掌握SONiC，一个一个服务的去"
"了解，会很容易陷入细节的泥潭，所以，我们最好把这些服务和控制流进行一个大的分"
"类，以帮助我们建立一个宏观的概念。"

#: src/2-2-services-intro.md:5
msgid ""
"```admonish note\n"
"我们这里不会深入到某一个具体的服务中去，而是先从整体上来看看SONiC中的服务的结"
"构，帮助我们建立一个整体的认识。关于具体的服务，我们会在工作流一章中，对常用"
"的工作流进行介绍，而关于详细的技术细节，大家也可以查阅每个服务相关的设计文"
"档。\n"
"```"
msgstr ""
"```admonish note\n"
"我们这里不会深入到某一个具体的服务中去，而是先从整体上来看看SONiC中的服务的结"
"构，帮助我们建立一个整体的认识。关于具体的服务，我们会在工作流一章中，对常用"
"的工作流进行介绍，而关于详细的技术细节，大家也可以查阅每个服务相关的设计文"
"档。\n"
"```"

#: src/2-2-services-intro.md:9
msgid "## 服务分类"
msgstr "## 服务分类"

#: src/2-2-services-intro.md:11
msgid ""
"总体而言，SONiC中的服务可以分为以下几类：`*syncd`, `*mgrd`，feature实现，"
"`orchagent`和`syncd`。"
msgstr ""
"总体而言，SONiC中的服务可以分为以下几类：`*syncd`, `*mgrd`，feature实现，"
"`orchagent`和`syncd`。"

#: src/2-2-services-intro.md:13
msgid "### `*syncd`服务"
msgstr "### `*syncd`服务"

#: src/2-2-services-intro.md:15
msgid ""
"这类服务名字中都以`syncd`结尾。它们做的事情都很类似：它们负责将硬件状态同步到"
"Redis中，一般目标都以APPL_DB或者STATE_DB为主。"
msgstr ""
"这类服务名字中都以`syncd`结尾。它们做的事情都很类似：它们负责将硬件状态同步到"
"Redis中，一般目标都以APPL_DB或者STATE_DB为主。"

#: src/2-2-services-intro.md:17
msgid ""
"比如，`portsyncd`就是通过监听netlink的事件，将交换机中所有Port的状态同步到"
"STATE_DB中，而`natsyncd`则是监听netlink的事件，将交换机中所有的NAT状态同步到"
"APPL_DB中。"
msgstr ""
"比如，`portsyncd`就是通过监听netlink的事件，将交换机中所有Port的状态同步到"
"STATE_DB中，而`natsyncd`则是监听netlink的事件，将交换机中所有的NAT状态同步到"
"APPL_DB中。"

#: src/2-2-services-intro.md:19
msgid "### `*mgrd`服务"
msgstr "### `*mgrd`服务"

#: src/2-2-services-intro.md:21
msgid ""
"这类服务名字中都以`mgrd`结尾。顾名思义，这些服务是所谓的“Manager”服务，也就是"
"说它们负责各个硬件的配置，和`*syncd`完全相反。它们的逻辑主要有两个部分："
msgstr ""
"这类服务名字中都以`mgrd`结尾。顾名思义，这些服务是所谓的“Manager”服务，也就是"
"说它们负责各个硬件的配置，和`*syncd`完全相反。它们的逻辑主要有两个部分："

#: src/2-2-services-intro.md:23
msgid ""
"1. **配置下发**：负责读取配置文件和监听Redis中的配置和状态改变（主要是"
"CONFIG_DB，APPL_DB和STATE_DB），然后将这些修改推送到交换机硬件中去。推送的方"
"法有多种，取决于更新的目标是什么，可以通过更新APPL_DB并发布更新消息，或者是直"
"接调用linux下的命令行，对系统进行修改。比如：`nbrmgr`就是监听CONFIG_DB，"
"APPL_DB和STATE_DB中neighbor的变化，并调用netlink和command line来对neighbor和"
"route进行修改，而`intfmgr`除了调用command line还会将一些状态更新到APPL_DB中"
"去。\n"
"2. **状态同步**：对于需要Reconcile的服务，`*mgrd`还会监听STATE_DB中的状态变"
"化，如果发现硬件状态和当前期望状态不一致，就会重新发起配置流程，将硬件状态设"
"置为期望状态。这些STATE_DB中的状态变化一般都是`*syncd`服务推送的。比如："
"`intfmgr`就会监听STATE_DB中，由`portsyncd`推送的，端口的Up/Down状态和MTU变"
"化，一旦发现和其内存中保存的期望状态不一致，就会重新下发配置。"
msgstr ""
"1. **配置下发**：负责读取配置文件和监听Redis中的配置和状态改变（主要是"
"CONFIG_DB，APPL_DB和STATE_DB），然后将这些修改推送到交换机硬件中去。推送的方"
"法有多种，取决于更新的目标是什么，可以通过更新APPL_DB并发布更新消息，或者是直"
"接调用linux下的命令行，对系统进行修改。比如：`nbrmgr`就是监听CONFIG_DB，"
"APPL_DB和STATE_DB中neighbor的变化，并调用netlink和command line来对neighbor和"
"route进行修改，而`intfmgr`除了调用command line还会将一些状态更新到APPL_DB中"
"去。\n"
"2. **状态同步**：对于需要Reconcile的服务，`*mgrd`还会监听STATE_DB中的状态变"
"化，如果发现硬件状态和当前期望状态不一致，就会重新发起配置流程，将硬件状态设"
"置为期望状态。这些STATE_DB中的状态变化一般都是`*syncd`服务推送的。比如："
"`intfmgr`就会监听STATE_DB中，由`portsyncd`推送的，端口的Up/Down状态和MTU变"
"化，一旦发现和其内存中保存的期望状态不一致，就会重新下发配置。"

#: src/2-2-services-intro.md:26
msgid "### 功能实现服务"
msgstr "### 功能实现服务"

#: src/2-2-services-intro.md:28
msgid ""
"有一些功能并不是依靠OS本身来完成的，而是由一些特定的进程来实现的，比如BGP，或"
"者一些外部接口。这些服务名字中经常以`d`结尾，表示deamon，比如：`bgpd`，"
"`lldpd`，`snmpd`，`teamd`等，或者干脆就是这个功能的名字，比如：`fancontrol`。"
msgstr ""
"有一些功能并不是依靠OS本身来完成的，而是由一些特定的进程来实现的，比如BGP，或"
"者一些外部接口。这些服务名字中经常以`d`结尾，表示deamon，比如：`bgpd`，"
"`lldpd`，`snmpd`，`teamd`等，或者干脆就是这个功能的名字，比如：`fancontrol`。"

#: src/2-2-services-intro.md:30
msgid "### `orchagent`服务"
msgstr "### `orchagent`服务"

#: src/2-2-services-intro.md:32
msgid ""
"这个是SONiC中最重要的一个服务，不像其他的服务只负责一两个特定的功能，"
"`orchagent`作为交换机ASIC状态的编排者（orchestrator），会检查数据库中所有来自"
"`*syncd`服务的状态，整合起来并下发给用于保存交换机ASIC配置的数据库：ASIC_DB。"
"这些状态最后会被`syncd`接收，并调用SAI API经过各个厂商提供的SAI实现和ASIC SDK"
"和ASIC进行交互，最终将配置下发到交换机硬件中。"
msgstr ""
"这个是SONiC中最重要的一个服务，不像其他的服务只负责一两个特定的功能，"
"`orchagent`作为交换机ASIC状态的编排者（orchestrator），会检查数据库中所有来自"
"`*syncd`服务的状态，整合起来并下发给用于保存交换机ASIC配置的数据库：ASIC_DB。"
"这些状态最后会被`syncd`接收，并调用SAI API经过各个厂商提供的SAI实现和ASIC SDK"
"和ASIC进行交互，最终将配置下发到交换机硬件中。"

#: src/2-2-services-intro.md:34
msgid "### `syncd`服务"
msgstr "### `syncd`服务"

#: src/2-2-services-intro.md:36
msgid ""
"`syncd`服务是`orchagent`的下游，它虽然名字叫`syncd`，但是它却同时肩负着ASIC的"
"`*mgrd`和`*syncd`的工作。"
msgstr ""
"`syncd`服务是`orchagent`的下游，它虽然名字叫`syncd`，但是它却同时肩负着ASIC的"
"`*mgrd`和`*syncd`的工作。"

#: src/2-2-services-intro.md:38
msgid ""
"- 首先，作为`*mgrd`，它会监听ASIC_DB的状态变化，一旦发现，就会获取其新的状态"
"并调用SAI API，将配置下发到交换机硬件中。\n"
"- 然后，作为`*syncd`，如果ASIC发送了任何的通知给SONiC，它也会将这些通知通过消"
"息的方式发送到Redis中，以便`orchagent`和`*mgrd`服务获取到这些变化，并进行处"
"理。这些通知的类型我们可以在[SwitchNotifications.h][SAISwitchNotify]中找到。"
msgstr ""
"- 首先，作为`*mgrd`，它会监听ASIC_DB的状态变化，一旦发现，就会获取其新的状态"
"并调用SAI API，将配置下发到交换机硬件中。\n"
"- 然后，作为`*syncd`，如果ASIC发送了任何的通知给SONiC，它也会将这些通知通过消"
"息的方式发送到Redis中，以便`orchagent`和`*mgrd`服务获取到这些变化，并进行处"
"理。这些通知的类型我们可以在[SwitchNotifications.h][SAISwitchNotify]中找到。"

#: src/2-2-services-intro.md:41
msgid "## 服务间控制流分类"
msgstr "## 服务间控制流分类"

#: src/2-2-services-intro.md:43
msgid ""
"有了这些分类，我们就可以更加清晰的来理解SONiC中的服务了，而其中非常重要的就是"
"理解服务之间的控制流。有了上面的分类，我们这里也可以把主要的控制流有分为两"
"类：配置下发和状态同步。"
msgstr ""
"有了这些分类，我们就可以更加清晰的来理解SONiC中的服务了，而其中非常重要的就是"
"理解服务之间的控制流。有了上面的分类，我们这里也可以把主要的控制流有分为两"
"类：配置下发和状态同步。"

#: src/2-2-services-intro.md:45
msgid "### 配置下发"
msgstr "### 配置下发"

#: src/2-2-services-intro.md:47
msgid "配置下发的流程一般是这样的："
msgstr "配置下发的流程一般是这样的："

#: src/2-2-services-intro.md:49
msgid ""
"1. **修改配置**：用户可以通过CLI或者REST API修改配置，这些配置会被写入到"
"CONFIG_DB中并通过Redis发送更新通知。或者外部程序可以通过特定的接口，比如BGP的"
"API，来修改配置，这种配置会通过内部的TCP Socket发送给`*mgrd`服务。\n"
"2. **`*mgrd`下发配置**：服务监听到CONFIG_DB中的配置变化，然后将这些配置推送到"
"交换机硬件中。这里由两种主要情况（并且可以同时存在）：\n"
"   1. **直接下发**：\n"
"      1. `*mgrd`服务直接调用linux下的命令行，或者是通过netlink来修改系统配"
"置\n"
"      2. `*syncd`服务会通过netlink或者其他方式监听到系统配置的变化，并将这些"
"变化推送到STATE_DB或者APPL_DB中。\n"
"      3. `*mgrd`服务监听到STATE_DB或者APPL_DB中的配置变化，然后将这些配置和其"
"内存中存储的配置进行比较，如果发现不一致，就会重新调用命令行或者netlink来修改"
"系统配置，直到它们一致为止。\n"
"   2. **间接下发**：\n"
"      1. `*mgrd`将状态推送到APPL_DB并通过Redis发送更新通知。\n"
"      2. `orchagent`服务监听到配置变化，然后根据所有相关的状态，计算出此时"
"ASIC应该达到的状态，并下发到ASIC_DB中。\n"
"      3. `syncd`服务监听到ASIC_DB的变化，然后将这些新的配置通过统一的SAI API"
"接口，调用ASIC Driver更新交换机ASIC中的配置。"
msgstr ""
"1. **修改配置**：用户可以通过CLI或者REST API修改配置，这些配置会被写入到"
"CONFIG_DB中并通过Redis发送更新通知。或者外部程序可以通过特定的接口，比如BGP的"
"API，来修改配置，这种配置会通过内部的TCP Socket发送给`*mgrd`服务。\n"
"2. **`*mgrd`下发配置**：服务监听到CONFIG_DB中的配置变化，然后将这些配置推送到"
"交换机硬件中。这里由两种主要情况（并且可以同时存在）：\n"
"   1. **直接下发**：\n"
"      1. `*mgrd`服务直接调用linux下的命令行，或者是通过netlink来修改系统配"
"置\n"
"      2. `*syncd`服务会通过netlink或者其他方式监听到系统配置的变化，并将这些"
"变化推送到STATE_DB或者APPL_DB中。\n"
"      3. `*mgrd`服务监听到STATE_DB或者APPL_DB中的配置变化，然后将这些配置和其"
"内存中存储的配置进行比较，如果发现不一致，就会重新调用命令行或者netlink来修改"
"系统配置，直到它们一致为止。\n"
"   2. **间接下发**：\n"
"      1. `*mgrd`将状态推送到APPL_DB并通过Redis发送更新通知。\n"
"      2. `orchagent`服务监听到配置变化，然后根据所有相关的状态，计算出此时"
"ASIC应该达到的状态，并下发到ASIC_DB中。\n"
"      3. `syncd`服务监听到ASIC_DB的变化，然后将这些新的配置通过统一的SAI API"
"接口，调用ASIC Driver更新交换机ASIC中的配置。"

#: src/2-2-services-intro.md:60
msgid ""
"配置初始化和配置下发类似，不过是在服务启动的时候读取配置文件，这里就不展开"
"了。"
msgstr ""
"配置初始化和配置下发类似，不过是在服务启动的时候读取配置文件，这里就不展开"
"了。"

#: src/2-2-services-intro.md:62
msgid "### 状态同步"
msgstr "### 状态同步"

#: src/2-2-services-intro.md:64
msgid ""
"如果这个时候，出现了一些情况，比如网口坏了，ASIC中的状态变了等等，这个时候我"
"们就需要进行状态更新和同步了。这个流程一般是这样的："
msgstr ""
"如果这个时候，出现了一些情况，比如网口坏了，ASIC中的状态变了等等，这个时候我"
"们就需要进行状态更新和同步了。这个流程一般是这样的："

#: src/2-2-services-intro.md:66
msgid ""
"1. **检测状态变化**：这个状态变化主要来源于`*syncd`服务（netlink等等）和"
"`syncd`服务（[SAI Switch Notification][SAISwitchNotify]），这些服务在检测到变"
"化后，会将它们发送给STATE_DB或者APPL_DB。\n"
"2. **处理状态变化**：`orchagent`和`*mgrd`服务会监听到这些变化，然后开始处理，"
"将新的配置重新通过命令行和netlink下发给系统，或者下发到ASIC_DB中，让`syncd`服"
"务再次对ASIC进行更新。"
msgstr ""
"1. **检测状态变化**：这个状态变化主要来源于`*syncd`服务（netlink等等）和"
"`syncd`服务（[SAI Switch Notification][SAISwitchNotify]），这些服务在检测到变"
"化后，会将它们发送给STATE_DB或者APPL_DB。\n"
"2. **处理状态变化**：`orchagent`和`*mgrd`服务会监听到这些变化，然后开始处理，"
"将新的配置重新通过命令行和netlink下发给系统，或者下发到ASIC_DB中，让`syncd`服"
"务再次对ASIC进行更新。"

#: src/2-2-services-intro.md:69
msgid "### 具体例子"
msgstr "### 具体例子"

#: src/2-2-services-intro.md:71
msgid ""
"SONiC的官方文档中给出了几个典型的控制流流转的例子，这里就不过多的展开了，有兴"
"趣的朋友可以去这里看看：[SONiC Subsystem Interactions](https://github.com/"
"sonic-net/SONiC/wiki/Architecture#sonic-subsystems-interactions)。我们在后面"
"工作流一章中，也会选择一些非常常用的工作流进行展开。"
msgstr ""
"SONiC的官方文档中给出了几个典型的控制流流转的例子，这里就不过多的展开了，有兴"
"趣的朋友可以去这里看看：[SONiC Subsystem Interactions](https://github.com/"
"sonic-net/SONiC/wiki/Architecture#sonic-subsystems-interactions)。我们在后面"
"工作流一章中，也会选择一些非常常用的工作流进行展开。"

#: src/2-3-key-containers.md:1
msgid "# 核心容器"
msgstr "# 核心容器"

#: src/2-3-key-containers.md:3
msgid "SONiC的设计中最具特色的地方：容器化。"
msgstr "SONiC的设计中最具特色的地方：容器化。"

#: src/2-3-key-containers.md:5
msgid ""
"从SONiC的上面的设计图中，我们可以看出来，SONiC中，所有的服务都是以容器的形式"
"存在的。在登录进交换机之后，我们可以通过`docker ps`命令来查看当前运行的容器："
msgstr ""
"从SONiC的上面的设计图中，我们可以看出来，SONiC中，所有的服务都是以容器的形式"
"存在的。在登录进交换机之后，我们可以通过`docker ps`命令来查看当前运行的容器："

#: src/2-3-key-containers.md:7
msgid ""
"```bash\n"
"admin@sonic:~$ docker ps\n"
"CONTAINER ID   IMAGE                                COMMAND                  "
"CREATED      STATUS        PORTS     NAMES\n"
"ddf09928ec58   docker-snmp:latest                   \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             snmp\n"
"c480f3cf9dd7   docker-sonic-mgmt-framework:latest   \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             mgmt-framework\n"
"3655aff31161   docker-lldp:latest                   \"/usr/bin/docker-lld…"
"\"   2 days ago   Up 32 hours             lldp\n"
"78f0b12ed10e   docker-platform-monitor:latest       \"/usr/bin/docker_ini…"
"\"   2 days ago   Up 32 hours             pmon\n"
"f9d9bcf6c9a6   docker-router-advertiser:latest      \"/usr/bin/docker-ini…"
"\"   2 days ago   Up 32 hours             radv\n"
"2e5dbee95844   docker-fpm-frr:latest                \"/usr/bin/docker_ini…"
"\"   2 days ago   Up 32 hours             bgp\n"
"bdfa58009226   docker-syncd-brcm:latest             \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             syncd\n"
"655e550b7a1b   docker-teamd:latest                  \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             teamd\n"
"1bd55acc181c   docker-orchagent:latest              \"/usr/bin/docker-ini…"
"\"   2 days ago   Up 32 hours             swss\n"
"bd20649228c8   docker-eventd:latest                 \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             eventd\n"
"b2f58447febb   docker-database:latest               \"/usr/local/bin/dock…"
"\"   2 days ago   Up 32 hours             database\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ docker ps\n"
"CONTAINER ID   IMAGE                                COMMAND                  "
"CREATED      STATUS        PORTS     NAMES\n"
"ddf09928ec58   docker-snmp:latest                   \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             snmp\n"
"c480f3cf9dd7   docker-sonic-mgmt-framework:latest   \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             mgmt-framework\n"
"3655aff31161   docker-lldp:latest                   \"/usr/bin/docker-lld…"
"\"   2 days ago   Up 32 hours             lldp\n"
"78f0b12ed10e   docker-platform-monitor:latest       \"/usr/bin/docker_ini…"
"\"   2 days ago   Up 32 hours             pmon\n"
"f9d9bcf6c9a6   docker-router-advertiser:latest      \"/usr/bin/docker-ini…"
"\"   2 days ago   Up 32 hours             radv\n"
"2e5dbee95844   docker-fpm-frr:latest                \"/usr/bin/docker_ini…"
"\"   2 days ago   Up 32 hours             bgp\n"
"bdfa58009226   docker-syncd-brcm:latest             \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             syncd\n"
"655e550b7a1b   docker-teamd:latest                  \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             teamd\n"
"1bd55acc181c   docker-orchagent:latest              \"/usr/bin/docker-ini…"
"\"   2 days ago   Up 32 hours             swss\n"
"bd20649228c8   docker-eventd:latest                 \"/usr/local/bin/supe…"
"\"   2 days ago   Up 32 hours             eventd\n"
"b2f58447febb   docker-database:latest               \"/usr/local/bin/dock…"
"\"   2 days ago   Up 32 hours             database\n"
"```"

#: src/2-3-key-containers.md:23
msgid "这里我们来简单介绍一下这些容器。"
msgstr "这里我们来简单介绍一下这些容器。"

#: src/2-3-key-containers.md:25
msgid "## 数据库容器：database"
msgstr "## 数据库容器：database"

#: src/2-3-key-containers.md:27
msgid ""
"这个容器中运行的就是我们多次提到的SONiC中的中心数据库Redis了，它里面存放着所"
"有交换机的配置和状态信息，SONiC也是主要通过它来向各个服务提供底层的通信机制。"
msgstr ""
"这个容器中运行的就是我们多次提到的SONiC中的中心数据库Redis了，它里面存放着所"
"有交换机的配置和状态信息，SONiC也是主要通过它来向各个服务提供底层的通信机制。"

#: src/2-3-key-containers.md:29
msgid "我们通过docker进入这个容器，就可以看到里面正在运行的redis进程了："
msgstr "我们通过docker进入这个容器，就可以看到里面正在运行的redis进程了："

#: src/2-3-key-containers.md:31
msgid ""
"```bash\n"
"admin@sonic:~$ sudo docker exec -it database bash\n"
"\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          82 13.7  1.7 130808 71692 pts/0    Sl   Apr26 393:27 /usr/bin/"
"redis-server 127.0.0.1:6379\n"
"...\n"
"\n"
"root@sonic:/# cat /var/run/redis/redis.pid\n"
"82\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ sudo docker exec -it database bash\n"
"\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          82 13.7  1.7 130808 71692 pts/0    Sl   Apr26 393:27 /usr/bin/"
"redis-server 127.0.0.1:6379\n"
"...\n"
"\n"
"root@sonic:/# cat /var/run/redis/redis.pid\n"
"82\n"
"```"

#: src/2-3-key-containers.md:44
msgid ""
"那么别的容器是如何来访问这个Redis数据库的呢？答案是通过Unix Socket。我们可以"
"在database容器中看到这个Unix Socket，它将交换机上的`/var/run/redis`目录map进"
"database容器，让database容器可以创建这个socket："
msgstr ""
"那么别的容器是如何来访问这个Redis数据库的呢？答案是通过Unix Socket。我们可以"
"在database容器中看到这个Unix Socket，它将交换机上的`/var/run/redis`目录map进"
"database容器，让database容器可以创建这个socket："

#: src/2-3-key-containers.md:46
msgid ""
"```bash\n"
"# In database container\n"
"root@sonic:/# ls /var/run/redis\n"
"redis.pid  redis.sock  sonic-db\n"
"\n"
"# On host\n"
"admin@sonic:~$ ls /var/run/redis\n"
"redis.pid  redis.sock  sonic-db\n"
"```"
msgstr ""
"```bash\n"
"# In database container\n"
"root@sonic:/# ls /var/run/redis\n"
"redis.pid  redis.sock  sonic-db\n"
"\n"
"# On host\n"
"admin@sonic:~$ ls /var/run/redis\n"
"redis.pid  redis.sock  sonic-db\n"
"```"

#: src/2-3-key-containers.md:56
msgid ""
"然后再将这个socket给map到其他的容器中，这样所有容器就都可以来访问这个中心数据"
"库啦，比如，swss容器："
msgstr ""
"然后再将这个socket给map到其他的容器中，这样所有容器就都可以来访问这个中心数据"
"库啦，比如，swss容器："

#: src/2-3-key-containers.md:58
msgid ""
"```bash\n"
"admin@sonic:~$ docker inspect swss\n"
"...\n"
"        \"HostConfig\": {\n"
"            \"Binds\": [\n"
"                ...\n"
"                \"/var/run/redis:/var/run/redis:rw\",\n"
"                ...\n"
"            ],\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ docker inspect swss\n"
"...\n"
"        \"HostConfig\": {\n"
"            \"Binds\": [\n"
"                ...\n"
"                \"/var/run/redis:/var/run/redis:rw\",\n"
"                ...\n"
"            ],\n"
"...\n"
"```"

#: src/2-3-key-containers.md:70
msgid "## 交换机状态管理容器：swss（Switch State Service）"
msgstr "## 交换机状态管理容器：swss（Switch State Service）"

#: src/2-3-key-containers.md:72
msgid ""
"这个容器可以说是SONiC中最关键的容器了，**它是SONiC的大脑**，里面运行着大量的"
"`*syncd`和`*mgrd`服务，用来管理交换机方方面面的配置，比如Port，neighbor，"
"ARP，VLAN，Tunnel等等等等。另外里面还运行着上面提到的`orchagent`，用来统一处"
"理和ASIC相关的配置和状态变化。"
msgstr ""
"这个容器可以说是SONiC中最关键的容器了，**它是SONiC的大脑**，里面运行着大量的"
"`*syncd`和`*mgrd`服务，用来管理交换机方方面面的配置，比如Port，neighbor，"
"ARP，VLAN，Tunnel等等等等。另外里面还运行着上面提到的`orchagent`，用来统一处"
"理和ASIC相关的配置和状态变化。"

#: src/2-3-key-containers.md:74
msgid ""
"这些服务大概的功能和流程我们上面已经提过了，所以就不再赘述了。这里我们可以通"
"过`ps`命令来看一下这个容器中运行的服务："
msgstr ""
"这些服务大概的功能和流程我们上面已经提过了，所以就不再赘述了。这里我们可以通"
"过`ps`命令来看一下这个容器中运行的服务："

#: src/2-3-key-containers.md:76
msgid ""
"```bash\n"
"admin@sonic:~$ docker exec -it swss bash\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          43  0.0  0.2  91016  9688 pts/0    Sl   Apr26   0:18 /usr/bin/"
"portsyncd\n"
"root          49  0.1  0.6 558420 27592 pts/0    Sl   Apr26   4:31 /usr/bin/"
"orchagent -d /var/log/swss -b 8192 -s -m 00:1c:73:f2:bc:b4\n"
"root          74  0.0  0.2  91240  9776 pts/0    Sl   Apr26   0:19 /usr/bin/"
"coppmgrd\n"
"root          93  0.0  0.0   4400  3432 pts/0    S    Apr26   0:09 /bin/"
"bash /usr/bin/arp_update\n"
"root          94  0.0  0.2  91008  8568 pts/0    Sl   Apr26   0:09 /usr/bin/"
"neighsyncd\n"
"root          96  0.0  0.2  91168  9800 pts/0    Sl   Apr26   0:19 /usr/bin/"
"vlanmgrd\n"
"root          99  0.0  0.2  91320  9848 pts/0    Sl   Apr26   0:20 /usr/bin/"
"intfmgrd\n"
"root         103  0.0  0.2  91136  9708 pts/0    Sl   Apr26   0:19 /usr/bin/"
"portmgrd\n"
"root         104  0.0  0.2  91380  9844 pts/0    Sl   Apr26   0:20 /usr/bin/"
"buffermgrd -l /usr/share/sonic/hwsku/pg_profile_lookup.ini\n"
"root         107  0.0  0.2  91284  9836 pts/0    Sl   Apr26   0:20 /usr/bin/"
"vrfmgrd\n"
"root         109  0.0  0.2  91040  8600 pts/0    Sl   Apr26   0:19 /usr/bin/"
"nbrmgrd\n"
"root         110  0.0  0.2  91184  9724 pts/0    Sl   Apr26   0:19 /usr/bin/"
"vxlanmgrd\n"
"root         112  0.0  0.2  90940  8804 pts/0    Sl   Apr26   0:09 /usr/bin/"
"fdbsyncd\n"
"root         113  0.0  0.2  91140  9656 pts/0    Sl   Apr26   0:20 /usr/bin/"
"tunnelmgrd\n"
"root         208  0.0  0.0   5772  1636 pts/0    S    Apr26   0:07 /usr/sbin/"
"ndppd\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ docker exec -it swss bash\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          43  0.0  0.2  91016  9688 pts/0    Sl   Apr26   0:18 /usr/bin/"
"portsyncd\n"
"root          49  0.1  0.6 558420 27592 pts/0    Sl   Apr26   4:31 /usr/bin/"
"orchagent -d /var/log/swss -b 8192 -s -m 00:1c:73:f2:bc:b4\n"
"root          74  0.0  0.2  91240  9776 pts/0    Sl   Apr26   0:19 /usr/bin/"
"coppmgrd\n"
"root          93  0.0  0.0   4400  3432 pts/0    S    Apr26   0:09 /bin/"
"bash /usr/bin/arp_update\n"
"root          94  0.0  0.2  91008  8568 pts/0    Sl   Apr26   0:09 /usr/bin/"
"neighsyncd\n"
"root          96  0.0  0.2  91168  9800 pts/0    Sl   Apr26   0:19 /usr/bin/"
"vlanmgrd\n"
"root          99  0.0  0.2  91320  9848 pts/0    Sl   Apr26   0:20 /usr/bin/"
"intfmgrd\n"
"root         103  0.0  0.2  91136  9708 pts/0    Sl   Apr26   0:19 /usr/bin/"
"portmgrd\n"
"root         104  0.0  0.2  91380  9844 pts/0    Sl   Apr26   0:20 /usr/bin/"
"buffermgrd -l /usr/share/sonic/hwsku/pg_profile_lookup.ini\n"
"root         107  0.0  0.2  91284  9836 pts/0    Sl   Apr26   0:20 /usr/bin/"
"vrfmgrd\n"
"root         109  0.0  0.2  91040  8600 pts/0    Sl   Apr26   0:19 /usr/bin/"
"nbrmgrd\n"
"root         110  0.0  0.2  91184  9724 pts/0    Sl   Apr26   0:19 /usr/bin/"
"vxlanmgrd\n"
"root         112  0.0  0.2  90940  8804 pts/0    Sl   Apr26   0:09 /usr/bin/"
"fdbsyncd\n"
"root         113  0.0  0.2  91140  9656 pts/0    Sl   Apr26   0:20 /usr/bin/"
"tunnelmgrd\n"
"root         208  0.0  0.0   5772  1636 pts/0    S    Apr26   0:07 /usr/sbin/"
"ndppd\n"
"...\n"
"```"

#: src/2-3-key-containers.md:99
msgid "## ASIC管理容器：syncd"
msgstr "## ASIC管理容器：syncd"

#: src/2-3-key-containers.md:101
msgid ""
"这个容器中主要是用于管理交换机上的ASIC的，里面运行着`syncd`服务。我们之前提到"
"的各个厂商提供的SAI（Switch Abstraction Interface）和ASIC Driver都是放在这个"
"容器中的。正是因为这个容器的存在，才使得SONiC可以支持多种不同的ASIC，而不需要"
"修改上层的服务。换句话说，如果没有这个容器，那SONiC就是一个缸中大脑，除了一些"
"基本的配置，其他只能靠想的，什么都干不了。"
msgstr ""
"这个容器中主要是用于管理交换机上的ASIC的，里面运行着`syncd`服务。我们之前提到"
"的各个厂商提供的SAI（Switch Abstraction Interface）和ASIC Driver都是放在这个"
"容器中的。正是因为这个容器的存在，才使得SONiC可以支持多种不同的ASIC，而不需要"
"修改上层的服务。换句话说，如果没有这个容器，那SONiC就是一个缸中大脑，除了一些"
"基本的配置，其他只能靠想的，什么都干不了。"

#: src/2-3-key-containers.md:103
msgid ""
"在syncd容器中运行的服务并不多，就是syncd，我们可以通过`ps`命令来查看，而在`/"
"usr/lib`目录下，我们也可以找到这个为了支持ASIC而编译出来的巨大无比的SAI文件："
msgstr ""
"在syncd容器中运行的服务并不多，就是syncd，我们可以通过`ps`命令来查看，而在`/"
"usr/lib`目录下，我们也可以找到这个为了支持ASIC而编译出来的巨大无比的SAI文件："

#: src/2-3-key-containers.md:105
msgid ""
"```bash\n"
"admin@sonic:~$ docker exec -it syncd bash\n"
"\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          20  0.0  0.0  87708  1544 pts/0    Sl   Apr26   0:00 /usr/bin/"
"dsserve /usr/bin/syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"root          32 10.7 14.9 2724404 599408 pts/0  Sl   Apr26 386:49 /usr/bin/"
"syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"...\n"
"\n"
"root@sonic:/# ls -lh /usr/lib\n"
"total 343M\n"
"...\n"
"lrwxrwxrwx 1 root root   13 Apr 25 04:38 libsai.so.1 -> libsai.so.1.0\n"
"-rw-r--r-- 1 root root 343M Feb  1 06:10 libsai.so.1.0\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ docker exec -it syncd bash\n"
"\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          20  0.0  0.0  87708  1544 pts/0    Sl   Apr26   0:00 /usr/bin/"
"dsserve /usr/bin/syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"root          32 10.7 14.9 2724404 599408 pts/0  Sl   Apr26 386:49 /usr/bin/"
"syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"...\n"
"\n"
"root@sonic:/# ls -lh /usr/lib\n"
"total 343M\n"
"...\n"
"lrwxrwxrwx 1 root root   13 Apr 25 04:38 libsai.so.1 -> libsai.so.1.0\n"
"-rw-r--r-- 1 root root 343M Feb  1 06:10 libsai.so.1.0\n"
"...\n"
"```"

#: src/2-3-key-containers.md:123
msgid "## 各种实现特定功能的容器"
msgstr "## 各种实现特定功能的容器"

#: src/2-3-key-containers.md:125
msgid ""
"SONiC中还有很多的容器是为了实现一些特定功能而存在的。这些容器一般都有着特殊的"
"外部接口（非SONiC CLI和REST API）和实现（非OS或ASIC），比如："
msgstr ""
"SONiC中还有很多的容器是为了实现一些特定功能而存在的。这些容器一般都有着特殊的"
"外部接口（非SONiC CLI和REST API）和实现（非OS或ASIC），比如："

#: src/2-3-key-containers.md:127
msgid ""
"- bgp：用来实现BGP协议（Border Gateway Protocol，边界网关协议）的容器\n"
"- lldp：用来实现LLDP协议（Link Layer Discovery Protocol，链路层发现协议）的容"
"器\n"
"- teamd：用来实现Link Aggregation（链路聚合）的容器\n"
"- snmp：用来实现SNMP协议（Simple Network Management Protocol，简单网络管理协"
"议）的容器"
msgstr ""
"- bgp：用来实现BGP协议（Border Gateway Protocol，边界网关协议）的容器\n"
"- lldp：用来实现LLDP协议（Link Layer Discovery Protocol，链路层发现协议）的容"
"器\n"
"- teamd：用来实现Link Aggregation（链路聚合）的容器\n"
"- snmp：用来实现SNMP协议（Simple Network Management Protocol，简单网络管理协"
"议）的容器"

#: src/2-3-key-containers.md:132
msgid ""
"和SWSS类似，为了适应SONiC的架构，它们中间也都会运行着上面我们提到的那几种服"
"务："
msgstr ""
"和SWSS类似，为了适应SONiC的架构，它们中间也都会运行着上面我们提到的那几种服"
"务："

#: src/2-3-key-containers.md:134
msgid ""
"- 配置管理和下发（类似`*mgrd`）：`lldpmgrd`，`zebra`（bgp）\n"
"- 状态同步（类似`*syncd`）：`lldpsyncd`，`fpmsyncd`（bgp），`teamsyncd`\n"
"- 服务实现或者外部接口（`*d`）：`lldpd`，`bgpd`，`teamd`，`snmpd`"
msgstr ""
"- 配置管理和下发（类似`*mgrd`）：`lldpmgrd`，`zebra`（bgp）\n"
"- 状态同步（类似`*syncd`）：`lldpsyncd`，`fpmsyncd`（bgp），`teamsyncd`\n"
"- 服务实现或者外部接口（`*d`）：`lldpd`，`bgpd`，`teamd`，`snmpd`"

#: src/2-3-key-containers.md:138
msgid "## 管理服务容器：mgmt-framework"
msgstr "## 管理服务容器：mgmt-framework"

#: src/2-3-key-containers.md:140
msgid ""
"我们在之前的章节中已经看过如何使用SONiC的CLI来进行一些交换机的配置，但是在实"
"际生产环境中，手动登录交换机使用CLI来配置所有的交换机是不现实的，所以SONiC提"
"供了一个REST API来解决这个问题。这个REST API的实现就是在`mgmt-framework`容器"
"中。我们可以通过`ps`命令来查看："
msgstr ""
"我们在之前的章节中已经看过如何使用SONiC的CLI来进行一些交换机的配置，但是在实"
"际生产环境中，手动登录交换机使用CLI来配置所有的交换机是不现实的，所以SONiC提"
"供了一个REST API来解决这个问题。这个REST API的实现就是在`mgmt-framework`容器"
"中。我们可以通过`ps`命令来查看："

#: src/2-3-key-containers.md:142
msgid ""
"```bash\n"
"admin@sonic:~$ docker exec -it mgmt-framework bash\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          16  0.3  1.2 1472804 52036 pts/0   Sl   16:20   0:02 /usr/sbin/"
"rest_server -ui /rest_ui -logtostderr -cert /tmp/cert.pem -key /tmp/key.pem\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ docker exec -it mgmt-framework bash\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          16  0.3  1.2 1472804 52036 pts/0   Sl   16:20   0:02 /usr/sbin/"
"rest_server -ui /rest_ui -logtostderr -cert /tmp/cert.pem -key /tmp/key.pem\n"
"...\n"
"```"

#: src/2-3-key-containers.md:151
msgid ""
"其实除了REST API，SONiC还可以通过其他方式来进行管理，如gNMI，这些也都是运行在"
"这个容器中的。其整体架构如下图所示 [\\[2\\]][SONiCMgmtFramework]："
msgstr ""
"其实除了REST API，SONiC还可以通过其他方式来进行管理，如gNMI，这些也都是运行在"
"这个容器中的。其整体架构如下图所示 [\\[2\\]][SONiCMgmtFramework]："

#: src/2-3-key-containers.md:155
msgid ""
"这里我们也可以发现，其实我们使用的CLI，底层也是通过调用这个REST API来实现的～"
msgstr ""
"这里我们也可以发现，其实我们使用的CLI，底层也是通过调用这个REST API来实现的～"

#: src/2-3-key-containers.md:157
msgid "## 平台监控容器：pmon（Platform Monitor）"
msgstr "## 平台监控容器：pmon（Platform Monitor）"

#: src/2-3-key-containers.md:159
msgid ""
"这个容器里面的服务基本都是用来监控交换机一些基础硬件的运行状态的，比如温度，"
"电源，风扇，SFP事件等等。同样，我们可以用`ps`命令来查看这个容器中运行的服务："
msgstr ""
"这个容器里面的服务基本都是用来监控交换机一些基础硬件的运行状态的，比如温度，"
"电源，风扇，SFP事件等等。同样，我们可以用`ps`命令来查看这个容器中运行的服务："

#: src/2-3-key-containers.md:161
msgid ""
"```bash\n"
"admin@sonic:~$ docker exec -it pmon bash\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          28  0.0  0.8  49972 33192 pts/0    S    Apr26   0:23 python3 /"
"usr/local/bin/ledd\n"
"root          29  0.9  1.0 278492 43816 pts/0    Sl   Apr26  34:41 python3 /"
"usr/local/bin/xcvrd\n"
"root          30  0.4  1.0  57660 40412 pts/0    S    Apr26  18:41 python3 /"
"usr/local/bin/psud\n"
"root          32  0.0  1.0  57172 40088 pts/0    S    Apr26   0:02 python3 /"
"usr/local/bin/syseepromd\n"
"root          33  0.0  1.0  58648 41400 pts/0    S    Apr26   0:27 python3 /"
"usr/local/bin/thermalctld\n"
"root          34  0.0  1.3  70044 53496 pts/0    S    Apr26   0:46 /usr/bin/"
"python3 /usr/local/bin/pcied\n"
"root          42  0.0  0.0  55320  1136 ?        Ss   Apr26   0:15 /usr/sbin/"
"sensord -f daemon\n"
"root          45  0.0  0.8  58648 32220 pts/0    S    Apr26   2:45 python3 /"
"usr/local/bin/thermalctld\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"admin@sonic:~$ docker exec -it pmon bash\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          28  0.0  0.8  49972 33192 pts/0    S    Apr26   0:23 python3 /"
"usr/local/bin/ledd\n"
"root          29  0.9  1.0 278492 43816 pts/0    Sl   Apr26  34:41 python3 /"
"usr/local/bin/xcvrd\n"
"root          30  0.4  1.0  57660 40412 pts/0    S    Apr26  18:41 python3 /"
"usr/local/bin/psud\n"
"root          32  0.0  1.0  57172 40088 pts/0    S    Apr26   0:02 python3 /"
"usr/local/bin/syseepromd\n"
"root          33  0.0  1.0  58648 41400 pts/0    S    Apr26   0:27 python3 /"
"usr/local/bin/thermalctld\n"
"root          34  0.0  1.3  70044 53496 pts/0    S    Apr26   0:46 /usr/bin/"
"python3 /usr/local/bin/pcied\n"
"root          42  0.0  0.0  55320  1136 ?        Ss   Apr26   0:15 /usr/sbin/"
"sensord -f daemon\n"
"root          45  0.0  0.8  58648 32220 pts/0    S    Apr26   2:45 python3 /"
"usr/local/bin/thermalctld\n"
"...\n"
"```"

#: src/2-3-key-containers.md:177
msgid ""
"其中大部分的服务从名字我们就能猜出来是做什么的了，中间只有xcvrd不是那么明显，"
"这里xcvr是transceiver的缩写，它是用来监控交换机的光模块的，比如SFP，QSFP等"
"等。"
msgstr ""
"其中大部分的服务从名字我们就能猜出来是做什么的了，中间只有xcvrd不是那么明显，"
"这里xcvr是transceiver的缩写，它是用来监控交换机的光模块的，比如SFP，QSFP等"
"等。"

#: src/2-3-key-containers.md:181
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SONiC Management Framework][SONiCMgmtFramework]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SONiC Management Framework][SONiCMgmtFramework]"

#: src/2-4-sai-intro.md:1
msgid "# SAI"
msgstr "# SAI"

#: src/2-4-sai-intro.md:3
msgid ""
"SAI（Switch Abstraction Interface，交换机抽象接口）是SONiC的基石，正因为有了"
"它，SONiC才能支持多种硬件平台。我们在[这个SAI API的文档][SAIAPI]中，可以看到"
"它定义的所有接口。"
msgstr ""
"SAI（Switch Abstraction Interface，交换机抽象接口）是SONiC的基石，正因为有了"
"它，SONiC才能支持多种硬件平台。我们在[这个SAI API的文档][SAIAPI]中，可以看到"
"它定义的所有接口。"

#: src/2-4-sai-intro.md:5
msgid ""
"[在核心容器一节中我们提到，SAI运行在`syncd`容器中](./2-3-key-containers."
"html)。不过和其他组件不同，它并不是一个服务，而是一组公共的头文件和动态链接库"
"（.so）。其中，所有的抽象接口都以c语言头文件的方式定义在了[OCP的SAI仓库]"
"[OCPSAI]中，而.so文件则由各个硬件厂商提供，用于实现SAI的接口。"
msgstr ""
"[在核心容器一节中我们提到，SAI运行在`syncd`容器中](./2-3-key-containers."
"html)。不过和其他组件不同，它并不是一个服务，而是一组公共的头文件和动态链接库"
"（.so）。其中，所有的抽象接口都以c语言头文件的方式定义在了[OCP的SAI仓库]"
"[OCPSAI]中，而.so文件则由各个硬件厂商提供，用于实现SAI的接口。"

#: src/2-4-sai-intro.md:7
msgid "## SAI接口"
msgstr "## SAI接口"

#: src/2-4-sai-intro.md:9
msgid ""
"为了有一个更加直观的理解，我们拿一小部分代码来展示一下SAI的接口定义和初始化的"
"方法，如下："
msgstr ""
"为了有一个更加直观的理解，我们拿一小部分代码来展示一下SAI的接口定义和初始化的"
"方法，如下："

#: src/2-4-sai-intro.md:11
msgid ""
"```cpp\n"
"// File: meta/saimetadata.h\n"
"typedef struct _sai_apis_t {\n"
"    sai_switch_api_t* switch_api;\n"
"    sai_port_api_t* port_api;\n"
"    ...\n"
"} sai_apis_t;\n"
"\n"
"// File: inc/saiswitch.h\n"
"typedef struct _sai_switch_api_t\n"
"{\n"
"    sai_create_switch_fn                   create_switch;\n"
"    sai_remove_switch_fn                   remove_switch;\n"
"    sai_set_switch_attribute_fn            set_switch_attribute;\n"
"    sai_get_switch_attribute_fn            get_switch_attribute;\n"
"    ...\n"
"} sai_switch_api_t;\n"
"\n"
"// File: inc/saiport.h\n"
"typedef struct _sai_port_api_t\n"
"{\n"
"    sai_create_port_fn                     create_port;\n"
"    sai_remove_port_fn                     remove_port;\n"
"    sai_set_port_attribute_fn              set_port_attribute;\n"
"    sai_get_port_attribute_fn              get_port_attribute;\n"
"    ...\n"
"} sai_port_api_t;\n"
"```"
msgstr ""
"```cpp\n"
"// File: meta/saimetadata.h\n"
"typedef struct _sai_apis_t {\n"
"    sai_switch_api_t* switch_api;\n"
"    sai_port_api_t* port_api;\n"
"    ...\n"
"} sai_apis_t;\n"
"\n"
"// File: inc/saiswitch.h\n"
"typedef struct _sai_switch_api_t\n"
"{\n"
"    sai_create_switch_fn                   create_switch;\n"
"    sai_remove_switch_fn                   remove_switch;\n"
"    sai_set_switch_attribute_fn            set_switch_attribute;\n"
"    sai_get_switch_attribute_fn            get_switch_attribute;\n"
"    ...\n"
"} sai_switch_api_t;\n"
"\n"
"// File: inc/saiport.h\n"
"typedef struct _sai_port_api_t\n"
"{\n"
"    sai_create_port_fn                     create_port;\n"
"    sai_remove_port_fn                     remove_port;\n"
"    sai_set_port_attribute_fn              set_port_attribute;\n"
"    sai_get_port_attribute_fn              get_port_attribute;\n"
"    ...\n"
"} sai_port_api_t;\n"
"```"

#: src/2-4-sai-intro.md:40
msgid ""
"其中，`sai_apis_t`结构体是SAI所有模块的接口的集合，其中每个成员都是一个特定模"
"块的接口列表的指针。我们用`sai_switch_api_t`来举例，它定义了SAI Switch模块的"
"所有接口，我们在`inc/saiswitch.h`中可以看到它的定义。同样的，我们在`inc/"
"saiport.h`中可以看到SAI Port模块的接口定义。"
msgstr ""
"其中，`sai_apis_t`结构体是SAI所有模块的接口的集合，其中每个成员都是一个特定模"
"块的接口列表的指针。我们用`sai_switch_api_t`来举例，它定义了SAI Switch模块的"
"所有接口，我们在`inc/saiswitch.h`中可以看到它的定义。同样的，我们在`inc/"
"saiport.h`中可以看到SAI Port模块的接口定义。"

#: src/2-4-sai-intro.md:42
msgid "## SAI初始化"
msgstr "## SAI初始化"

#: src/2-4-sai-intro.md:44
msgid ""
"SAI的初始化其实就是想办法获取上面这些函数指针，这样我们就可以通过SAI的接口来"
"操作ASIC了。"
msgstr ""
"SAI的初始化其实就是想办法获取上面这些函数指针，这样我们就可以通过SAI的接口来"
"操作ASIC了。"

#: src/2-4-sai-intro.md:46
msgid "参与SAI初始化的主要函数有两个，他们都定义在`inc/sai.h`中："
msgstr "参与SAI初始化的主要函数有两个，他们都定义在`inc/sai.h`中："

#: src/2-4-sai-intro.md:48
msgid ""
"- `sai_api_initialize`：初始化SAI\n"
"- `sai_api_query`：传入SAI的API的类型，获取对应的接口列表"
msgstr ""
"- `sai_api_initialize`：初始化SAI\n"
"- `sai_api_query`：传入SAI的API的类型，获取对应的接口列表"

#: src/2-4-sai-intro.md:51
msgid ""
"虽然大部分厂商的SAI实现是闭源的，但是mellanox却开源了自己的SAI实现，所以这里"
"我们可以借助其更加深入的理解SAI是如何工作的。"
msgstr ""
"虽然大部分厂商的SAI实现是闭源的，但是mellanox却开源了自己的SAI实现，所以这里"
"我们可以借助其更加深入的理解SAI是如何工作的。"

#: src/2-4-sai-intro.md:53
msgid ""
"比如，`sai_api_initialize`函数其实就是简单的设置设置两个全局变量，然后返回"
"`SAI_STATUS_SUCCESS`："
msgstr ""
"比如，`sai_api_initialize`函数其实就是简单的设置设置两个全局变量，然后返回"
"`SAI_STATUS_SUCCESS`："

#: src/2-4-sai-intro.md:55
msgid ""
"```cpp\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_interfacequery.c\n"
"sai_status_t sai_api_initialize(_In_ uint64_t flags, _In_ const "
"sai_service_method_table_t* services)\n"
"{\n"
"    if (g_initialized) {\n"
"        return SAI_STATUS_FAILURE;\n"
"    }\n"
"    // Validate parameters here (code emitted)\n"
"\n"
"    memcpy(&g_mlnx_services, services, sizeof(g_mlnx_services));\n"
"    g_initialized = true;\n"
"    return SAI_STATUS_SUCCESS;\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_interfacequery.c\n"
"sai_status_t sai_api_initialize(_In_ uint64_t flags, _In_ const "
"sai_service_method_table_t* services)\n"
"{\n"
"    if (g_initialized) {\n"
"        return SAI_STATUS_FAILURE;\n"
"    }\n"
"    // Validate parameters here (code emitted)\n"
"\n"
"    memcpy(&g_mlnx_services, services, sizeof(g_mlnx_services));\n"
"    g_initialized = true;\n"
"    return SAI_STATUS_SUCCESS;\n"
"}\n"
"```"

#: src/2-4-sai-intro.md:70
msgid ""
"初始化完成后，我们就可以使用`sai_api_query`函数，通过传入API的类型来查询对应"
"的接口列表，而每一个接口列表其实都是一个全局变量："
msgstr ""
"初始化完成后，我们就可以使用`sai_api_query`函数，通过传入API的类型来查询对应"
"的接口列表，而每一个接口列表其实都是一个全局变量："

#: src/2-4-sai-intro.md:72
msgid ""
"```cpp\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_interfacequery.c\n"
"sai_status_t sai_api_query(_In_ sai_api_t sai_api_id, _Out_ void** "
"api_method_table)\n"
"{\n"
"    if (!g_initialized) {\n"
"        return SAI_STATUS_UNINITIALIZED;\n"
"    }\n"
"    ...\n"
"\n"
"    return sai_api_query_eth(sai_api_id, api_method_table);\n"
"}\n"
"\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_interfacequery_eth.c\n"
"sai_status_t sai_api_query_eth(_In_ sai_api_t sai_api_id, _Out_ void** "
"api_method_table)\n"
"{\n"
"    switch (sai_api_id) {\n"
"    case SAI_API_BRIDGE:\n"
"        *(const sai_bridge_api_t**)api_method_table = &mlnx_bridge_api;\n"
"        return SAI_STATUS_SUCCESS;\n"
"    case SAI_API_SWITCH:\n"
"        *(const sai_switch_api_t**)api_method_table = &mlnx_switch_api;\n"
"        return SAI_STATUS_SUCCESS;\n"
"    ...\n"
"    default:\n"
"        if (sai_api_id >= (sai_api_t)SAI_API_EXTENSIONS_RANGE_END) {\n"
"            return SAI_STATUS_INVALID_PARAMETER;\n"
"        } else {\n"
"            return SAI_STATUS_NOT_IMPLEMENTED;\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_bridge.c\n"
"const sai_bridge_api_t mlnx_bridge_api = {\n"
"    mlnx_create_bridge,\n"
"    mlnx_remove_bridge,\n"
"    mlnx_set_bridge_attribute,\n"
"    mlnx_get_bridge_attribute,\n"
"    ...\n"
"};\n"
"\n"
"\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_switch.c\n"
"const sai_switch_api_t mlnx_switch_api = {\n"
"    mlnx_create_switch,\n"
"    mlnx_remove_switch,\n"
"    mlnx_set_switch_attribute,\n"
"    mlnx_get_switch_attribute,\n"
"    ...\n"
"};\n"
"```"
msgstr ""
"```cpp\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_interfacequery.c\n"
"sai_status_t sai_api_query(_In_ sai_api_t sai_api_id, _Out_ void** "
"api_method_table)\n"
"{\n"
"    if (!g_initialized) {\n"
"        return SAI_STATUS_UNINITIALIZED;\n"
"    }\n"
"    ...\n"
"\n"
"    return sai_api_query_eth(sai_api_id, api_method_table);\n"
"}\n"
"\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_interfacequery_eth.c\n"
"sai_status_t sai_api_query_eth(_In_ sai_api_t sai_api_id, _Out_ void** "
"api_method_table)\n"
"{\n"
"    switch (sai_api_id) {\n"
"    case SAI_API_BRIDGE:\n"
"        *(const sai_bridge_api_t**)api_method_table = &mlnx_bridge_api;\n"
"        return SAI_STATUS_SUCCESS;\n"
"    case SAI_API_SWITCH:\n"
"        *(const sai_switch_api_t**)api_method_table = &mlnx_switch_api;\n"
"        return SAI_STATUS_SUCCESS;\n"
"    ...\n"
"    default:\n"
"        if (sai_api_id >= (sai_api_t)SAI_API_EXTENSIONS_RANGE_END) {\n"
"            return SAI_STATUS_INVALID_PARAMETER;\n"
"        } else {\n"
"            return SAI_STATUS_NOT_IMPLEMENTED;\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_bridge.c\n"
"const sai_bridge_api_t mlnx_bridge_api = {\n"
"    mlnx_create_bridge,\n"
"    mlnx_remove_bridge,\n"
"    mlnx_set_bridge_attribute,\n"
"    mlnx_get_bridge_attribute,\n"
"    ...\n"
"};\n"
"\n"
"\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_switch.c\n"
"const sai_switch_api_t mlnx_switch_api = {\n"
"    mlnx_create_switch,\n"
"    mlnx_remove_switch,\n"
"    mlnx_set_switch_attribute,\n"
"    mlnx_get_switch_attribute,\n"
"    ...\n"
"};\n"
"```"

#: src/2-4-sai-intro.md:124
msgid "## SAI的使用"
msgstr "## SAI的使用"

#: src/2-4-sai-intro.md:126
msgid ""
"在`syncd`容器中，SONiC会在启动时启动`syncd`服务，而`syncd`服务会加载当前系统"
"中的SAI组件。这个组件由各个厂商提供，它们会根据自己的硬件平台来实现上面展现的"
"SAI的接口，从而让SONiC使用统一的上层逻辑来控制多种不同的硬件平台。"
msgstr ""
"在`syncd`容器中，SONiC会在启动时启动`syncd`服务，而`syncd`服务会加载当前系统"
"中的SAI组件。这个组件由各个厂商提供，它们会根据自己的硬件平台来实现上面展现的"
"SAI的接口，从而让SONiC使用统一的上层逻辑来控制多种不同的硬件平台。"

#: src/2-4-sai-intro.md:128
msgid "我们可以通过`ps`, `ls`和`nm`命令来简单的对这个进行验证："
msgstr "我们可以通过`ps`, `ls`和`nm`命令来简单的对这个进行验证："

#: src/2-4-sai-intro.md:130
msgid ""
"```bash\n"
"# Enter into syncd container\n"
"admin@sonic:~$ docker exec -it syncd bash\n"
"\n"
"# List all processes. We will only see syncd process here.\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          21  0.0  0.0  87708  1532 pts/0    Sl   16:20   0:00 /usr/bin/"
"dsserve /usr/bin/syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"root          33 11.1 15.0 2724396 602532 pts/0  Sl   16:20  36:30 /usr/bin/"
"syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"...\n"
"\n"
"# Find all libsai*.so.* files.\n"
"root@sonic:/# find / -name libsai*.so.*\n"
"/usr/lib/x86_64-linux-gnu/libsaimeta.so.0\n"
"/usr/lib/x86_64-linux-gnu/libsaimeta.so.0.0.0\n"
"/usr/lib/x86_64-linux-gnu/libsaimetadata.so.0.0.0\n"
"/usr/lib/x86_64-linux-gnu/libsairedis.so.0.0.0\n"
"/usr/lib/x86_64-linux-gnu/libsairedis.so.0\n"
"/usr/lib/x86_64-linux-gnu/libsaimetadata.so.0\n"
"/usr/lib/libsai.so.1\n"
"/usr/lib/libsai.so.1.0\n"
"\n"
"# Copy the file out of switch and check libsai.so on your own dev machine.\n"
"# We will see the most important SAI export functions here.\n"
"$ nm -C -D ./libsai.so.1.0 > ./sai-exports.txt\n"
"$ vim sai-exports.txt\n"
"...\n"
"0000000006581ae0 T sai_api_initialize\n"
"0000000006582700 T sai_api_query\n"
"0000000006581da0 T sai_api_uninitialize\n"
"...\n"
"```"
msgstr ""
"```bash\n"
"# Enter into syncd container\n"
"admin@sonic:~$ docker exec -it syncd bash\n"
"\n"
"# List all processes. We will only see syncd process here.\n"
"root@sonic:/# ps aux\n"
"USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"...\n"
"root          21  0.0  0.0  87708  1532 pts/0    Sl   16:20   0:00 /usr/bin/"
"dsserve /usr/bin/syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"root          33 11.1 15.0 2724396 602532 pts/0  Sl   16:20  36:30 /usr/bin/"
"syncd --diag -u -s -p /etc/sai.d/sai.profile -b /tmp/"
"break_before_make_objects\n"
"...\n"
"\n"
"# Find all libsai*.so.* files.\n"
"root@sonic:/# find / -name libsai*.so.*\n"
"/usr/lib/x86_64-linux-gnu/libsaimeta.so.0\n"
"/usr/lib/x86_64-linux-gnu/libsaimeta.so.0.0.0\n"
"/usr/lib/x86_64-linux-gnu/libsaimetadata.so.0.0.0\n"
"/usr/lib/x86_64-linux-gnu/libsairedis.so.0.0.0\n"
"/usr/lib/x86_64-linux-gnu/libsairedis.so.0\n"
"/usr/lib/x86_64-linux-gnu/libsaimetadata.so.0\n"
"/usr/lib/libsai.so.1\n"
"/usr/lib/libsai.so.1.0\n"
"\n"
"# Copy the file out of switch and check libsai.so on your own dev machine.\n"
"# We will see the most important SAI export functions here.\n"
"$ nm -C -D ./libsai.so.1.0 > ./sai-exports.txt\n"
"$ vim sai-exports.txt\n"
"...\n"
"0000000006581ae0 T sai_api_initialize\n"
"0000000006582700 T sai_api_query\n"
"0000000006581da0 T sai_api_uninitialize\n"
"...\n"
"```"

#: src/2-4-sai-intro.md:166
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SAI API][SAIAPI]\n"
"3. [Forwarding Metamorphosis: Fast Programmable Match-Action Processing in "
"Hardware for SDN][PISA]\n"
"4. [Github: sonic-net/sonic-sairedis][SONiCSAIRedis]\n"
"5. [Github: opencomputeproject/SAI][OCPSAI]\n"
"6. [Arista 7050QX Series 10/40G Data Center Switches Data Sheet]"
"[Arista7050QX]\n"
"7. [Github repo: Nvidia (Mellanox) SAI implementation][MnlxSAI]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SAI API][SAIAPI]\n"
"3. [Forwarding Metamorphosis: Fast Programmable Match-Action Processing in "
"Hardware for SDN][PISA]\n"
"4. [Github: sonic-net/sonic-sairedis][SONiCSAIRedis]\n"
"5. [Github: opencomputeproject/SAI][OCPSAI]\n"
"6. [Arista 7050QX Series 10/40G Data Center Switches Data Sheet]"
"[Arista7050QX]\n"
"7. [Github repo: Nvidia (Mellanox) SAI implementation][MnlxSAI]"

#: src/3-dev-guide.md:1
msgid "# 开发上手指南"
msgstr "# 开发上手指南"

#: src/3-1-code-repos.md:1
msgid "# 代码仓库"
msgstr "# 代码仓库"

#: src/3-1-code-repos.md:3
msgid ""
"SONiC的代码都托管在[GitHub的sonic-net账号][SONiCGitHub]上，仓库数量有30几个之"
"多，所以刚开始看SONiC的代码时，肯定是会有点懵的，不过不用担心，我们这里就来一"
"起看看～"
msgstr ""
"SONiC的代码都托管在[GitHub的sonic-net账号][SONiCGitHub]上，仓库数量有30几个之"
"多，所以刚开始看SONiC的代码时，肯定是会有点懵的，不过不用担心，我们这里就来一"
"起看看～"

#: src/3-1-code-repos.md:5
msgid "## 核心仓库"
msgstr "## 核心仓库"

#: src/3-1-code-repos.md:7
msgid "首先是SONiC中最重要的两个核心仓库：SONiC和sonic-buildimage。"
msgstr "首先是SONiC中最重要的两个核心仓库：SONiC和sonic-buildimage。"

#: src/3-1-code-repos.md:9
msgid "### Landing仓库：SONiC"
msgstr "### Landing仓库：SONiC"

#: src/3-1-code-repos.md:11
msgid "<https://github.com/sonic-net/SONiC>"
msgstr "<https://github.com/sonic-net/SONiC>"

#: src/3-1-code-repos.md:13
msgid ""
"这个仓库里面存储着SONiC的Landing Page和大量的文档，Wiki，教程，以往的Talk的"
"Slides，等等等等。这个仓库可以说是每个新人上手最常用的仓库了，但是注意，这个"
"仓库里面**没有任何的代码**，只有文档。"
msgstr ""
"这个仓库里面存储着SONiC的Landing Page和大量的文档，Wiki，教程，以往的Talk的"
"Slides，等等等等。这个仓库可以说是每个新人上手最常用的仓库了，但是注意，这个"
"仓库里面**没有任何的代码**，只有文档。"

#: src/3-1-code-repos.md:15
msgid "### 镜像构建仓库：sonic-buildimage"
msgstr "### 镜像构建仓库：sonic-buildimage"

#: src/3-1-code-repos.md:17
msgid "<https://github.com/sonic-net/sonic-buildimage>"
msgstr "<https://github.com/sonic-net/sonic-buildimage>"

#: src/3-1-code-repos.md:19
msgid ""
"这个构建仓库为什么对于我们十分重要？和其他项目不同，**SONiC的构建仓库其实才是"
"它的主仓库**！这个仓库里面包含："
msgstr ""
"这个构建仓库为什么对于我们十分重要？和其他项目不同，**SONiC的构建仓库其实才是"
"它的主仓库**！这个仓库里面包含："

#: src/3-1-code-repos.md:21
msgid ""
"- 所有的功能实现仓库，它们都以submodule的形式被加入到了这个仓库中（`src`目"
"录）\n"
"- 所有设备厂商的支持文件（`device`目录），比如每个型号的交换机的配置文件，用"
"来访问硬件的支持脚本，等等等等，比如：我的交换机是Arista 7050 QX-32S，那么我"
"就可以在`device/arista/x86_64-arista_7050_qx32s`目录中找到它的支持文件。\n"
"- 所有ASIC芯片厂商提供的支持文件（`platform`目录），比如每个平台的驱动程序，"
"BSP，底层支持的脚本等等。这里我们可以看到几乎所有的主流芯片厂商的支持文件，比"
"如：Broadcom，Mellanox，等等，也有用来做模拟软交换机的实现，比如vs和p4。\n"
"- SONiC用来构建所有容器镜像的Dockerfile（`dockers`目录）\n"
"- 各种各样通用的配置文件和脚本（`files`目录）\n"
"- 用来做构建的编译容器的dockerfile（`sonic-slave-*`目录）\n"
"- 等等……"
msgstr ""
"- 所有的功能实现仓库，它们都以submodule的形式被加入到了这个仓库中（`src`目"
"录）\n"
"- 所有设备厂商的支持文件（`device`目录），比如每个型号的交换机的配置文件，用"
"来访问硬件的支持脚本，等等等等，比如：我的交换机是Arista 7050 QX-32S，那么我"
"就可以在`device/arista/x86_64-arista_7050_qx32s`目录中找到它的支持文件。\n"
"- 所有ASIC芯片厂商提供的支持文件（`platform`目录），比如每个平台的驱动程序，"
"BSP，底层支持的脚本等等。这里我们可以看到几乎所有的主流芯片厂商的支持文件，比"
"如：Broadcom，Mellanox，等等，也有用来做模拟软交换机的实现，比如vs和p4。\n"
"- SONiC用来构建所有容器镜像的Dockerfile（`dockers`目录）\n"
"- 各种各样通用的配置文件和脚本（`files`目录）\n"
"- 用来做构建的编译容器的dockerfile（`sonic-slave-*`目录）\n"
"- 等等……"

#: src/3-1-code-repos.md:29
msgid ""
"正因为这个仓库里面将所有相关的资源全都放在了一起，所以我们学习SONiC的代码时，"
"基本只需要下载这一个源码仓库就可以了，不管是搜索还是跳转都非常方便！"
msgstr ""
"正因为这个仓库里面将所有相关的资源全都放在了一起，所以我们学习SONiC的代码时，"
"基本只需要下载这一个源码仓库就可以了，不管是搜索还是跳转都非常方便！"

#: src/3-1-code-repos.md:31
msgid "## 功能实现仓库"
msgstr "## 功能实现仓库"

#: src/3-1-code-repos.md:33
msgid ""
"除了核心仓库，SONiC下还有很多功能实现仓库，里面都是各个容器和子服务的实现，这"
"些仓库都被以submodule的形式放在了sonic-buildimage的`src`目录下，如果我们想对"
"SONiC进行修改和贡献，我们也需要了解一下。"
msgstr ""
"除了核心仓库，SONiC下还有很多功能实现仓库，里面都是各个容器和子服务的实现，这"
"些仓库都被以submodule的形式放在了sonic-buildimage的`src`目录下，如果我们想对"
"SONiC进行修改和贡献，我们也需要了解一下。"

#: src/3-1-code-repos.md:35
msgid "### SWSS（Switch State Service）相关仓库"
msgstr "### SWSS（Switch State Service）相关仓库"

#: src/3-1-code-repos.md:37
msgid ""
"在上一篇中我们介绍过，SWSS容器是SONiC的大脑，在SONiC下，它由两个repo组成："
"[sonic-swss-common](https://github.com/sonic-net/sonic-swss-common)和[sonic-"
"swss](https://github.com/sonic-net/sonic-swss)。"
msgstr ""
"在上一篇中我们介绍过，SWSS容器是SONiC的大脑，在SONiC下，它由两个repo组成："
"[sonic-swss-common](https://github.com/sonic-net/sonic-swss-common)和[sonic-"
"swss](https://github.com/sonic-net/sonic-swss)。"

#: src/3-1-code-repos.md:39
msgid "#### SWSS公共库：sonic-swss-common"
msgstr "#### SWSS公共库：sonic-swss-common"

#: src/3-1-code-repos.md:41
msgid ""
"首先是公共库：sonic-swss-common（<https://github.com/sonic-net/sonic-swss-"
"common>）。"
msgstr ""
"首先是公共库：sonic-swss-common（<https://github.com/sonic-net/sonic-swss-"
"common>）。"

#: src/3-1-code-repos.md:43
msgid ""
"这个仓库里面包含了所有`*mgrd`和`*syncd`服务所需要的公共功能，比如，logger，"
"json，netlink的封装，Redis操作和基于Redis的各种服务间通讯机制的封装等等。虽然"
"能看出来这个仓库一开始的目标是专门给swss服务使用的，但是也正因为功能多，很多"
"其他的仓库都有它的引用，比如`swss-sairedis`和`swss-restapi`。"
msgstr ""
"这个仓库里面包含了所有`*mgrd`和`*syncd`服务所需要的公共功能，比如，logger，"
"json，netlink的封装，Redis操作和基于Redis的各种服务间通讯机制的封装等等。虽然"
"能看出来这个仓库一开始的目标是专门给swss服务使用的，但是也正因为功能多，很多"
"其他的仓库都有它的引用，比如`swss-sairedis`和`swss-restapi`。"

#: src/3-1-code-repos.md:45
msgid "#### SWSS主仓库：sonic-swss"
msgstr "#### SWSS主仓库：sonic-swss"

#: src/3-1-code-repos.md:47
msgid ""
"然后就是SWSS的主仓库sonic-swss了：<https://github.com/sonic-net/sonic-swss>。"
msgstr ""
"然后就是SWSS的主仓库sonic-swss了：<https://github.com/sonic-net/sonic-swss>。"

#: src/3-1-code-repos.md:49
msgid "我们可以在这个仓库中找到："
msgstr "我们可以在这个仓库中找到："

#: src/3-1-code-repos.md:51
msgid ""
"- 绝大部分的`*mgrd`和`*syncd`服务：`orchagent`, `portsyncd/portmgrd/"
"intfmgrd`，`neighsyncd/nbrmgrd`，`natsyncd/natmgrd`，`buffermgrd`，"
"`coppmgrd`，`macsecmgrd`，`sflowmgrd`，`tunnelmgrd`，`vlanmgrd`，`vrfmgrd`，"
"`vxlanmgrd`，等等。\n"
"- `swssconfig`：在`swssconfig`目录下，用于在快速重启时（fast reboot）恢复FDB"
"和ARP表。\n"
"- `swssplayer`：也在`swssconfig`目录下，用来记录所有通过SWSS进行的配置下发操"
"作，这样我们就可以利用它来做replay，从而对问题进行重现和调试。\n"
"- 甚至一些不在SWSS容器中的服务，比如`fpmsyncd`（bgp容器）和`teamsyncd/"
"teammgrd`（teamd容器）。"
msgstr ""
"- 绝大部分的`*mgrd`和`*syncd`服务：`orchagent`, `portsyncd/portmgrd/"
"intfmgrd`，`neighsyncd/nbrmgrd`，`natsyncd/natmgrd`，`buffermgrd`，"
"`coppmgrd`，`macsecmgrd`，`sflowmgrd`，`tunnelmgrd`，`vlanmgrd`，`vrfmgrd`，"
"`vxlanmgrd`，等等。\n"
"- `swssconfig`：在`swssconfig`目录下，用于在快速重启时（fast reboot）恢复FDB"
"和ARP表。\n"
"- `swssplayer`：也在`swssconfig`目录下，用来记录所有通过SWSS进行的配置下发操"
"作，这样我们就可以利用它来做replay，从而对问题进行重现和调试。\n"
"- 甚至一些不在SWSS容器中的服务，比如`fpmsyncd`（bgp容器）和`teamsyncd/"
"teammgrd`（teamd容器）。"

#: src/3-1-code-repos.md:56
msgid "### SAI/平台相关仓库"
msgstr "### SAI/平台相关仓库"

#: src/3-1-code-repos.md:58
msgid ""
"接下来就是作为交换机抽象接口的SAI了，[虽然SAI是微软提出来并在2015年3月份发布"
"了0.1版本](https://www.opencompute.org/documents/switch-abstraction-"
"interface-ocp-specification-v0-2-pdf)，但是[在2015年9月份，SONiC都还没有发布"
"第一个版本的时候，就已经被OCP接收并作为一个公共的标准了](https://azure."
"microsoft.com/en-us/blog/switch-abstraction-interface-sai-officially-"
"accepted-by-the-open-compute-project-ocp/)，这也是SONiC能够在这么短的时间内就"
"得到了这么多厂商的支持的原因之一。而也因为如此，SAI的代码仓库也被分成了两部"
"分："
msgstr ""
"接下来就是作为交换机抽象接口的SAI了，[虽然SAI是微软提出来并在2015年3月份发布"
"了0.1版本](https://www.opencompute.org/documents/switch-abstraction-"
"interface-ocp-specification-v0-2-pdf)，但是[在2015年9月份，SONiC都还没有发布"
"第一个版本的时候，就已经被OCP接收并作为一个公共的标准了](https://azure."
"microsoft.com/en-us/blog/switch-abstraction-interface-sai-officially-"
"accepted-by-the-open-compute-project-ocp/)，这也是SONiC能够在这么短的时间内就"
"得到了这么多厂商的支持的原因之一。而也因为如此，SAI的代码仓库也被分成了两部"
"分："

#: src/3-1-code-repos.md:60
msgid ""
"- OCP下的OpenComputeProject/SAI：<https://github.com/opencomputeproject/"
"SAI>。里面包含了有关SAI标准的所有代码，包括SAI的头文件，behavior model，测试"
"用例，文档等等。\n"
"- SONiC下的sonic-sairedis：<https://github.com/sonic-net/sonic-sairedis>。里"
"面包含了SONiC中用来和SAI交互的所有代码，比如syncd服务，和各种调试统计，比如用"
"来做replay的`saiplayer`和用来导出asic状态的`saidump`。"
msgstr ""
"- OCP下的OpenComputeProject/SAI：<https://github.com/opencomputeproject/"
"SAI>。里面包含了有关SAI标准的所有代码，包括SAI的头文件，behavior model，测试"
"用例，文档等等。\n"
"- SONiC下的sonic-sairedis：<https://github.com/sonic-net/sonic-sairedis>。里"
"面包含了SONiC中用来和SAI交互的所有代码，比如syncd服务，和各种调试统计，比如用"
"来做replay的`saiplayer`和用来导出asic状态的`saidump`。"

#: src/3-1-code-repos.md:63
msgid ""
"除了这两个仓库之外，还有一个平台相关的仓库，比如：[sonic-platform-vpp]"
"(https://github.com/sonic-net/sonic-platform-vpp)，它的作用是通过SAI的接口，"
"利用vpp来实现数据平面的功能，相当于一个高性能的软交换机，个人感觉未来可能会被"
"合并到buildimage仓库中，作为platform目录下的一部分。"
msgstr ""
"除了这两个仓库之外，还有一个平台相关的仓库，比如：[sonic-platform-vpp]"
"(https://github.com/sonic-net/sonic-platform-vpp)，它的作用是通过SAI的接口，"
"利用vpp来实现数据平面的功能，相当于一个高性能的软交换机，个人感觉未来可能会被"
"合并到buildimage仓库中，作为platform目录下的一部分。"

#: src/3-1-code-repos.md:65
msgid "### 管理服务（mgmt）相关仓库"
msgstr "### 管理服务（mgmt）相关仓库"

#: src/3-1-code-repos.md:67
msgid "然后是SONiC中所有和[管理服务][SONiCMgmtFramework]相关的仓库："
msgstr "然后是SONiC中所有和[管理服务][SONiCMgmtFramework]相关的仓库："

#: src/3-1-code-repos.md:69
msgid ""
"| 名称 | 说明 |\n"
"| --- | --- |\n"
"| [sonic-mgmt-common](https://github.com/sonic-net/sonic-mgmt-common) | 管理"
"服务的基础库，里面包含着`translib`，yang model相关的代码 |\n"
"| [sonic-mgmt-framework](https://github.com/sonic-net/sonic-mgmt-framework) "
"| 使用Go来实现的REST Server，是下方架构图中的REST Gateway（进程名："
"`rest_server`） |\n"
"| [sonic-gnmi](https://github.com/sonic-net/sonic-gnmi) | 和sonic-mgmt-"
"framework类似，是下方架构图中，基于gRPC的gNMI（gRPC Network Management "
"Interface）Server |\n"
"| [sonic-restapi](https://github.com/sonic-net/sonic-restapi) | 这是SONiC使用"
"go来实现的另一个配置管理的REST Server，和mgmt-framework不同，这个server在收到"
"消息后会直接对CONFIG_DB进行操作，而不是走translib（下图中没有，进程名：`go-"
"server-server`） |\n"
"| [sonic-mgmt](https://github.com/sonic-net/sonic-mgmt) | 各种自动化脚本"
"（`ansible`目录），测试（`tests`目录），用来搭建test bed和测试上报"
"（`test_reporting`目录）之类的， |"
msgstr ""
"| 名称 | 说明 |\n"
"| --- | --- |\n"
"| [sonic-mgmt-common](https://github.com/sonic-net/sonic-mgmt-common) | 管理"
"服务的基础库，里面包含着`translib`，yang model相关的代码 |\n"
"| [sonic-mgmt-framework](https://github.com/sonic-net/sonic-mgmt-framework) "
"| 使用Go来实现的REST Server，是下方架构图中的REST Gateway（进程名："
"`rest_server`） |\n"
"| [sonic-gnmi](https://github.com/sonic-net/sonic-gnmi) | 和sonic-mgmt-"
"framework类似，是下方架构图中，基于gRPC的gNMI（gRPC Network Management "
"Interface）Server |\n"
"| [sonic-restapi](https://github.com/sonic-net/sonic-restapi) | 这是SONiC使用"
"go来实现的另一个配置管理的REST Server，和mgmt-framework不同，这个server在收到"
"消息后会直接对CONFIG_DB进行操作，而不是走translib（下图中没有，进程名：`go-"
"server-server`） |\n"
"| [sonic-mgmt](https://github.com/sonic-net/sonic-mgmt) | 各种自动化脚本"
"（`ansible`目录），测试（`tests`目录），用来搭建test bed和测试上报"
"（`test_reporting`目录）之类的， |"

#: src/3-1-code-repos.md:77
msgid ""
"这里还是附上SONiC管理服务的架构图，方便大家配合食用 [\\[4\\]]"
"[SONiCMgmtFramework]："
msgstr ""
"这里还是附上SONiC管理服务的架构图，方便大家配合食用 [\\[4\\]]"
"[SONiCMgmtFramework]："

#: src/3-1-code-repos.md:81
msgid "### 平台监控相关仓库：sonic-platform-common和sonic-platform-daemons"
msgstr "### 平台监控相关仓库：sonic-platform-common和sonic-platform-daemons"

#: src/3-1-code-repos.md:83
msgid "以下两个仓库都和平台监控和控制相关，比如LED，风扇，电源，温控等等："
msgstr "以下两个仓库都和平台监控和控制相关，比如LED，风扇，电源，温控等等："

#: src/3-1-code-repos.md:85
msgid ""
"| 名称 | 说明 |\n"
"| --- | --- |\n"
"| [sonic-platform-common](https://github.com/sonic-net/sonic-platform-"
"common) | 这是给厂商们提供的基础包，用来定义访问风扇，LED，电源管理，温控等等"
"模块的接口定义，这些接口都是用python来实现的 |\n"
"| [sonic-platform-daemons](https://github.com/sonic-net/sonic-platform-"
"daemons) | 这里包含了SONiC中pmon容器中运行的各种监控服务：`chassisd`，"
"`ledd`，`pcied`，`psud`，`syseepromd`，`thermalctld`，`xcvrd`，`ycabled`，它"
"们都使用python实现，通过和中心数据库Redis进行连接，和加载并调用各个厂商提供的"
"接口实现来对各个模块进行监控和控制 |"
msgstr ""
"| 名称 | 说明 |\n"
"| --- | --- |\n"
"| [sonic-platform-common](https://github.com/sonic-net/sonic-platform-"
"common) | 这是给厂商们提供的基础包，用来定义访问风扇，LED，电源管理，温控等等"
"模块的接口定义，这些接口都是用python来实现的 |\n"
"| [sonic-platform-daemons](https://github.com/sonic-net/sonic-platform-"
"daemons) | 这里包含了SONiC中pmon容器中运行的各种监控服务：`chassisd`，"
"`ledd`，`pcied`，`psud`，`syseepromd`，`thermalctld`，`xcvrd`，`ycabled`，它"
"们都使用python实现，通过和中心数据库Redis进行连接，和加载并调用各个厂商提供的"
"接口实现来对各个模块进行监控和控制 |"

#: src/3-1-code-repos.md:90
msgid "### 其他功能实现仓库"
msgstr "### 其他功能实现仓库"

#: src/3-1-code-repos.md:92
msgid ""
"除了上面这些仓库以外，SONiC还有很多实现其方方面面功能的仓库，有些是一个或多个"
"进程，有些是一些库，它们的作用如下表所示："
msgstr ""
"除了上面这些仓库以外，SONiC还有很多实现其方方面面功能的仓库，有些是一个或多个"
"进程，有些是一些库，它们的作用如下表所示："

#: src/3-1-code-repos.md:94
msgid ""
"| 仓库 | 介绍 |\n"
"| --- | --- |\n"
"| [sonic-snmpagent](https://github.com/sonic-net/sonic-snmpagent) | [AgentX]"
"(https://www.ietf.org/rfc/rfc2741.txt) SNMP subagent的实现"
"（`sonic_ax_impl`），用于连接Redis数据库，给snmpd提供所需要的各种信息，可以把"
"它理解成snmpd的控制面，而snmpd是数据面，用于响应外部SNMP的请求 |\n"
"| [sonic-frr](https://github.com/sonic-net/sonic-frr) | FRRouting，各种路由协"
"议的实现，所以这个仓库中我们可以找到如`bgpd`，`zebra`这类的路由相关的进程实"
"现 |\n"
"| [sonic-linkmgrd](https://github.com/sonic-net/sonic-linkmgrd) | Dual ToR "
"support，检查Link的状态，并且控制ToR的连接 |\n"
"| [sonic-dhcp-relay](https://github.com/sonic-net/sonic-dhcp-relay) | DHCP "
"relay agent |\n"
"| [sonic-dhcpmon](https://github.com/sonic-net/sonic-dhcpmon) | 监控DHCP的状"
"态，并报告给中心数据库Redis |\n"
"| [sonic-dbsyncd](https://github.com/sonic-net/sonic-dbsyncd) | `lldp_syncd`"
"服务，但是repo的名字没取好，叫做dbsyncd |\n"
"| [sonic-pins](https://github.com/sonic-net/sonic-pins) | Google开发的基于P4"
"的网络栈支持（P4 Integrated Network Stack，PINS），更多信息可以参看[PINS的官"
"网][SONiCPINS]。 |\n"
"| [sonic-stp](https://github.com/sonic-net/sonic-stp) | STP（Spanning Tree "
"Protocol）的支持 |\n"
"| [sonic-ztp](https://github.com/sonic-net/sonic-ztp) | [Zero Touch "
"Provisioning][SONiCZTP] |\n"
"| [DASH](https://github.com/sonic-net/DASH) | [Disaggregated API for SONiC "
"Hosts][SONiCDASH] |\n"
"| [sonic-host-services](https://github.com/sonic-net/sonic-host-services) | "
"运行在host上通过dbus用来为容器中的服务提供支持的服务，比如保存和重新加载配"
"置，保存dump之类的非常有限的功能，类似一个host broker |\n"
"| [sonic-fips](https://github.com/sonic-net/sonic-fips) | FIPS（Federal "
"Information Processing Standards）的支持，里面有很多为了支持FIPS标准而加入的"
"各种补丁文件 |\n"
"| [sonic-wpa-supplicant](https://github.com/sonic-net/sonic-wpa-supplicant) "
"| 各种无线网络协议的支持 |"
msgstr ""
"| 仓库 | 介绍 |\n"
"| --- | --- |\n"
"| [sonic-snmpagent](https://github.com/sonic-net/sonic-snmpagent) | [AgentX]"
"(https://www.ietf.org/rfc/rfc2741.txt) SNMP subagent的实现"
"（`sonic_ax_impl`），用于连接Redis数据库，给snmpd提供所需要的各种信息，可以把"
"它理解成snmpd的控制面，而snmpd是数据面，用于响应外部SNMP的请求 |\n"
"| [sonic-frr](https://github.com/sonic-net/sonic-frr) | FRRouting，各种路由协"
"议的实现，所以这个仓库中我们可以找到如`bgpd`，`zebra`这类的路由相关的进程实"
"现 |\n"
"| [sonic-linkmgrd](https://github.com/sonic-net/sonic-linkmgrd) | Dual ToR "
"support，检查Link的状态，并且控制ToR的连接 |\n"
"| [sonic-dhcp-relay](https://github.com/sonic-net/sonic-dhcp-relay) | DHCP "
"relay agent |\n"
"| [sonic-dhcpmon](https://github.com/sonic-net/sonic-dhcpmon) | 监控DHCP的状"
"态，并报告给中心数据库Redis |\n"
"| [sonic-dbsyncd](https://github.com/sonic-net/sonic-dbsyncd) | `lldp_syncd`"
"服务，但是repo的名字没取好，叫做dbsyncd |\n"
"| [sonic-pins](https://github.com/sonic-net/sonic-pins) | Google开发的基于P4"
"的网络栈支持（P4 Integrated Network Stack，PINS），更多信息可以参看[PINS的官"
"网][SONiCPINS]。 |\n"
"| [sonic-stp](https://github.com/sonic-net/sonic-stp) | STP（Spanning Tree "
"Protocol）的支持 |\n"
"| [sonic-ztp](https://github.com/sonic-net/sonic-ztp) | [Zero Touch "
"Provisioning][SONiCZTP] |\n"
"| [DASH](https://github.com/sonic-net/DASH) | [Disaggregated API for SONiC "
"Hosts][SONiCDASH] |\n"
"| [sonic-host-services](https://github.com/sonic-net/sonic-host-services) | "
"运行在host上通过dbus用来为容器中的服务提供支持的服务，比如保存和重新加载配"
"置，保存dump之类的非常有限的功能，类似一个host broker |\n"
"| [sonic-fips](https://github.com/sonic-net/sonic-fips) | FIPS（Federal "
"Information Processing Standards）的支持，里面有很多为了支持FIPS标准而加入的"
"各种补丁文件 |\n"
"| [sonic-wpa-supplicant](https://github.com/sonic-net/sonic-wpa-supplicant) "
"| 各种无线网络协议的支持 |"

#: src/3-1-code-repos.md:110
msgid "## 工具仓库：sonic-utilities"
msgstr "## 工具仓库：sonic-utilities"

#: src/3-1-code-repos.md:112
msgid "<https://github.com/sonic-net/sonic-utilities>"
msgstr "<https://github.com/sonic-net/sonic-utilities>"

#: src/3-1-code-repos.md:114
msgid "这个仓库存放着SONiC所有的命令行下的工具："
msgstr "这个仓库存放着SONiC所有的命令行下的工具："

#: src/3-1-code-repos.md:116
msgid ""
"- `config`，`show`，`clear`目录：这是三个SONiC CLI的主命令的实现。需要注意的"
"是，具体的命令实现并不一定在这几个目录里面，大量的命令是通过调用其他命令来实"
"现的，这几个命令只是提供了一个入口。\n"
"- `scripts`，`sfputil`，`psuutil`，`pcieutil`，`fwutil`，`ssdutil`，"
"`acl_loader`目录：这些目录下提供了大量的工具命令，但是它们大多并不是直接给用"
"户使用的，而是被`config`，`show`和`clear`目录下的命令调用的，比如：`show "
"platform fan`命令，就是通过调用`scripts`目录下的`fanshow`命令来实现的。\n"
"- `utilities_common`，`flow_counter_util`，`syslog_util`目录：这些目录和上面"
"类似，但是提供的是基础类，可以直接在python中import调用。\n"
"- 另外还有很多其他的命令：`fdbutil`，`pddf_fanutil`，`pddf_ledutil`，"
"`pddf_psuutil`，`pddf_thermalutil`，等等，用于查看和控制各个模块的状态。\n"
"- `connect`和`consutil`目录：这两个目录下的命令是用来连接到其他SONiC设备并对"
"其进行管理的。\n"
"- `crm`目录：用来配置和查看SONiC中的[CRM（Critical Resource Monitoring）]"
"[SONiCCRM]。这个命令并没有被包含在`config`和`show`命令中，所以用户可以直接使"
"用。\n"
"- `pfc`目录：用来配置和查看SONiC中的[PFC（Priority-based Flow Control）]"
"[SONiCPFC]。\n"
"- `pfcwd`目录：用来配置和查看SONiC中的[PFC Watch Dog][SONiCPFCWD]，比如启动，"
"停止，修改polling interval之类的操作。"
msgstr ""
"- `config`，`show`，`clear`目录：这是三个SONiC CLI的主命令的实现。需要注意的"
"是，具体的命令实现并不一定在这几个目录里面，大量的命令是通过调用其他命令来实"
"现的，这几个命令只是提供了一个入口。\n"
"- `scripts`，`sfputil`，`psuutil`，`pcieutil`，`fwutil`，`ssdutil`，"
"`acl_loader`目录：这些目录下提供了大量的工具命令，但是它们大多并不是直接给用"
"户使用的，而是被`config`，`show`和`clear`目录下的命令调用的，比如：`show "
"platform fan`命令，就是通过调用`scripts`目录下的`fanshow`命令来实现的。\n"
"- `utilities_common`，`flow_counter_util`，`syslog_util`目录：这些目录和上面"
"类似，但是提供的是基础类，可以直接在python中import调用。\n"
"- 另外还有很多其他的命令：`fdbutil`，`pddf_fanutil`，`pddf_ledutil`，"
"`pddf_psuutil`，`pddf_thermalutil`，等等，用于查看和控制各个模块的状态。\n"
"- `connect`和`consutil`目录：这两个目录下的命令是用来连接到其他SONiC设备并对"
"其进行管理的。\n"
"- `crm`目录：用来配置和查看SONiC中的[CRM（Critical Resource Monitoring）]"
"[SONiCCRM]。这个命令并没有被包含在`config`和`show`命令中，所以用户可以直接使"
"用。\n"
"- `pfc`目录：用来配置和查看SONiC中的[PFC（Priority-based Flow Control）]"
"[SONiCPFC]。\n"
"- `pfcwd`目录：用来配置和查看SONiC中的[PFC Watch Dog][SONiCPFCWD]，比如启动，"
"停止，修改polling interval之类的操作。"

#: src/3-1-code-repos.md:125
msgid "## 内核补丁：sonic-linux-kernel"
msgstr "## 内核补丁：sonic-linux-kernel"

#: src/3-1-code-repos.md:127
msgid "<https://github.com/sonic-net/sonic-linux-kernel>"
msgstr "<https://github.com/sonic-net/sonic-linux-kernel>"

#: src/3-1-code-repos.md:129
msgid ""
"虽然SONiC是基于debian的，但是默认的debian内核却不一定能运行SONiC，比如某个模"
"块默认没有启动，或者某些老版本的驱动有问题，所以SONiC需要或多或少有一些修改的"
"Linux内核。而这个仓库就是用来存放所有的内核补丁的。"
msgstr ""
"虽然SONiC是基于debian的，但是默认的debian内核却不一定能运行SONiC，比如某个模"
"块默认没有启动，或者某些老版本的驱动有问题，所以SONiC需要或多或少有一些修改的"
"Linux内核。而这个仓库就是用来存放所有的内核补丁的。"

#: src/3-1-code-repos.md:133
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SONiC Source Repositories][SONiCRepo]\n"
"3. [SONiC Management Framework][SONiCMgmtFramework]\n"
"4. [SAI API][SAIAPI]\n"
"5. [SONiC Critical Resource Monitoring][SONiCCRM]\n"
"6. [SONiC Zero Touch Provisioning][SONiCZTP]\n"
"7. [SONiC Critical Resource Monitoring][SONiCCRM]\n"
"8. [SONiC P4 Integrated Network Stack][SONiCPINS]\n"
"9. [SONiC Disaggregated API for Switch Hosts][SONiCDash]\n"
"10. [SAI spec for OCP][SAISpec]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [SONiC Source Repositories][SONiCRepo]\n"
"3. [SONiC Management Framework][SONiCMgmtFramework]\n"
"4. [SAI API][SAIAPI]\n"
"5. [SONiC Critical Resource Monitoring][SONiCCRM]\n"
"6. [SONiC Zero Touch Provisioning][SONiCZTP]\n"
"7. [SONiC Critical Resource Monitoring][SONiCCRM]\n"
"8. [SONiC P4 Integrated Network Stack][SONiCPINS]\n"
"9. [SONiC Disaggregated API for Switch Hosts][SONiCDash]\n"
"10. [SAI spec for OCP][SAISpec]"

#: src/3-2-compile.md:1
msgid "# 编译"
msgstr "# 编译"

#: src/3-2-compile.md:3
msgid "## 编译环境"
msgstr "## 编译环境"

#: src/3-2-compile.md:5
msgid ""
"由于SONiC是基于debian开发的，为了保证我们无论在什么平台下都可以成功的编译"
"SONiC，并且编译出来的程序能在对应的平台上运行，SONiC使用了容器化的编译环境 "
"—— 它将所有的工具和依赖都安装在对应debian版本的docker容器中，然后将我们的代码"
"挂载进容器，最后在容器内部进行编译工作，这样我们就可以很轻松的在任何平台上编"
"译SONiC，而不用担心依赖不匹配的问题，比如有一些包在debian里的版本比ubuntu更"
"高，这样就可能导致最后的程序在debian上运行的时候出现一些意外的错误。"
msgstr ""
"由于SONiC是基于debian开发的，为了保证我们无论在什么平台下都可以成功的编译"
"SONiC，并且编译出来的程序能在对应的平台上运行，SONiC使用了容器化的编译环境 "
"—— 它将所有的工具和依赖都安装在对应debian版本的docker容器中，然后将我们的代码"
"挂载进容器，最后在容器内部进行编译工作，这样我们就可以很轻松的在任何平台上编"
"译SONiC，而不用担心依赖不匹配的问题，比如有一些包在debian里的版本比ubuntu更"
"高，这样就可能导致最后的程序在debian上运行的时候出现一些意外的错误。"

#: src/3-2-compile.md:7
msgid "## 初始化编译环境"
msgstr "## 初始化编译环境"

#: src/3-2-compile.md:9
msgid "### 安装Docker"
msgstr "### 安装Docker"

#: src/3-2-compile.md:11
msgid ""
"为了支持容器化的编译环境，第一步，我们需要保证我们的机器上安装了docker。"
msgstr ""
"为了支持容器化的编译环境，第一步，我们需要保证我们的机器上安装了docker。"

#: src/3-2-compile.md:13
msgid ""
"Docker的安装方法可以参考[官方文档][DockerInstall]，这里我们以Ubuntu为例，简单"
"介绍一下安装方法。"
msgstr ""
"Docker的安装方法可以参考[官方文档][DockerInstall]，这里我们以Ubuntu为例，简单"
"介绍一下安装方法。"

#: src/3-2-compile.md:15
msgid "首先，我们需要把docker的源和证书加入到apt的源列表中："
msgstr "首先，我们需要把docker的源和证书加入到apt的源列表中："

#: src/3-2-compile.md:17
msgid ""
"```bash\n"
"sudo apt-get update\n"
"sudo apt-get install ca-certificates curl gnupg\n"
"\n"
"sudo install -m 0755 -d /etc/apt/keyrings\n"
"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor "
"-o /etc/apt/keyrings/docker.gpg\n"
"sudo chmod a+r /etc/apt/keyrings/docker.gpg\n"
"\n"
"echo \\\n"
"  \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/"
"docker.gpg] https://download.docker.com/linux/ubuntu \\\n"
"  \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\n"
"  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n"
"```"
msgstr ""
"```bash\n"
"sudo apt-get update\n"
"sudo apt-get install ca-certificates curl gnupg\n"
"\n"
"sudo install -m 0755 -d /etc/apt/keyrings\n"
"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor "
"-o /etc/apt/keyrings/docker.gpg\n"
"sudo chmod a+r /etc/apt/keyrings/docker.gpg\n"
"\n"
"echo \\\n"
"  \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/"
"docker.gpg] https://download.docker.com/linux/ubuntu \\\n"
"  \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\n"
"  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n"
"```"

#: src/3-2-compile.md:31
msgid "然后，我们就可以通过apt来快速安装啦："
msgstr "然后，我们就可以通过apt来快速安装啦："

#: src/3-2-compile.md:33
msgid ""
"```bash\n"
"sudo apt-get update\n"
"sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-"
"plugin docker-compose-plugin\n"
"```"
msgstr ""
"```bash\n"
"sudo apt-get update\n"
"sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-"
"plugin docker-compose-plugin\n"
"```"

#: src/3-2-compile.md:38
msgid ""
"安装完docker的程序之后，我们还需要把当前的账户添加到docker的用户组中，然后**"
"退出并重新登录当前用户**，这样我们就可以不用sudo来运行docker命令了！**这一点"
"非常重要**，因为后续SONiC的build是不允许使用sudo的。"
msgstr ""
"安装完docker的程序之后，我们还需要把当前的账户添加到docker的用户组中，然后**"
"退出并重新登录当前用户**，这样我们就可以不用sudo来运行docker命令了！**这一点"
"非常重要**，因为后续SONiC的build是不允许使用sudo的。"

#: src/3-2-compile.md:40
msgid ""
"```bash\n"
"sudo gpasswd -a ${USER} docker\n"
"```"
msgstr ""
"```bash\n"
"sudo gpasswd -a ${USER} docker\n"
"```"

#: src/3-2-compile.md:44
msgid ""
"安装完成之后，别忘了通过以下命令来验证一下是否安装成功（注意，此处不需要"
"sudo！）："
msgstr ""
"安装完成之后，别忘了通过以下命令来验证一下是否安装成功（注意，此处不需要"
"sudo！）："

#: src/3-2-compile.md:46
msgid ""
"```bash\n"
"docker run hello-world\n"
"```"
msgstr ""
"```bash\n"
"docker run hello-world\n"
"```"

#: src/3-2-compile.md:50
msgid "### 安装其他依赖"
msgstr "### 安装其他依赖"

#: src/3-2-compile.md:52
msgid ""
"```bash\n"
"sudo apt install -y python3-pip\n"
"pip3 install --user j2cli\n"
"```"
msgstr ""
"```bash\n"
"sudo apt install -y python3-pip\n"
"pip3 install --user j2cli\n"
"```"

#: src/3-2-compile.md:57
msgid "### 拉取代码"
msgstr "### 拉取代码"

#: src/3-2-compile.md:59
msgid ""
"在[3.1 代码仓库](./3-1-code-repos)一章中，我们提到了SONiC的主仓库是[sonic-"
"buildimage][SonicBuildimageRepo]。它也是我们目前为止唯一需要安装关注的repo。"
msgstr ""
"在[3.1 代码仓库](./3-1-code-repos)一章中，我们提到了SONiC的主仓库是[sonic-"
"buildimage][SonicBuildimageRepo]。它也是我们目前为止唯一需要安装关注的repo。"

#: src/3-2-compile.md:61
msgid ""
"因为这个仓库通过submodule的形式将其他所有和编译相关的仓库包含在内，我们通过"
"git命令拉取代码时需要注意加上`--recuse-submodules`的选项："
msgstr ""
"因为这个仓库通过submodule的形式将其他所有和编译相关的仓库包含在内，我们通过"
"git命令拉取代码时需要注意加上`--recuse-submodules`的选项："

#: src/3-2-compile.md:63
msgid ""
"```bash\n"
"git clone --recurse-submodules https://github.com/sonic-net/sonic-buildimage."
"git\n"
"```"
msgstr ""
"```bash\n"
"git clone --recurse-submodules https://github.com/sonic-net/sonic-buildimage."
"git\n"
"```"

#: src/3-2-compile.md:67
msgid "如果在拉取代码的时候忘记拉取submodule，可以通过以下命令来补上："
msgstr "如果在拉取代码的时候忘记拉取submodule，可以通过以下命令来补上："

#: src/3-2-compile.md:69
msgid ""
"```bash\n"
"git submodule update --init --recursive\n"
"```"
msgstr ""
"```bash\n"
"git submodule update --init --recursive\n"
"```"

#: src/3-2-compile.md:73
msgid ""
"当代码下载完毕之后，或者对于已有的repo，我们就可以通过以下命令来初始化编译环"
"境了。这个命令更新当前所有的submodule到需要的版本，以帮助我们成功编译："
msgstr ""
"当代码下载完毕之后，或者对于已有的repo，我们就可以通过以下命令来初始化编译环"
"境了。这个命令更新当前所有的submodule到需要的版本，以帮助我们成功编译："

#: src/3-2-compile.md:75
msgid ""
"```bash\n"
"sudo modprobe overlay\n"
"make init\n"
"```"
msgstr ""
"```bash\n"
"sudo modprobe overlay\n"
"make init\n"
"```"

#: src/3-2-compile.md:80
msgid "## 了解并设置你的目标平台"
msgstr "## 了解并设置你的目标平台"

#: src/3-2-compile.md:82
msgid ""
"[SONiC虽然支持非常多种不同的交换机][SONiCDevices]，但是由于不同型号的交换机使"
"用的ASIC不同，所使用的驱动和SDK也会不同。SONiC通过SAI来封装这些变化，为上层提"
"供统一的配置接口，但是在编译的时候，我们需要正确的设置好，这样才能保证我们编"
"译出来的SONiC可以在我们的目标平台上运行。"
msgstr ""
"[SONiC虽然支持非常多种不同的交换机][SONiCDevices]，但是由于不同型号的交换机使"
"用的ASIC不同，所使用的驱动和SDK也会不同。SONiC通过SAI来封装这些变化，为上层提"
"供统一的配置接口，但是在编译的时候，我们需要正确的设置好，这样才能保证我们编"
"译出来的SONiC可以在我们的目标平台上运行。"

#: src/3-2-compile.md:84
msgid "现在，SONiC主要支持如下几个平台："
msgstr "现在，SONiC主要支持如下几个平台："

#: src/3-2-compile.md:86
msgid ""
"- barefoot\n"
"- broadcom\n"
"- marvell\n"
"- mellanox\n"
"- cavium\n"
"- centec\n"
"- nephos\n"
"- innovium\n"
"- vs"
msgstr ""
"- barefoot\n"
"- broadcom\n"
"- marvell\n"
"- mellanox\n"
"- cavium\n"
"- centec\n"
"- nephos\n"
"- innovium\n"
"- vs"

#: src/3-2-compile.md:96
msgid "在确认好平台之后，我们就可以运行如下命令来配置我们的编译环境了："
msgstr "在确认好平台之后，我们就可以运行如下命令来配置我们的编译环境了："

#: src/3-2-compile.md:98
msgid ""
"```bash\n"
"make PLATFORM=<platform> configure\n"
"# e.g.: make PLATFORM=mellanox configure\n"
"```"
msgstr ""
"```bash\n"
"make PLATFORM=<platform> configure\n"
"# e.g.: make PLATFORM=mellanox configure\n"
"```"

#: src/3-2-compile.md:103
msgid ""
"```admonish note\n"
"<b>所有的make命令</b>（除了`make init`）一开始都会检查并创建所有debian版本的"
"docker builder：bullseye，stretch，jessie，buster。每个builder都需要几十分钟"
"的时间才能创建完成，这对于我们平时开发而言实在完全没有必要，一般来说，我们只"
"需要创建最新的版本即可（当前为bullseye，bookwarm暂时还没有支持），具体命令如"
"下：\n"
"\n"
"    NOJESSIE=1 NOSTRETCH=1 NOBUSTER=1 make PLATFORM=<platform> configure\n"
"\n"
"当然，为了以后开发更加方便，避免重复输入，我们可以将这个命令写入到`~/.bashrc`"
"中，这样每次打开终端的时候，就会设置好这些环境变量了。\n"
"\n"
"    export NOJESSIE=1\n"
"    export NOSTRETCH=1\n"
"    export NOBUSTER=1\n"
"```"
msgstr ""
"```admonish note\n"
"<b>所有的make命令</b>（除了`make init`）一开始都会检查并创建所有debian版本的"
"docker builder：bullseye，stretch，jessie，buster。每个builder都需要几十分钟"
"的时间才能创建完成，这对于我们平时开发而言实在完全没有必要，一般来说，我们只"
"需要创建最新的版本即可（当前为bullseye，bookwarm暂时还没有支持），具体命令如"
"下：\n"
"\n"
"    NOJESSIE=1 NOSTRETCH=1 NOBUSTER=1 make PLATFORM=<platform> configure\n"
"\n"
"当然，为了以后开发更加方便，避免重复输入，我们可以将这个命令写入到`~/.bashrc`"
"中，这样每次打开终端的时候，就会设置好这些环境变量了。\n"
"\n"
"    export NOJESSIE=1\n"
"    export NOSTRETCH=1\n"
"    export NOBUSTER=1\n"
"```"

#: src/3-2-compile.md:115
msgid "## 编译代码"
msgstr "## 编译代码"

#: src/3-2-compile.md:117
msgid "### 编译全部代码"
msgstr "### 编译全部代码"

#: src/3-2-compile.md:119
msgid "设置好平台之后，我们就可以开始编译代码了："
msgstr "设置好平台之后，我们就可以开始编译代码了："

#: src/3-2-compile.md:121
msgid ""
"```bash\n"
"# The number of jobs can be the number of cores on your machine.\n"
"# Say, if you have 16 cores, then feel free to set it to 16 to speed up the "
"build.\n"
"make SONIC_BUILD_JOBS=4 all\n"
"```"
msgstr ""
"```bash\n"
"# The number of jobs can be the number of cores on your machine.\n"
"# Say, if you have 16 cores, then feel free to set it to 16 to speed up the "
"build.\n"
"make SONIC_BUILD_JOBS=4 all\n"
"```"

#: src/3-2-compile.md:127
msgid ""
"```admonish note\n"
"当然，对于开发而言，我们可以把SONIC_BUILD_JOBS和上面其他变量一起也加入`~/."
"bashrc`中，减少我们的输入。\n"
"\n"
"    export SONIC_BUILD_JOBS=<number of cores>\n"
"```"
msgstr ""
"```admonish note\n"
"当然，对于开发而言，我们可以把SONIC_BUILD_JOBS和上面其他变量一起也加入`~/."
"bashrc`中，减少我们的输入。\n"
"\n"
"    export SONIC_BUILD_JOBS=<number of cores>\n"
"```"

#: src/3-2-compile.md:133
msgid "### 编译子项目代码"
msgstr "### 编译子项目代码"

#: src/3-2-compile.md:135
msgid ""
"我们从SONiC的Build Pipeline中就会发现，编译整个项目是非常耗时的，而绝大部分时"
"候，我们的代码改动只会影响很小部分的代码，所以有没有办法减少我们编译的工作量"
"呢？答案是肯定的，我们可以通过指定make target来仅编译我们需要的子项目。"
msgstr ""
"我们从SONiC的Build Pipeline中就会发现，编译整个项目是非常耗时的，而绝大部分时"
"候，我们的代码改动只会影响很小部分的代码，所以有没有办法减少我们编译的工作量"
"呢？答案是肯定的，我们可以通过指定make target来仅编译我们需要的子项目。"

#: src/3-2-compile.md:137
msgid "SONiC中每个子项目生成的文件都可以在`target`目录中找到，比如："
msgstr "SONiC中每个子项目生成的文件都可以在`target`目录中找到，比如："

#: src/3-2-compile.md:139
msgid ""
"- Docker containers: target/<docker-image>.gz，比如：`target/docker-"
"orchagent.gz`\n"
"- Deb packages: target/debs/<debian-version>/<package>.deb，比如：`target/"
"debs/bullseye/libswsscommon_1.0.0_amd64.deb`\n"
"- Python wheels: target/python-wheels/<debian-version>/<package>.whl，比如："
"`target/python-wheels/bullseye/sonic_utilities-1.2-py3-none-any.whl`"
msgstr ""
"- Docker containers: target/<docker-image>.gz，比如：`target/docker-"
"orchagent.gz`\n"
"- Deb packages: target/debs/<debian-version>/<package>.deb，比如：`target/"
"debs/bullseye/libswsscommon_1.0.0_amd64.deb`\n"
"- Python wheels: target/python-wheels/<debian-version>/<package>.whl，比如："
"`target/python-wheels/bullseye/sonic_utilities-1.2-py3-none-any.whl`"

#: src/3-2-compile.md:143
msgid ""
"当我们找到了我们需要的子项目之后，我们便可以将其生成的文件删除，然后重新调用"
"make命令，这里我们用`libswsscommon`来举例子，如下："
msgstr ""
"当我们找到了我们需要的子项目之后，我们便可以将其生成的文件删除，然后重新调用"
"make命令，这里我们用`libswsscommon`来举例子，如下："

#: src/3-2-compile.md:145
msgid ""
"```bash\n"
"# Remove the deb package for bullseye\n"
"rm target/debs/bullseye/libswsscommon_1.0.0_amd64.deb\n"
"\n"
"# Build the deb package for bullseye\n"
"NOJESSIE=1 NOSTRETCH=1 NOBUSTER=1 make target/debs/bullseye/"
"libswsscommon_1.0.0_amd64.deb\n"
"```"
msgstr ""
"```bash\n"
"# Remove the deb package for bullseye\n"
"rm target/debs/bullseye/libswsscommon_1.0.0_amd64.deb\n"
"\n"
"# Build the deb package for bullseye\n"
"NOJESSIE=1 NOSTRETCH=1 NOBUSTER=1 make target/debs/bullseye/"
"libswsscommon_1.0.0_amd64.deb\n"
"```"

#: src/3-2-compile.md:153
msgid "### 检查和处理编译错误"
msgstr "### 检查和处理编译错误"

#: src/3-2-compile.md:155
msgid ""
"如果不巧在编译的时候发生了错误，我们可以通过检查失败项目的日志文件来查看具体"
"的原因。在SONiC中，每一个子编译项目都会生成其相关的日志文件，我们可以很容易的"
"在`target`目录中找到，如下："
msgstr ""
"如果不巧在编译的时候发生了错误，我们可以通过检查失败项目的日志文件来查看具体"
"的原因。在SONiC中，每一个子编译项目都会生成其相关的日志文件，我们可以很容易的"
"在`target`目录中找到，如下："

#: src/3-2-compile.md:157
msgid ""
"```bash\n"
"$ ls -l\n"
"...\n"
"-rw-r--r--  1 r12f r12f 103M Jun  8 22:35 docker-database.gz\n"
"-rw-r--r--  1 r12f r12f  26K Jun  8 22:35 docker-database.gz.log      // Log "
"file for docker-database.gz\n"
"-rw-r--r--  1 r12f r12f 106M Jun  8 22:44 docker-dhcp-relay.gz\n"
"-rw-r--r--  1 r12f r12f 106K Jun  8 22:44 docker-dhcp-relay.gz.log    // Log "
"file for docker-dhcp-relay.gz\n"
"```"
msgstr ""
"```bash\n"
"$ ls -l\n"
"...\n"
"-rw-r--r--  1 r12f r12f 103M Jun  8 22:35 docker-database.gz\n"
"-rw-r--r--  1 r12f r12f  26K Jun  8 22:35 docker-database.gz.log      // Log "
"file for docker-database.gz\n"
"-rw-r--r--  1 r12f r12f 106M Jun  8 22:44 docker-dhcp-relay.gz\n"
"-rw-r--r--  1 r12f r12f 106K Jun  8 22:44 docker-dhcp-relay.gz.log    // Log "
"file for docker-dhcp-relay.gz\n"
"```"

#: src/3-2-compile.md:166
msgid ""
"如果我们不想每次在更新代码之后都去代码的根目录下重新编译，然后查看日志文件，"
"SONiC还提供了一个更加方便的方法，能让我们在编译完成之后停在docker builder中，"
"这样我们就可以直接去对应的目录运行`make`命令来重新编译了："
msgstr ""
"如果我们不想每次在更新代码之后都去代码的根目录下重新编译，然后查看日志文件，"
"SONiC还提供了一个更加方便的方法，能让我们在编译完成之后停在docker builder中，"
"这样我们就可以直接去对应的目录运行`make`命令来重新编译了："

#: src/3-2-compile.md:168
msgid ""
"```bash\n"
"# KEEP_SLAVE_ON=yes make <target>\n"
"KEEP_SLAVE_ON=yes make target/debs/bullseye/libswsscommon_1.0.0_amd64.deb\n"
"KEEP_SLAVE_ON=yes make all\n"
"```"
msgstr ""
"```bash\n"
"# KEEP_SLAVE_ON=yes make <target>\n"
"KEEP_SLAVE_ON=yes make target/debs/bullseye/libswsscommon_1.0.0_amd64.deb\n"
"KEEP_SLAVE_ON=yes make all\n"
"```"

#: src/3-2-compile.md:174
msgid ""
"```admonish note\n"
"有些仓库中的部分代码在全量编译的时候是不会编译的，比如，`sonic-swss-common`中"
"的gtest，所以使用这种方法重编译的时候，请一定注意查看原仓库的编译指南，以避免"
"出错，如：<https://github.com/sonic-net/sonic-swss-common#build-from-"
"source>。\n"
"```"
msgstr ""
"```admonish note\n"
"有些仓库中的部分代码在全量编译的时候是不会编译的，比如，`sonic-swss-common`中"
"的gtest，所以使用这种方法重编译的时候，请一定注意查看原仓库的编译指南，以避免"
"出错，如：<https://github.com/sonic-net/sonic-swss-common#build-from-"
"source>。\n"
"```"

#: src/3-2-compile.md:178
msgid "## 获取正确的镜像文件"
msgstr "## 获取正确的镜像文件"

#: src/3-2-compile.md:180
msgid ""
"编译完成之后，我们就可以在`target`目录中找到我们需要的镜像文件了，但是这里有"
"一个问题：我们到底要用哪一种镜像来把SONiC安装到我们的交换机上呢？这里主要取决"
"于交换机使用什么样的BootLoader或者安装程序，其映射关系如下："
msgstr ""
"编译完成之后，我们就可以在`target`目录中找到我们需要的镜像文件了，但是这里有"
"一个问题：我们到底要用哪一种镜像来把SONiC安装到我们的交换机上呢？这里主要取决"
"于交换机使用什么样的BootLoader或者安装程序，其映射关系如下："

#: src/3-2-compile.md:182
msgid ""
"| Bootloader | 后缀 |\n"
"| --- | --- |\n"
"| Aboot | .swi |\n"
"| ONIE | .bin |\n"
"| Grub | .img.gz |"
msgstr ""
"| Bootloader | 后缀 |\n"
"| --- | --- |\n"
"| Aboot | .swi |\n"
"| ONIE | .bin |\n"
"| Grub | .img.gz |"

#: src/3-2-compile.md:188
msgid "## 部分升级"
msgstr "## 部分升级"

#: src/3-2-compile.md:190
msgid ""
"显然，在开发的时候，每次都编译安装镜像然后进行全量安装的效率是相当低下的，所"
"以我们可以选择不安装镜像而使用直接升级deb包的方式来进行部分升级，从而提高我们"
"的开发效率。"
msgstr ""
"显然，在开发的时候，每次都编译安装镜像然后进行全量安装的效率是相当低下的，所"
"以我们可以选择不安装镜像而使用直接升级deb包的方式来进行部分升级，从而提高我们"
"的开发效率。"

#: src/3-2-compile.md:192
msgid ""
"我们可以将deb包上传到交换机的`/etc/sonic`目录下，这个目录下的文件会被map到所"
"有容器的`/etc/sonic`目录下，接着我们可以进入到容器中，然后使用`dpkg`命令来安"
"装deb包，如下："
msgstr ""
"我们可以将deb包上传到交换机的`/etc/sonic`目录下，这个目录下的文件会被map到所"
"有容器的`/etc/sonic`目录下，接着我们可以进入到容器中，然后使用`dpkg`命令来安"
"装deb包，如下："

#: src/3-2-compile.md:194
msgid ""
"```bash\n"
"# Enter the docker container\n"
"docker exec -it <container> bash\n"
"\n"
"# Install deb package\n"
"dpkg -i <deb-package>\n"
"```"
msgstr ""
"```bash\n"
"# Enter the docker container\n"
"docker exec -it <container> bash\n"
"\n"
"# Install deb package\n"
"dpkg -i <deb-package>\n"
"```"

#: src/3-2-compile.md:204
msgid ""
"1. [SONiC Build Guide][SONiCBuild]\n"
"2. [Install Docker Engine][DockerInstall]\n"
"3. [Github repo: sonic-buildimage][SonicBuildimageRepo]\n"
"4. [SONiC Supported Devices and Platforms][SONiCDevices]\n"
"5. [Wrapper for starting make inside sonic-slave container]"
"[SONiCBuildImageMakeFile]"
msgstr ""
"1. [SONiC Build Guide][SONiCBuild]\n"
"2. [Install Docker Engine][DockerInstall]\n"
"3. [Github repo: sonic-buildimage][SonicBuildimageRepo]\n"
"4. [SONiC Supported Devices and Platforms][SONiCDevices]\n"
"5. [Wrapper for starting make inside sonic-slave container]"
"[SONiCBuildImageMakeFile]"

#: src/3-3-debugging.md:1
msgid "# 调试"
msgstr "# 调试"

#: src/4-communications.md:1
msgid "# 通信机制"
msgstr "# 通信机制"

#: src/4-communications.md:3
msgid "SONiC中主要的通信机制有两种：与内核的通信和基于Redis的服务间的通信。"
msgstr "SONiC中主要的通信机制有两种：与内核的通信和基于Redis的服务间的通信。"

#: src/4-communications.md:5
msgid ""
"- 与内核通信主要有两种方法：命令行调用和Netlink消息。\n"
"- 而基于Redis的服务间通信主要有四种方法：SubscriberStateTable，"
"NotificationProducer/Consumer，Producer/ConsumerTable，Producer/"
"ConsumerStateTable。虽然它们都是基于Redis的，但是它们解决的问题和方法却非常不"
"同。"
msgstr ""
"- 与内核通信主要有两种方法：命令行调用和Netlink消息。\n"
"- 而基于Redis的服务间通信主要有四种方法：SubscriberStateTable，"
"NotificationProducer/Consumer，Producer/ConsumerTable，Producer/"
"ConsumerStateTable。虽然它们都是基于Redis的，但是它们解决的问题和方法却非常不"
"同。"

#: src/4-communications.md:8
msgid ""
"所有这些基础的通信机制的实现都在[sonic-swss-common][SONiCSWSSCommon]这个repo"
"中的`common`目录下。另外在其之上，为了方便各个服务使用，SONiC还在[sonic-swss]"
"[SONiCSWSS]中封装了一层Orch，将常用的表放在其中。"
msgstr ""
"所有这些基础的通信机制的实现都在[sonic-swss-common][SONiCSWSSCommon]这个repo"
"中的`common`目录下。另外在其之上，为了方便各个服务使用，SONiC还在[sonic-swss]"
"[SONiCSWSS]中封装了一层Orch，将常用的表放在其中。"

#: src/4-communications.md:10
msgid "这一章，我们就主要来看看这些通信机制的实现吧！"
msgstr "这一章，我们就主要来看看这些通信机制的实现吧！"

#: src/4-communications.md:14 src/4-2-1-redis-wrappers.md:35
#: src/4-2-3-orch-layer.md:36 src/4-3-event-polling-and-error-handling.md:121
#: src/5-2-bgp-workflow.md:9
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-swss][SONiCSWSS]\n"
"3. [Github repo: sonic-swss-common][SONiCSWSSCommon]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-swss][SONiCSWSS]\n"
"3. [Github repo: sonic-swss-common][SONiCSWSSCommon]"

#: src/4-1-1-exec.md:1
msgid "# 命令行调用"
msgstr "# 命令行调用"

#: src/4-1-1-exec.md:3
msgid ""
"SONiC中的与内核通信最简单的方式就是命令行调用了，其实现放在[common/exec.h]"
"(https://github.com/sonic-net/sonic-swss-common/blob/master/common/exec.h)文"
"件下，且十分简单，接口如下："
msgstr ""
"SONiC中的与内核通信最简单的方式就是命令行调用了，其实现放在[common/exec.h]"
"(https://github.com/sonic-net/sonic-swss-common/blob/master/common/exec.h)文"
"件下，且十分简单，接口如下："

#: src/4-1-1-exec.md:5
msgid ""
"```cpp\n"
"// File: common/exec.h\n"
"// Namespace: swss\n"
"int exec(const std::string &cmd, std::string &stdout);\n"
"```"
msgstr ""
"```cpp\n"
"// File: common/exec.h\n"
"// Namespace: swss\n"
"int exec(const std::string &cmd, std::string &stdout);\n"
"```"

#: src/4-1-1-exec.md:11
msgid ""
"其中，`cmd`是要执行的命令，`stdout`是命令执行的输出。这里的`exec`函数是一个同"
"步调用，调用者会一直阻塞，直到命令执行完毕。其内部通过调用`popen`函数来创建子"
"进程，并且通过`fgets`函数来获取输出。不过，**虽然这个函数返回了输出，但是基本"
"上并没有人使用**，而只是通过返回值来判断是否成功，甚至连错误log中都不会写入输"
"出的结果。"
msgstr ""
"其中，`cmd`是要执行的命令，`stdout`是命令执行的输出。这里的`exec`函数是一个同"
"步调用，调用者会一直阻塞，直到命令执行完毕。其内部通过调用`popen`函数来创建子"
"进程，并且通过`fgets`函数来获取输出。不过，**虽然这个函数返回了输出，但是基本"
"上并没有人使用**，而只是通过返回值来判断是否成功，甚至连错误log中都不会写入输"
"出的结果。"

#: src/4-1-1-exec.md:13
msgid ""
"这个函数虽然粗暴，但是使用广泛，特别是在各个`*mgrd`服务中，比如`portmgrd`中就"
"用它来设置每一个Port的状态等等。"
msgstr ""
"这个函数虽然粗暴，但是使用广泛，特别是在各个`*mgrd`服务中，比如`portmgrd`中就"
"用它来设置每一个Port的状态等等。"

#: src/4-1-1-exec.md:15
msgid ""
"```cpp\n"
"// File: sonic-swss - cfgmgr/portmgr.cpp\n"
"bool PortMgr::setPortAdminStatus(const string &alias, const bool up)\n"
"{\n"
"    stringstream cmd;\n"
"    string res, cmd_str;\n"
"\n"
"    // ip link set dev <port_name> [up|down]\n"
"    cmd << IP_CMD << \" link set dev \" << shellquote(alias) << (up ? \" "
"up\" : \" down\");\n"
"    cmd_str = cmd.str();\n"
"    int ret = swss::exec(cmd_str, res);\n"
"\n"
"    // ...\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss - cfgmgr/portmgr.cpp\n"
"bool PortMgr::setPortAdminStatus(const string &alias, const bool up)\n"
"{\n"
"    stringstream cmd;\n"
"    string res, cmd_str;\n"
"\n"
"    // ip link set dev <port_name> [up|down]\n"
"    cmd << IP_CMD << \" link set dev \" << shellquote(alias) << (up ? \" "
"up\" : \" down\");\n"
"    cmd_str = cmd.str();\n"
"    int ret = swss::exec(cmd_str, res);\n"
"\n"
"    // ...\n"
"```"

#: src/4-1-1-exec.md:30
msgid ""
"```admonish note\n"
"**为什么说命令行调用是一种通信机制呢**？\n"
"\n"
"原因是当`*mgrd`服务调用`exec`函数对系统进行的修改，会触发下面马上会提到的"
"netlink事件，从而通知其他服务进行相应的修改，比如`*syncd`，这样就间接的构成了"
"一种通信。所以这里我们把命令行调用看作一种通信机制能帮助我们以后更好的理解"
"SONiC的各种工作流。\n"
"```"
msgstr ""
"```admonish note\n"
"**为什么说命令行调用是一种通信机制呢**？\n"
"\n"
"原因是当`*mgrd`服务调用`exec`函数对系统进行的修改，会触发下面马上会提到的"
"netlink事件，从而通知其他服务进行相应的修改，比如`*syncd`，这样就间接的构成了"
"一种通信。所以这里我们把命令行调用看作一种通信机制能帮助我们以后更好的理解"
"SONiC的各种工作流。\n"
"```"

#: src/4-1-1-exec.md:38 src/4-1-2-netlink.md:72
msgid "1. [Github repo: sonic-swss-common][SONiCSWSSCommon]"
msgstr "1. [Github repo: sonic-swss-common][SONiCSWSSCommon]"

#: src/4-1-2-netlink.md:1
msgid "# Netlink"
msgstr "# Netlink"

#: src/4-1-2-netlink.md:3
msgid ""
"Netlink是Linux内核中用于内核与用户空间进程之间的一种基于消息的通信机制。它通"
"过套接字接口和自定义的协议族来实现，可以用来传递各种类型的内核消息，包括网络"
"设备状态、路由表更新、防火墙规则变化、系统资源使用情况等等。而SONiC的`*sync`"
"服务就大量使用了Netlink的机制来监听系统中网络设备的变化，并将最新的状态同步到"
"Redis中，并通知其他服务进行相应的修改。"
msgstr ""
"Netlink是Linux内核中用于内核与用户空间进程之间的一种基于消息的通信机制。它通"
"过套接字接口和自定义的协议族来实现，可以用来传递各种类型的内核消息，包括网络"
"设备状态、路由表更新、防火墙规则变化、系统资源使用情况等等。而SONiC的`*sync`"
"服务就大量使用了Netlink的机制来监听系统中网络设备的变化，并将最新的状态同步到"
"Redis中，并通知其他服务进行相应的修改。"

#: src/4-1-2-netlink.md:5
msgid ""
"Netlink的实现主要在这几个文件中：[common/netmsg.*](https://github.com/sonic-"
"net/sonic-swss-common/blob/master/common/netmsg.h)、[common/netlink.*]"
"(https://github.com/sonic-net/sonic-swss-common/blob/master/common/netlink."
"h) 和 [common/netdispatcher.*](https://github.com/sonic-net/sonic-swss-"
"common/blob/master/common/netdispatcher.h)，具体类图如下："
msgstr ""
"Netlink的实现主要在这几个文件中：[common/netmsg.*](https://github.com/sonic-"
"net/sonic-swss-common/blob/master/common/netmsg.h)、[common/netlink.*]"
"(https://github.com/sonic-net/sonic-swss-common/blob/master/common/netlink."
"h) 和 [common/netdispatcher.*](https://github.com/sonic-net/sonic-swss-"
"common/blob/master/common/netdispatcher.h)，具体类图如下："

#: src/4-1-2-netlink.md:9 src/4-2-1-redis-wrappers.md:9
msgid "其中："
msgstr "其中："

#: src/4-1-2-netlink.md:11
msgid ""
"- **Netlink**：封装了Netlink的套接字接口，提供了Netlink消息的接口和接收消息的"
"回调。\n"
"- **NetDispatcher**：它是一个单例，提供了Handler注册的接口。当Netlink类接收到"
"原始的消息后，就会调用NetDispatcher将其解析成nl_onject，并根据消息的类型调用"
"相应的Handler。\n"
"- **NetMsg**：Netlink消息Handler的基类，仅提供了onMsg的接口，其中没有实现。"
msgstr ""
"- **Netlink**：封装了Netlink的套接字接口，提供了Netlink消息的接口和接收消息的"
"回调。\n"
"- **NetDispatcher**：它是一个单例，提供了Handler注册的接口。当Netlink类接收到"
"原始的消息后，就会调用NetDispatcher将其解析成nl_onject，并根据消息的类型调用"
"相应的Handler。\n"
"- **NetMsg**：Netlink消息Handler的基类，仅提供了onMsg的接口，其中没有实现。"

#: src/4-1-2-netlink.md:15
msgid ""
"举一个例子，当`portsyncd`启动的时候，它会创建一个Netlink对象，用来监听Link相"
"关的状态变化，并且会实现NetMsg的接口，对Link相关的消息进行处理。具体的实现如"
"下："
msgstr ""
"举一个例子，当`portsyncd`启动的时候，它会创建一个Netlink对象，用来监听Link相"
"关的状态变化，并且会实现NetMsg的接口，对Link相关的消息进行处理。具体的实现如"
"下："

#: src/4-1-2-netlink.md:17
msgid ""
"```cpp\n"
"// File: sonic-swss - portsyncd/portsyncd.cpp\n"
"int main(int argc, char **argv)\n"
"{\n"
"    // ...\n"
"\n"
"    // Create Netlink object to listen to link messages\n"
"    NetLink netlink;\n"
"    netlink.registerGroup(RTNLGRP_LINK);\n"
"\n"
"    // Here SONiC request a fulldump of current state, so that it can get "
"the current state of all links\n"
"    netlink.dumpRequest(RTM_GETLINK);      \n"
"    cout << \"Listen to link messages...\" << endl;\n"
"    // ...\n"
"\n"
"    // Register handler for link messages\n"
"    LinkSync sync(&appl_db, &state_db);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_NEWLINK, "
"&sync);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_DELLINK, "
"&sync);\n"
"\n"
"    // ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss - portsyncd/portsyncd.cpp\n"
"int main(int argc, char **argv)\n"
"{\n"
"    // ...\n"
"\n"
"    // Create Netlink object to listen to link messages\n"
"    NetLink netlink;\n"
"    netlink.registerGroup(RTNLGRP_LINK);\n"
"\n"
"    // Here SONiC request a fulldump of current state, so that it can get "
"the current state of all links\n"
"    netlink.dumpRequest(RTM_GETLINK);      \n"
"    cout << \"Listen to link messages...\" << endl;\n"
"    // ...\n"
"\n"
"    // Register handler for link messages\n"
"    LinkSync sync(&appl_db, &state_db);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_NEWLINK, "
"&sync);\n"
"    NetDispatcher::getInstance().registerMessageHandler(RTM_DELLINK, "
"&sync);\n"
"\n"
"    // ...\n"
"}\n"
"```"

#: src/4-1-2-netlink.md:41
msgid ""
"上面的LinkSync，就是一个NetMsg的实现，它实现了onMsg接口，用来处理Link相关的消"
"息："
msgstr ""
"上面的LinkSync，就是一个NetMsg的实现，它实现了onMsg接口，用来处理Link相关的消"
"息："

#: src/4-1-2-netlink.md:43
msgid ""
"```cpp\n"
"// File: sonic-swss - portsyncd/linksync.h\n"
"class LinkSync : public NetMsg\n"
"{\n"
"public:\n"
"    LinkSync(DBConnector *appl_db, DBConnector *state_db);\n"
"\n"
"    // NetMsg interface\n"
"    virtual void onMsg(int nlmsg_type, struct nl_object *obj);\n"
"\n"
"    // ...\n"
"};\n"
"\n"
"// File: sonic-swss - portsyncd/linksync.cpp\n"
"void LinkSync::onMsg(int nlmsg_type, struct nl_object *obj)\n"
"{\n"
"    // ...\n"
"\n"
"    // Write link state to Redis DB\n"
"    FieldValueTuple fv(\"oper_status\", oper ? \"up\" : \"down\");\n"
"    vector<FieldValueTuple> fvs;\n"
"    fvs.push_back(fv);\n"
"    m_stateMgmtPortTable.set(key, fvs);\n"
"    // ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss - portsyncd/linksync.h\n"
"class LinkSync : public NetMsg\n"
"{\n"
"public:\n"
"    LinkSync(DBConnector *appl_db, DBConnector *state_db);\n"
"\n"
"    // NetMsg interface\n"
"    virtual void onMsg(int nlmsg_type, struct nl_object *obj);\n"
"\n"
"    // ...\n"
"};\n"
"\n"
"// File: sonic-swss - portsyncd/linksync.cpp\n"
"void LinkSync::onMsg(int nlmsg_type, struct nl_object *obj)\n"
"{\n"
"    // ...\n"
"\n"
"    // Write link state to Redis DB\n"
"    FieldValueTuple fv(\"oper_status\", oper ? \"up\" : \"down\");\n"
"    vector<FieldValueTuple> fvs;\n"
"    fvs.push_back(fv);\n"
"    m_stateMgmtPortTable.set(key, fvs);\n"
"    // ...\n"
"}\n"
"```"

#: src/4-2-1-redis-wrappers.md:1
msgid "# Redis封装"
msgstr "# Redis封装"

#: src/4-2-1-redis-wrappers.md:3
msgid "## Redis数据库操作层"
msgstr "## Redis数据库操作层"

#: src/4-2-1-redis-wrappers.md:5
msgid ""
"第一层，也是最底层，是Redis的数据库操作层，封装了各种基本命令，比如，DB的连"
"接，命令的执行，事件通知的回调接口等等。具体的类图如下："
msgstr ""
"第一层，也是最底层，是Redis的数据库操作层，封装了各种基本命令，比如，DB的连"
"接，命令的执行，事件通知的回调接口等等。具体的类图如下："

#: src/4-2-1-redis-wrappers.md:11
msgid ""
"- **[RedisContext](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/dbconnector.h)**：封装并保持着与Redis的连接，当其销毁时会将其连"
"接关闭。\n"
"- **[DBConnector](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/dbconnector.h)**：封装了所有的底层使用到的Redis的命令，比如`SET`、"
"`GET`、`DEL`等等。\n"
"- **[RedisTransactioner](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/redistran.h)**：封装了Redis的事务操作，用于在一个事务中执行多个"
"命令，比如`MULTI`、`EXEC`等等。\n"
"- **[RedisPipeline](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/redispipeline.h)**：封装了hiredis的redisAppendFormattedCommand "
"API，提供了一个类似队列的异步的执行Redis命令的接口（虽然大部分使用方法依然是"
"同步的）。它也是少有的对`SCRIPT LOAD`命令进行了封装的类，用于在Redis中加载Lua"
"脚本实现存储过程。SONiC中绝大部分需要执行Lua脚本的类，都会使用这个类来进行加"
"载和调用。\n"
"- **[RedisSelect](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/redisselect.h)**：它实现了Selectable的接口，用来支持基于epoll的事件通"
"知机制（Event Polling）。主要是在我们收到了Redis的回复，用来触发epoll进行回调"
"（我们最后会更详细的介绍）。\n"
"- **[SonicDBConfig](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/dbconnector.h)**：这个类是一个“静态类”，它主要实现了SONiC DB的"
"配置文件的读取和解析。其他的数据库操作类，如果需要任何的配置信息，都会通过这"
"个类来获取。"
msgstr ""
"- **[RedisContext](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/dbconnector.h)**：封装并保持着与Redis的连接，当其销毁时会将其连"
"接关闭。\n"
"- **[DBConnector](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/dbconnector.h)**：封装了所有的底层使用到的Redis的命令，比如`SET`、"
"`GET`、`DEL`等等。\n"
"- **[RedisTransactioner](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/redistran.h)**：封装了Redis的事务操作，用于在一个事务中执行多个"
"命令，比如`MULTI`、`EXEC`等等。\n"
"- **[RedisPipeline](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/redispipeline.h)**：封装了hiredis的redisAppendFormattedCommand "
"API，提供了一个类似队列的异步的执行Redis命令的接口（虽然大部分使用方法依然是"
"同步的）。它也是少有的对`SCRIPT LOAD`命令进行了封装的类，用于在Redis中加载Lua"
"脚本实现存储过程。SONiC中绝大部分需要执行Lua脚本的类，都会使用这个类来进行加"
"载和调用。\n"
"- **[RedisSelect](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/redisselect.h)**：它实现了Selectable的接口，用来支持基于epoll的事件通"
"知机制（Event Polling）。主要是在我们收到了Redis的回复，用来触发epoll进行回调"
"（我们最后会更详细的介绍）。\n"
"- **[SonicDBConfig](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/dbconnector.h)**：这个类是一个“静态类”，它主要实现了SONiC DB的"
"配置文件的读取和解析。其他的数据库操作类，如果需要任何的配置信息，都会通过这"
"个类来获取。"

#: src/4-2-1-redis-wrappers.md:19
msgid "## 表（Table）抽象层"
msgstr "## 表（Table）抽象层"

#: src/4-2-1-redis-wrappers.md:21
msgid ""
"在Redis数据库操作层之上，便是SONiC自己利用Redis中间的Key建立的表（Table）的抽"
"象了，因为每一个Redis的Key的格式都是`<table-name><separator><key-name>`，所以"
"SONiC在访问数据库时需要对其进行一次转换（没有印象的小伙伴可以移步[我之前的博"
"客了解更多的信息](/posts/sonic-2-key-components/#数据库)）。"
msgstr ""
"在Redis数据库操作层之上，便是SONiC自己利用Redis中间的Key建立的表（Table）的抽"
"象了，因为每一个Redis的Key的格式都是`<table-name><separator><key-name>`，所以"
"SONiC在访问数据库时需要对其进行一次转换（没有印象的小伙伴可以移步[我之前的博"
"客了解更多的信息](/posts/sonic-2-key-components/#数据库)）。"

#: src/4-2-1-redis-wrappers.md:23
msgid "相关类的主要类图如下："
msgstr "相关类的主要类图如下："

#: src/4-2-1-redis-wrappers.md:27
msgid "其中关键的类有三个："
msgstr "其中关键的类有三个："

#: src/4-2-1-redis-wrappers.md:29
msgid ""
"- **[TableBase](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/table.h)**：这个类是所有表的基类，它主要封装了表的基本信息，如表的名"
"字，Redis Key的打包，每个表发生修改时用于通信的Channel的名字，等等。\n"
"- **[Table](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/table.h)**：这个类就是对于每个表增删改查的封装了，里面包含了表的名称和"
"分隔符，这样就可以在调用时构造最终的key了。\n"
"- **[ConsumerTableBase](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/consumertablebase.h)**：这个类是各种SubscriptionTable的基类，里"
"面主要是封装了一个简单的队列和其pop操作（对，只有pop，没有push），用来给上层"
"调用。"
msgstr ""
"- **[TableBase](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/table.h)**：这个类是所有表的基类，它主要封装了表的基本信息，如表的名"
"字，Redis Key的打包，每个表发生修改时用于通信的Channel的名字，等等。\n"
"- **[Table](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/table.h)**：这个类就是对于每个表增删改查的封装了，里面包含了表的名称和"
"分隔符，这样就可以在调用时构造最终的key了。\n"
"- **[ConsumerTableBase](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/consumertablebase.h)**：这个类是各种SubscriptionTable的基类，里"
"面主要是封装了一个简单的队列和其pop操作（对，只有pop，没有push），用来给上层"
"调用。"

#: src/4-2-2-redis-messaging-layer.md:1
msgid "# 通信层 - PubSub"
msgstr "# 通信层 - PubSub"

#: src/4-2-2-redis-messaging-layer.md:3
msgid ""
"在Redis的封装和表抽象之上，便是SONiC的通信层了，由于需求的不同，这一层中提供"
"了四种不同的PubSub的封装，用于服务间的通信。"
msgstr ""
"在Redis的封装和表抽象之上，便是SONiC的通信层了，由于需求的不同，这一层中提供"
"了四种不同的PubSub的封装，用于服务间的通信。"

#: src/4-2-2-redis-messaging-layer.md:5
msgid "## SubscribeStateTable"
msgstr "## SubscribeStateTable"

#: src/4-2-2-redis-messaging-layer.md:7
msgid ""
"最直接的就是[SubscriberStateTable](https://github.com/sonic-net/sonic-swss-"
"common/blob/master/common/subscriberstatetable.h)了。"
msgstr ""
"最直接的就是[SubscriberStateTable](https://github.com/sonic-net/sonic-swss-"
"common/blob/master/common/subscriberstatetable.h)了。"

#: src/4-2-2-redis-messaging-layer.md:9
msgid ""
"它的原理是利用Redis数据库中自带的keyspace消息通知机制 [\\[4\\]]"
"[RedisKeyspace] —— 当数据库中的任何一个key对应的值发生了变化，就会触发Redis发"
"送两个keyspace的事件通知，一个是`__keyspace@<db-id>__:<key>`下的`<op>`事件，"
"一个是`__keyspace@<db-id>__:<op>`下的`<key>>`事件，比如，在数据库0中删除了一"
"个key，那么就会触发两个事件通知："
msgstr ""
"它的原理是利用Redis数据库中自带的keyspace消息通知机制 [\\[4\\]]"
"[RedisKeyspace] —— 当数据库中的任何一个key对应的值发生了变化，就会触发Redis发"
"送两个keyspace的事件通知，一个是`__keyspace@<db-id>__:<key>`下的`<op>`事件，"
"一个是`__keyspace@<db-id>__:<op>`下的`<key>>`事件，比如，在数据库0中删除了一"
"个key，那么就会触发两个事件通知："

#: src/4-2-2-redis-messaging-layer.md:11
msgid ""
"```redis\n"
"PUBLISH __keyspace@0__:foo del\n"
"PUBLISH __keyevent@0__:del foo\n"
"```"
msgstr ""
"```redis\n"
"PUBLISH __keyspace@0__:foo del\n"
"PUBLISH __keyevent@0__:del foo\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:16
msgid ""
"而SubscriberStateTable就是监听了第一个事件通知，然后调用相应的回调函数。和其"
"直接相关的主要的类的类图如下，这里可以看到它继承了ConsumerTableBase，因为它是"
"Redis的消息的Consumer："
msgstr ""
"而SubscriberStateTable就是监听了第一个事件通知，然后调用相应的回调函数。和其"
"直接相关的主要的类的类图如下，这里可以看到它继承了ConsumerTableBase，因为它是"
"Redis的消息的Consumer："

#: src/4-2-2-redis-messaging-layer.md:20
msgid "在初始化时，我们可以看到它是如何订阅Redis的事件通知的："
msgstr "在初始化时，我们可以看到它是如何订阅Redis的事件通知的："

#: src/4-2-2-redis-messaging-layer.md:22
msgid ""
"```cpp\n"
"// File: sonic-swss-common - common/subscriberstatetable.cpp\n"
"SubscriberStateTable::SubscriberStateTable(DBConnector *db, const string "
"&tableName, int popBatchSize, int pri)\n"
"    : ConsumerTableBase(db, tableName, popBatchSize, pri), m_table(db, "
"tableName)\n"
"{\n"
"    m_keyspace = \"__keyspace@\";\n"
"    m_keyspace += to_string(db->getDbId()) + \"__:\" + tableName + m_table."
"getTableNameSeparator() + \"*\";\n"
"    psubscribe(m_db, m_keyspace);\n"
"    // ...\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss-common - common/subscriberstatetable.cpp\n"
"SubscriberStateTable::SubscriberStateTable(DBConnector *db, const string "
"&tableName, int popBatchSize, int pri)\n"
"    : ConsumerTableBase(db, tableName, popBatchSize, pri), m_table(db, "
"tableName)\n"
"{\n"
"    m_keyspace = \"__keyspace@\";\n"
"    m_keyspace += to_string(db->getDbId()) + \"__:\" + tableName + m_table."
"getTableNameSeparator() + \"*\";\n"
"    psubscribe(m_db, m_keyspace);\n"
"    // ...\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:33
msgid "其事件接收和分发主要由两个函数负责："
msgstr "其事件接收和分发主要由两个函数负责："

#: src/4-2-2-redis-messaging-layer.md:35
msgid ""
"- `readData()`负责将redis中待读取的事件读取出来，并放入ConsumerTableBase中的"
"队列中\n"
"- `pops()`：负责将队列中的原始事件取出来，并且进行解析，然后通过函数参数传递"
"给调用方"
msgstr ""
"- `readData()`负责将redis中待读取的事件读取出来，并放入ConsumerTableBase中的"
"队列中\n"
"- `pops()`：负责将队列中的原始事件取出来，并且进行解析，然后通过函数参数传递"
"给调用方"

#: src/4-2-2-redis-messaging-layer.md:38
msgid ""
"```cpp\n"
"// File: sonic-swss-common - common/subscriberstatetable.cpp\n"
"uint64_t SubscriberStateTable::readData()\n"
"{\n"
"    // ...\n"
"    reply = nullptr;\n"
"    int status;\n"
"    do {\n"
"        status = redisGetReplyFromReader(m_subscribe->getContext(), "
"reinterpret_cast<void**>(&reply));\n"
"        if(reply != nullptr && status == REDIS_OK) {\n"
"            m_keyspace_event_buffer."
"emplace_back(make_shared<RedisReply>(reply));\n"
"        }\n"
"    } while(reply != nullptr && status == REDIS_OK);\n"
"    // ...\n"
"    return 0;\n"
"}\n"
"\n"
"void SubscriberStateTable::pops(deque<KeyOpFieldsValuesTuple> &vkco, const "
"string& /*prefix*/)\n"
"{\n"
"    vkco.clear();\n"
"    // ...\n"
"\n"
"    // Pop from m_keyspace_event_buffer, which is filled by readData()\n"
"    while (auto event = popEventBuffer()) {\n"
"        KeyOpFieldsValuesTuple kco;\n"
"        // Parsing here ...\n"
"        vkco.push_back(kco);\n"
"    }\n"
"\n"
"    m_keyspace_event_buffer.clear();\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss-common - common/subscriberstatetable.cpp\n"
"uint64_t SubscriberStateTable::readData()\n"
"{\n"
"    // ...\n"
"    reply = nullptr;\n"
"    int status;\n"
"    do {\n"
"        status = redisGetReplyFromReader(m_subscribe->getContext(), "
"reinterpret_cast<void**>(&reply));\n"
"        if(reply != nullptr && status == REDIS_OK) {\n"
"            m_keyspace_event_buffer."
"emplace_back(make_shared<RedisReply>(reply));\n"
"        }\n"
"    } while(reply != nullptr && status == REDIS_OK);\n"
"    // ...\n"
"    return 0;\n"
"}\n"
"\n"
"void SubscriberStateTable::pops(deque<KeyOpFieldsValuesTuple> &vkco, const "
"string& /*prefix*/)\n"
"{\n"
"    vkco.clear();\n"
"    // ...\n"
"\n"
"    // Pop from m_keyspace_event_buffer, which is filled by readData()\n"
"    while (auto event = popEventBuffer()) {\n"
"        KeyOpFieldsValuesTuple kco;\n"
"        // Parsing here ...\n"
"        vkco.push_back(kco);\n"
"    }\n"
"\n"
"    m_keyspace_event_buffer.clear();\n"
"}\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:71
msgid "## NotificationProducer / NotificationConsumer"
msgstr "## NotificationProducer / NotificationConsumer"

#: src/4-2-2-redis-messaging-layer.md:73
msgid ""
"说到消息通信，我们很容易就会联想到消息队列，这就是我们的第二种通信方式 —— "
"[NotificationProducer](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/notificationproducer.h)和[NotificationConsumer](https://github."
"com/sonic-net/sonic-swss-common/blob/master/common/notificationconsumer.h)。"
msgstr ""
"说到消息通信，我们很容易就会联想到消息队列，这就是我们的第二种通信方式 —— "
"[NotificationProducer](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/notificationproducer.h)和[NotificationConsumer](https://github."
"com/sonic-net/sonic-swss-common/blob/master/common/notificationconsumer.h)。"

#: src/4-2-2-redis-messaging-layer.md:75
msgid ""
"这种通信方式通过Redis的自带的PubSub来实现，主要是对`PUBLISH`和`SUBSCRIBE`命令"
"的包装，很有限的应用在最简单的通知型的场景中，比如orchagent中的timeout "
"check, restart check之类，非传递用户配置和数据的场景："
msgstr ""
"这种通信方式通过Redis的自带的PubSub来实现，主要是对`PUBLISH`和`SUBSCRIBE`命令"
"的包装，很有限的应用在最简单的通知型的场景中，比如orchagent中的timeout "
"check, restart check之类，非传递用户配置和数据的场景："

#: src/4-2-2-redis-messaging-layer.md:79
msgid ""
"这种通信模式下，消息的发送方Producer，主要会做两件事情：一是将消息打包成JSON"
"格式，二是调用Redis的`PUBLISH`命令将消息发送出去。而且由于`PUBLISH`命令只能携"
"带一个消息，所以请求中的`op`和`data`字段会被放在`values`的最前面，然后再调用"
"`buildJson`函数将其打包成一个JSON数组的格式："
msgstr ""
"这种通信模式下，消息的发送方Producer，主要会做两件事情：一是将消息打包成JSON"
"格式，二是调用Redis的`PUBLISH`命令将消息发送出去。而且由于`PUBLISH`命令只能携"
"带一个消息，所以请求中的`op`和`data`字段会被放在`values`的最前面，然后再调用"
"`buildJson`函数将其打包成一个JSON数组的格式："

#: src/4-2-2-redis-messaging-layer.md:81
msgid ""
"```cpp\n"
"int64_t swss::NotificationProducer::send(const std::string &op, const std::"
"string &data, std::vector<FieldValueTuple> &values)\n"
"{\n"
"    // Pack the op and data into values array, then pack everything into a "
"JSON string as the message\n"
"    FieldValueTuple opdata(op, data);\n"
"    values.insert(values.begin(), opdata);\n"
"    std::string msg = JSon::buildJson(values);\n"
"    values.erase(values.begin());\n"
"\n"
"    // Publish message to Redis channel\n"
"    RedisCommand command;\n"
"    command.format(\"PUBLISH %s %s\", m_channel.c_str(), msg.c_str());\n"
"    // ...\n"
"    RedisReply reply = m_pipe->push(command);\n"
"    reply.checkReplyType(REDIS_REPLY_INTEGER);\n"
"    return reply.getReply<long long int>();\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"int64_t swss::NotificationProducer::send(const std::string &op, const std::"
"string &data, std::vector<FieldValueTuple> &values)\n"
"{\n"
"    // Pack the op and data into values array, then pack everything into a "
"JSON string as the message\n"
"    FieldValueTuple opdata(op, data);\n"
"    values.insert(values.begin(), opdata);\n"
"    std::string msg = JSon::buildJson(values);\n"
"    values.erase(values.begin());\n"
"\n"
"    // Publish message to Redis channel\n"
"    RedisCommand command;\n"
"    command.format(\"PUBLISH %s %s\", m_channel.c_str(), msg.c_str());\n"
"    // ...\n"
"    RedisReply reply = m_pipe->push(command);\n"
"    reply.checkReplyType(REDIS_REPLY_INTEGER);\n"
"    return reply.getReply<long long int>();\n"
"}\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:100
msgid "接收方则是利用`SUBSCRIBE`命令来接收所有的通知："
msgstr "接收方则是利用`SUBSCRIBE`命令来接收所有的通知："

#: src/4-2-2-redis-messaging-layer.md:102
msgid ""
"```cpp\n"
"void swss::NotificationConsumer::subscribe()\n"
"{\n"
"    // ...\n"
"    m_subscribe = new DBConnector(m_db->getDbId(),\n"
"                                    m_db->getContext()->unix_sock.path,\n"
"                                    NOTIFICATION_SUBSCRIBE_TIMEOUT);\n"
"    // ...\n"
"\n"
"    // Subscribe to Redis channel\n"
"    std::string s = \"SUBSCRIBE \" + m_channel;\n"
"    RedisReply r(m_subscribe, s, REDIS_REPLY_ARRAY);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"void swss::NotificationConsumer::subscribe()\n"
"{\n"
"    // ...\n"
"    m_subscribe = new DBConnector(m_db->getDbId(),\n"
"                                    m_db->getContext()->unix_sock.path,\n"
"                                    NOTIFICATION_SUBSCRIBE_TIMEOUT);\n"
"    // ...\n"
"\n"
"    // Subscribe to Redis channel\n"
"    std::string s = \"SUBSCRIBE \" + m_channel;\n"
"    RedisReply r(m_subscribe, s, REDIS_REPLY_ARRAY);\n"
"}\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:117
msgid "## ProducerTable / ConsumerTable"
msgstr "## ProducerTable / ConsumerTable"

#: src/4-2-2-redis-messaging-layer.md:119
msgid ""
"我们可以看到NotificationProducer/Consumer实现简单粗暴，但是由于API的限制 "
"[\\[8\\]][RedisClientHandling]，它并不适合用来传递数据，所以，SONiC中提供了一"
"种和它非常接近的另外一种基于消息队列的通信机制 —— [ProducerTable](https://"
"github.com/sonic-net/sonic-swss-common/blob/master/common/producertable.h)和"
"[ConsumerTable](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/consumertable.h)。"
msgstr ""
"我们可以看到NotificationProducer/Consumer实现简单粗暴，但是由于API的限制 "
"[\\[8\\]][RedisClientHandling]，它并不适合用来传递数据，所以，SONiC中提供了一"
"种和它非常接近的另外一种基于消息队列的通信机制 —— [ProducerTable](https://"
"github.com/sonic-net/sonic-swss-common/blob/master/common/producertable.h)和"
"[ConsumerTable](https://github.com/sonic-net/sonic-swss-common/blob/master/"
"common/consumertable.h)。"

#: src/4-2-2-redis-messaging-layer.md:121
msgid ""
"这种通信方式通过Redis的List来实现，和Notification不同的地方在于，发布给"
"Channel中的消息非常的简单（单字符\"G\"），所有的数据都存储在List中，从而解决"
"了Notification中消息大小限制的问题。在SONiC中，它主要用在FlexCounter，`syncd`"
"服务和`ASIC_DB`中："
msgstr ""
"这种通信方式通过Redis的List来实现，和Notification不同的地方在于，发布给"
"Channel中的消息非常的简单（单字符\"G\"），所有的数据都存储在List中，从而解决"
"了Notification中消息大小限制的问题。在SONiC中，它主要用在FlexCounter，`syncd`"
"服务和`ASIC_DB`中："

#: src/4-2-2-redis-messaging-layer.md:123
msgid ""
"1. **消息格式**：每条消息都是一个（Key, FieldValuePairs, Op）的三元组，如果用"
"JSON来表达这个消息，那么它的格式如下：（这里的Key是Table中数据的Key，被操作的"
"数据是[Hash][RedisHash]，所以Field就是Hash中的Field，Value就是Hash中的Value"
"了，也就是说一个消息可以对很多个Field进行操作）\n"
"\n"
"   ```json\n"
"   [ \"Key\", \"[\\\"Field1\\\", \\\"Value1\\\", \\\"Field2\", \\\"Value2\\"
"\", ...]\", \"Op\" ]\n"
"   ```\n"
"\n"
"2. **Enqueue**：ProducerTable通过Lua脚本将消息三元组原子的写入消息队列中"
"（Key = `<table-name>_KEY_VALUE_OP_QUEUE`，并且发布更新通知到特定的Channel"
"（Key = `<table-name>_CHANNEL`）中。\n"
"3. **Pop**：ConsumerTable也通过Lua脚本从消息队列中原子的读取消息三元组，并**"
"在读取过程中**将其中请求的改动真正的写入到数据库中。"
msgstr ""
"1. **消息格式**：每条消息都是一个（Key, FieldValuePairs, Op）的三元组，如果用"
"JSON来表达这个消息，那么它的格式如下：（这里的Key是Table中数据的Key，被操作的"
"数据是[Hash][RedisHash]，所以Field就是Hash中的Field，Value就是Hash中的Value"
"了，也就是说一个消息可以对很多个Field进行操作）\n"
"\n"
"   ```json\n"
"   [ \"Key\", \"[\\\"Field1\\\", \\\"Value1\\\", \\\"Field2\", \\\"Value2\\"
"\", ...]\", \"Op\" ]\n"
"   ```\n"
"\n"
"2. **Enqueue**：ProducerTable通过Lua脚本将消息三元组原子的写入消息队列中"
"（Key = `<table-name>_KEY_VALUE_OP_QUEUE`，并且发布更新通知到特定的Channel"
"（Key = `<table-name>_CHANNEL`）中。\n"
"3. **Pop**：ConsumerTable也通过Lua脚本从消息队列中原子的读取消息三元组，并**"
"在读取过程中**将其中请求的改动真正的写入到数据库中。"

#: src/4-2-2-redis-messaging-layer.md:132
msgid ""
"```admonish note\n"
"**注意**：Redis中Lua脚本和MULTI/EXEC的原子性和通常说的数据库ACID中的原子性"
"（Atomicity）不同，Redis中的原子性其实更接近于ACID中的隔离性（Isolation），他"
"保证Lua脚本中所有的命令在执行的时候不会有其他的命令执行，但是并不保证Lua脚本"
"中的所有命令都会执行成功，比如，如果Lua脚本中的第二个命令执行失败了，那么第一"
"个命令依然会被提交，只是后面的命令就不会继续执行了。更多的细节可以参考Redis官"
"方文档 [\\[5\\]][RedisTx] [\\[6\\]][RedisLuaAtomicity]。\n"
"```"
msgstr ""
"```admonish note\n"
"**注意**：Redis中Lua脚本和MULTI/EXEC的原子性和通常说的数据库ACID中的原子性"
"（Atomicity）不同，Redis中的原子性其实更接近于ACID中的隔离性（Isolation），他"
"保证Lua脚本中所有的命令在执行的时候不会有其他的命令执行，但是并不保证Lua脚本"
"中的所有命令都会执行成功，比如，如果Lua脚本中的第二个命令执行失败了，那么第一"
"个命令依然会被提交，只是后面的命令就不会继续执行了。更多的细节可以参考Redis官"
"方文档 [\\[5\\]][RedisTx] [\\[6\\]][RedisLuaAtomicity]。\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:136
msgid ""
"其主要类图如下，这里我们可以看到在ProducerTable中的`m_shaEnqueue`和"
"ConsumerTable中的`m_shaPop`，它们就是上面我们提到的这两个Lua脚本在加载时获得"
"的SHA了，而之后我们就可以使用Redis的`EVALSHA`命令对他们进行原子的调用了："
msgstr ""
"其主要类图如下，这里我们可以看到在ProducerTable中的`m_shaEnqueue`和"
"ConsumerTable中的`m_shaPop`，它们就是上面我们提到的这两个Lua脚本在加载时获得"
"的SHA了，而之后我们就可以使用Redis的`EVALSHA`命令对他们进行原子的调用了："

#: src/4-2-2-redis-messaging-layer.md:140
msgid ""
"ProducerTable的核心逻辑如下，我们可以看到对Values的JSON打包，和使用`EVALSHA`"
"来进行Lua脚本的调用："
msgstr ""
"ProducerTable的核心逻辑如下，我们可以看到对Values的JSON打包，和使用`EVALSHA`"
"来进行Lua脚本的调用："

#: src/4-2-2-redis-messaging-layer.md:142
msgid ""
"```cpp\n"
"// File: sonic-swss-common - common/producertable.cpp\n"
"ProducerTable::ProducerTable(RedisPipeline *pipeline, const string "
"&tableName, bool buffered)\n"
"    // ...\n"
"{\n"
"    string luaEnque =\n"
"        \"redis.call('LPUSH', KEYS[1], ARGV[1], ARGV[2], ARGV[3]);\"\n"
"        \"redis.call('PUBLISH', KEYS[2], ARGV[4]);\";\n"
"\n"
"    m_shaEnque = m_pipe->loadRedisScript(luaEnque);\n"
"}\n"
"\n"
"void ProducerTable::set(const string &key, const vector<FieldValueTuple> "
"&values, const string &op, const string &prefix)\n"
"{\n"
"    enqueueDbChange(key, JSon::buildJson(values), \"S\" + op, prefix);\n"
"}\n"
"\n"
"void ProducerTable::del(const string &key, const string &op, const string "
"&prefix)\n"
"{\n"
"    enqueueDbChange(key, \"{}\", \"D\" + op, prefix);\n"
"}\n"
"\n"
"void ProducerTable::enqueueDbChange(const string &key, const string &value, "
"const string &op, const string& /* prefix */)\n"
"{\n"
"    RedisCommand command;\n"
"\n"
"    command.format(\n"
"        \"EVALSHA %s 2 %s %s %s %s %s %s\",\n"
"        m_shaEnque.c_str(),\n"
"        getKeyValueOpQueueTableName().c_str(),\n"
"        getChannelName(m_pipe->getDbId()).c_str(),\n"
"        key.c_str(),\n"
"        value.c_str(),\n"
"        op.c_str(),\n"
"        \"G\");\n"
"\n"
"    m_pipe->push(command, REDIS_REPLY_NIL);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss-common - common/producertable.cpp\n"
"ProducerTable::ProducerTable(RedisPipeline *pipeline, const string "
"&tableName, bool buffered)\n"
"    // ...\n"
"{\n"
"    string luaEnque =\n"
"        \"redis.call('LPUSH', KEYS[1], ARGV[1], ARGV[2], ARGV[3]);\"\n"
"        \"redis.call('PUBLISH', KEYS[2], ARGV[4]);\";\n"
"\n"
"    m_shaEnque = m_pipe->loadRedisScript(luaEnque);\n"
"}\n"
"\n"
"void ProducerTable::set(const string &key, const vector<FieldValueTuple> "
"&values, const string &op, const string &prefix)\n"
"{\n"
"    enqueueDbChange(key, JSon::buildJson(values), \"S\" + op, prefix);\n"
"}\n"
"\n"
"void ProducerTable::del(const string &key, const string &op, const string "
"&prefix)\n"
"{\n"
"    enqueueDbChange(key, \"{}\", \"D\" + op, prefix);\n"
"}\n"
"\n"
"void ProducerTable::enqueueDbChange(const string &key, const string &value, "
"const string &op, const string& /* prefix */)\n"
"{\n"
"    RedisCommand command;\n"
"\n"
"    command.format(\n"
"        \"EVALSHA %s 2 %s %s %s %s %s %s\",\n"
"        m_shaEnque.c_str(),\n"
"        getKeyValueOpQueueTableName().c_str(),\n"
"        getChannelName(m_pipe->getDbId()).c_str(),\n"
"        key.c_str(),\n"
"        value.c_str(),\n"
"        op.c_str(),\n"
"        \"G\");\n"
"\n"
"    m_pipe->push(command, REDIS_REPLY_NIL);\n"
"}\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:182
msgid ""
"而另一侧的ConsumerTable就稍稍复杂一点，因为其支持的op类型很多，所以逻辑都写在"
"了一个单独的文件中（`common/consumer_table_pops.lua`），我们这里就不贴代码"
"了，有兴趣的同学可以自己去看看。"
msgstr ""
"而另一侧的ConsumerTable就稍稍复杂一点，因为其支持的op类型很多，所以逻辑都写在"
"了一个单独的文件中（`common/consumer_table_pops.lua`），我们这里就不贴代码"
"了，有兴趣的同学可以自己去看看。"

#: src/4-2-2-redis-messaging-layer.md:184
msgid ""
"```cpp\n"
"// File: sonic-swss-common - common/consumertable.cpp\n"
"ConsumerTable::ConsumerTable(DBConnector *db, const string &tableName, int "
"popBatchSize, int pri)\n"
"    : ConsumerTableBase(db, tableName, popBatchSize, pri)\n"
"    , TableName_KeyValueOpQueues(tableName)\n"
"    , m_modifyRedis(true)\n"
"{\n"
"    std::string luaScript = loadLuaScript(\"consumer_table_pops.lua\");\n"
"    m_shaPop = loadRedisScript(db, luaScript);\n"
"    // ...\n"
"}\n"
"\n"
"void ConsumerTable::pops(deque<KeyOpFieldsValuesTuple> &vkco, const string "
"&prefix)\n"
"{\n"
"    // Note that here we are processing the messages in bulk with "
"POP_BATCH_SIZE!\n"
"    RedisCommand command;\n"
"    command.format(\n"
"        \"EVALSHA %s 2 %s %s %d %d\",\n"
"        m_shaPop.c_str(),\n"
"        getKeyValueOpQueueTableName().c_str(),\n"
"        (prefix+getTableName()).c_str(),\n"
"        POP_BATCH_SIZE,\n"
"\n"
"    RedisReply r(m_db, command, REDIS_REPLY_ARRAY);\n"
"    vkco.clear();\n"
"\n"
"    // Parse and pack the messages in bulk\n"
"    // ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: sonic-swss-common - common/consumertable.cpp\n"
"ConsumerTable::ConsumerTable(DBConnector *db, const string &tableName, int "
"popBatchSize, int pri)\n"
"    : ConsumerTableBase(db, tableName, popBatchSize, pri)\n"
"    , TableName_KeyValueOpQueues(tableName)\n"
"    , m_modifyRedis(true)\n"
"{\n"
"    std::string luaScript = loadLuaScript(\"consumer_table_pops.lua\");\n"
"    m_shaPop = loadRedisScript(db, luaScript);\n"
"    // ...\n"
"}\n"
"\n"
"void ConsumerTable::pops(deque<KeyOpFieldsValuesTuple> &vkco, const string "
"&prefix)\n"
"{\n"
"    // Note that here we are processing the messages in bulk with "
"POP_BATCH_SIZE!\n"
"    RedisCommand command;\n"
"    command.format(\n"
"        \"EVALSHA %s 2 %s %s %d %d\",\n"
"        m_shaPop.c_str(),\n"
"        getKeyValueOpQueueTableName().c_str(),\n"
"        (prefix+getTableName()).c_str(),\n"
"        POP_BATCH_SIZE,\n"
"\n"
"    RedisReply r(m_db, command, REDIS_REPLY_ARRAY);\n"
"    vkco.clear();\n"
"\n"
"    // Parse and pack the messages in bulk\n"
"    // ...\n"
"}\n"
"```"

#: src/4-2-2-redis-messaging-layer.md:215
msgid "## ProducerStateTable / ConsumerStateTable"
msgstr "## ProducerStateTable / ConsumerStateTable"

#: src/4-2-2-redis-messaging-layer.md:217
msgid ""
"Producer/ConsumerTable虽然直观，而且保序，但是它一个消息只能处理一个Key，并且"
"还需要JSON的序列化，然而很多时候我们并用不到保序的功能，反而更需要更大的吞吐"
"量，所以为了优化性能，SONiC就引入了第四种通信方式，也是最常用的通信方式："
"[ProducerStateTable](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/producerstatetable.h)和[ConsumerStateTable](https://github.com/"
"sonic-net/sonic-swss-common/blob/master/common/consumertatetable.h)。"
msgstr ""
"Producer/ConsumerTable虽然直观，而且保序，但是它一个消息只能处理一个Key，并且"
"还需要JSON的序列化，然而很多时候我们并用不到保序的功能，反而更需要更大的吞吐"
"量，所以为了优化性能，SONiC就引入了第四种通信方式，也是最常用的通信方式："
"[ProducerStateTable](https://github.com/sonic-net/sonic-swss-common/blob/"
"master/common/producerstatetable.h)和[ConsumerStateTable](https://github.com/"
"sonic-net/sonic-swss-common/blob/master/common/consumertatetable.h)。"

#: src/4-2-2-redis-messaging-layer.md:219
msgid ""
"与ProducerTable不同，ProducerStateTable使用Hash的方式来存储消息，而不是List。"
"这样虽然不能保证消息的顺序，但是却可以很好的提升性能！首先，我们省下了JSON的"
"序列化的开销，其次，对于同一个Key下的相同的Field如果被变更多次，那么只需要保"
"留最后一次的变更，这样就将关于这个Key的所有变更消息就合并成了一条，减少了很多"
"不必要的消息处理。"
msgstr ""
"与ProducerTable不同，ProducerStateTable使用Hash的方式来存储消息，而不是List。"
"这样虽然不能保证消息的顺序，但是却可以很好的提升性能！首先，我们省下了JSON的"
"序列化的开销，其次，对于同一个Key下的相同的Field如果被变更多次，那么只需要保"
"留最后一次的变更，这样就将关于这个Key的所有变更消息就合并成了一条，减少了很多"
"不必要的消息处理。"

#: src/4-2-2-redis-messaging-layer.md:221
msgid ""
"Producer/ConsumerStateTable的底层实现相比于Producer/ConsumerTable也更加复杂一"
"些。其相关联的类的主要类图如下，这里我们依然可以看到它的实现是通过`EVALSHA`调"
"用Lua脚本来实现的，`m_shaSet`和`m_shaDel`就是用来存放修改和发送消息的，而另一"
"边`m_shaPop`就是用来获取消息的："
msgstr ""
"Producer/ConsumerStateTable的底层实现相比于Producer/ConsumerTable也更加复杂一"
"些。其相关联的类的主要类图如下，这里我们依然可以看到它的实现是通过`EVALSHA`调"
"用Lua脚本来实现的，`m_shaSet`和`m_shaDel`就是用来存放修改和发送消息的，而另一"
"边`m_shaPop`就是用来获取消息的："

#: src/4-2-2-redis-messaging-layer.md:225
msgid "在传递消息时："
msgstr "在传递消息时："

#: src/4-2-2-redis-messaging-layer.md:227
msgid ""
"- 首先，每个消息会被存放成两个部分：一个是KEY_SET，用来保存当前有哪些Key发生"
"了修改，它以Set的形式存放在`<table-name_KEY_SET>`的key下，另一个是所有被修改"
"的Key的内容，它以Hash的形式存放在`_<redis-key-name>`的key下。\n"
"- 然后，消息存放之后Producer如果发现是新的Key，那么就是调用`PUBLISH`命令，来"
"通知`<table-name>_CHANNEL@<db-id>`Channel，有新的Key出现了。\n"
"\n"
"  ```cpp\n"
"  // File: sonic-swss-common - common/producerstatetable.cpp\n"
"  ProducerStateTable::ProducerStateTable(RedisPipeline *pipeline, const "
"string &tableName, bool buffered)\n"
"      : TableBase(tableName, SonicDBConfig::getSeparator(pipeline-"
">getDBConnector()))\n"
"      , TableName_KeySet(tableName)\n"
"      // ...\n"
"  {\n"
"      string luaSet =\n"
"          \"local added = redis.call('SADD', KEYS[2], ARGV[2])\\n\"\n"
"          \"for i = 0, #KEYS - 3 do\\n\"\n"
"          \"    redis.call('HSET', KEYS[3 + i], ARGV[3 + i * 2], ARGV[4 + i "
"* 2])\\n\"\n"
"          \"end\\n\"\n"
"          \" if added > 0 then \\n\"\n"
"          \"    redis.call('PUBLISH', KEYS[1], ARGV[1])\\n\"\n"
"          \"end\\n\";\n"
"\n"
"      m_shaSet = m_pipe->loadRedisScript(luaSet);\n"
"  ```\n"
"\n"
"- 最后，Consumer会通过`SUBSCRIBE`命令来订阅`<table-name>_CHANNEL@<db-"
"id>`Channel，一旦有新的消息到来，就会使用Lua脚本调用`HGETALL`命令来获取所有的"
"Key，并将其中的值读取出来并真正的写入到数据库中去。\n"
"\n"
"  ```cpp\n"
"  ConsumerStateTable::ConsumerStateTable(DBConnector *db, const std::string "
"&tableName, int popBatchSize, int pri)\n"
"      : ConsumerTableBase(db, tableName, popBatchSize, pri)\n"
"      , TableName_KeySet(tableName)\n"
"  {\n"
"      std::string luaScript = loadLuaScript(\"consumer_state_table_pops."
"lua\");\n"
"      m_shaPop = loadRedisScript(db, luaScript);\n"
"      // ...\n"
"  \n"
"      subscribe(m_db, getChannelName(m_db->getDbId()));\n"
"      // ...\n"
"  ```"
msgstr ""
"- 首先，每个消息会被存放成两个部分：一个是KEY_SET，用来保存当前有哪些Key发生"
"了修改，它以Set的形式存放在`<table-name_KEY_SET>`的key下，另一个是所有被修改"
"的Key的内容，它以Hash的形式存放在`_<redis-key-name>`的key下。\n"
"- 然后，消息存放之后Producer如果发现是新的Key，那么就是调用`PUBLISH`命令，来"
"通知`<table-name>_CHANNEL@<db-id>`Channel，有新的Key出现了。\n"
"\n"
"  ```cpp\n"
"  // File: sonic-swss-common - common/producerstatetable.cpp\n"
"  ProducerStateTable::ProducerStateTable(RedisPipeline *pipeline, const "
"string &tableName, bool buffered)\n"
"      : TableBase(tableName, SonicDBConfig::getSeparator(pipeline-"
">getDBConnector()))\n"
"      , TableName_KeySet(tableName)\n"
"      // ...\n"
"  {\n"
"      string luaSet =\n"
"          \"local added = redis.call('SADD', KEYS[2], ARGV[2])\\n\"\n"
"          \"for i = 0, #KEYS - 3 do\\n\"\n"
"          \"    redis.call('HSET', KEYS[3 + i], ARGV[3 + i * 2], ARGV[4 + i "
"* 2])\\n\"\n"
"          \"end\\n\"\n"
"          \" if added > 0 then \\n\"\n"
"          \"    redis.call('PUBLISH', KEYS[1], ARGV[1])\\n\"\n"
"          \"end\\n\";\n"
"\n"
"      m_shaSet = m_pipe->loadRedisScript(luaSet);\n"
"  ```\n"
"\n"
"- 最后，Consumer会通过`SUBSCRIBE`命令来订阅`<table-name>_CHANNEL@<db-"
"id>`Channel，一旦有新的消息到来，就会使用Lua脚本调用`HGETALL`命令来获取所有的"
"Key，并将其中的值读取出来并真正的写入到数据库中去。\n"
"\n"
"  ```cpp\n"
"  ConsumerStateTable::ConsumerStateTable(DBConnector *db, const std::string "
"&tableName, int popBatchSize, int pri)\n"
"      : ConsumerTableBase(db, tableName, popBatchSize, pri)\n"
"      , TableName_KeySet(tableName)\n"
"  {\n"
"      std::string luaScript = loadLuaScript(\"consumer_state_table_pops."
"lua\");\n"
"      m_shaPop = loadRedisScript(db, luaScript);\n"
"      // ...\n"
"  \n"
"      subscribe(m_db, getChannelName(m_db->getDbId()));\n"
"      // ...\n"
"  ```"

#: src/4-2-2-redis-messaging-layer.md:264
msgid "为了方便理解，我们这里举一个例子：启用Port Ethernet0："
msgstr "为了方便理解，我们这里举一个例子：启用Port Ethernet0："

#: src/4-2-2-redis-messaging-layer.md:266
msgid ""
"- 首先，我们在命令行下调用`config interface startup Ethernet0`来启用"
"Ethernet0，这会导致`portmgrd`通过ProducerStateTable向APP_DB发送状态更新消息，"
"如下：\n"
"\n"
"  ```redis\n"
"  EVALSHA \"<hash-of-set-lua>\" \"6\" \"PORT_TABLE_CHANNEL@0\" "
"\"PORT_TABLE_KEY_SET\" \n"
"      \"_PORT_TABLE:Ethernet0\" \"_PORT_TABLE:Ethernet0\" \"_PORT_TABLE:"
"Ethernet0\" \"_PORT_TABLE:Ethernet0\" \"G\"\n"
"      \"Ethernet0\" \"alias\" \"Ethernet5/1\" \"index\" \"5\" \"lanes\" "
"\"9,10,11,12\" \"speed\" \"40000\"\n"
"  ```\n"
"\n"
"  这个命令会在其中调用如下的命令来创建和发布消息：\n"
"\n"
"  ```redis\n"
"  SADD \"PORT_TABLE_KEY_SET\" \"_PORT_TABLE:Ethernet0\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"alias\" \"Ethernet5/1\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"index\" \"5\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"lanes\" \"9,10,11,12\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"speed\" \"40000\"\n"
"  PUBLISH \"PORT_TABLE_CHANNEL@0\" \"_PORT_TABLE:Ethernet0\"\n"
"  ```\n"
"\n"
"  所以最终这个消息会在APPL_DB中被存放成如下的形式：\n"
"\n"
"  ```redis\n"
"  PORT_TABLE_KEY_SET:\n"
"    _PORT_TABLE:Ethernet0\n"
"\n"
"  _PORT_TABLE:Ethernet0:\n"
"    alias: Ethernet5/1\n"
"    index: 5\n"
"    lanes: 9,10,11,12\n"
"    speed: 40000\n"
"  ```\n"
"\n"
"- 当ConsumerStateTable收到消息后，也会调用`EVALSHA`命令来执行Lua脚本，如"
"下：\n"
"\n"
"  ```redis\n"
"  EVALSHA \"<hash-of-pop-lua>\" \"3\" \"PORT_TABLE_KEY_SET\" \"PORT_TABLE:\" "
"\"PORT_TABLE_DEL_SET\" \"8192\" \"_\"\n"
"  ```\n"
"\n"
"  和Producer类似，这个脚本会执行如下命令，将`PORT_TABLE_KEY_SET`中的key，也就"
"是`_PORT_TABLE:Ethernet0`读取出来，然后再将其对应的Hash读取出来，并更新到"
"`PORT_TABLE:Ethernet0`去，同时将`_PORT_TABLE:Ethernet0`从数据库和"
"`PORT_TABLE_KEY_SET`中删除。\n"
"\n"
"  ```redis\n"
"  SPOP \"PORT_TABLE_KEY_SET\" \"_PORT_TABLE:Ethernet0\"\n"
"  HGETALL \"_PORT_TABLE:Ethernet0\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"alias\" \"Ethernet5/1\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"index\" \"5\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"lanes\" \"9,10,11,12\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"speed\" \"40000\"\n"
"  DEL \"_PORT_TABLE:Ethernet0\"\n"
"  ```\n"
"\n"
"  到这里，数据的更新才算是完成了。"
msgstr ""
"- 首先，我们在命令行下调用`config interface startup Ethernet0`来启用"
"Ethernet0，这会导致`portmgrd`通过ProducerStateTable向APP_DB发送状态更新消息，"
"如下：\n"
"\n"
"  ```redis\n"
"  EVALSHA \"<hash-of-set-lua>\" \"6\" \"PORT_TABLE_CHANNEL@0\" "
"\"PORT_TABLE_KEY_SET\" \n"
"      \"_PORT_TABLE:Ethernet0\" \"_PORT_TABLE:Ethernet0\" \"_PORT_TABLE:"
"Ethernet0\" \"_PORT_TABLE:Ethernet0\" \"G\"\n"
"      \"Ethernet0\" \"alias\" \"Ethernet5/1\" \"index\" \"5\" \"lanes\" "
"\"9,10,11,12\" \"speed\" \"40000\"\n"
"  ```\n"
"\n"
"  这个命令会在其中调用如下的命令来创建和发布消息：\n"
"\n"
"  ```redis\n"
"  SADD \"PORT_TABLE_KEY_SET\" \"_PORT_TABLE:Ethernet0\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"alias\" \"Ethernet5/1\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"index\" \"5\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"lanes\" \"9,10,11,12\"\n"
"  HSET \"_PORT_TABLE:Ethernet0\" \"speed\" \"40000\"\n"
"  PUBLISH \"PORT_TABLE_CHANNEL@0\" \"_PORT_TABLE:Ethernet0\"\n"
"  ```\n"
"\n"
"  所以最终这个消息会在APPL_DB中被存放成如下的形式：\n"
"\n"
"  ```redis\n"
"  PORT_TABLE_KEY_SET:\n"
"    _PORT_TABLE:Ethernet0\n"
"\n"
"  _PORT_TABLE:Ethernet0:\n"
"    alias: Ethernet5/1\n"
"    index: 5\n"
"    lanes: 9,10,11,12\n"
"    speed: 40000\n"
"  ```\n"
"\n"
"- 当ConsumerStateTable收到消息后，也会调用`EVALSHA`命令来执行Lua脚本，如"
"下：\n"
"\n"
"  ```redis\n"
"  EVALSHA \"<hash-of-pop-lua>\" \"3\" \"PORT_TABLE_KEY_SET\" \"PORT_TABLE:\" "
"\"PORT_TABLE_DEL_SET\" \"8192\" \"_\"\n"
"  ```\n"
"\n"
"  和Producer类似，这个脚本会执行如下命令，将`PORT_TABLE_KEY_SET`中的key，也就"
"是`_PORT_TABLE:Ethernet0`读取出来，然后再将其对应的Hash读取出来，并更新到"
"`PORT_TABLE:Ethernet0`去，同时将`_PORT_TABLE:Ethernet0`从数据库和"
"`PORT_TABLE_KEY_SET`中删除。\n"
"\n"
"  ```redis\n"
"  SPOP \"PORT_TABLE_KEY_SET\" \"_PORT_TABLE:Ethernet0\"\n"
"  HGETALL \"_PORT_TABLE:Ethernet0\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"alias\" \"Ethernet5/1\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"index\" \"5\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"lanes\" \"9,10,11,12\"\n"
"  HSET \"PORT_TABLE:Ethernet0\" \"speed\" \"40000\"\n"
"  DEL \"_PORT_TABLE:Ethernet0\"\n"
"  ```\n"
"\n"
"  到这里，数据的更新才算是完成了。"

#: src/4-2-2-redis-messaging-layer.md:320
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-swss][SONiCSWSS]\n"
"3. [Github repo: sonic-swss-common][SONiCSWSSCommon]\n"
"4. [Redis keyspace notifications][RedisKeyspace]\n"
"5. [Redis Transactions][RedisTx]\n"
"6. [Redis Atomicity with Lua][RedisLuaAtomicity]\n"
"7. [Redis hashes][RedisHash]\n"
"8. [Redis client handling][RedisClientHandling]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-swss][SONiCSWSS]\n"
"3. [Github repo: sonic-swss-common][SONiCSWSSCommon]\n"
"4. [Redis keyspace notifications][RedisKeyspace]\n"
"5. [Redis Transactions][RedisTx]\n"
"6. [Redis Atomicity with Lua][RedisLuaAtomicity]\n"
"7. [Redis hashes][RedisHash]\n"
"8. [Redis client handling][RedisClientHandling]"

#: src/4-2-3-orch-layer.md:1
msgid "# 服务层 - Orch"
msgstr "# 服务层 - Orch"

#: src/4-2-3-orch-layer.md:3
msgid ""
"最后，为了方便各个服务使用，SONiC还在通信层上进行了更进一步的封装，为各个服务"
"提供了一个基类：[Orch](https://github.com/sonic-net/sonic-swss/blob/master/"
"src/orchagent/orch.hcommon/consumertatetable.h)。"
msgstr ""
"最后，为了方便各个服务使用，SONiC还在通信层上进行了更进一步的封装，为各个服务"
"提供了一个基类：[Orch](https://github.com/sonic-net/sonic-swss/blob/master/"
"src/orchagent/orch.hcommon/consumertatetable.h)。"

#: src/4-2-3-orch-layer.md:5
msgid ""
"由于有了上面这些封装，Orch中关于消息通信的封装就相对简单了，主要的类图如下："
msgstr ""
"由于有了上面这些封装，Orch中关于消息通信的封装就相对简单了，主要的类图如下："

#: src/4-2-3-orch-layer.md:9
msgid ""
"```admonish note\n"
"注意：由于这一层是服务层，所以其代码是在`sonic-swss`的仓库中，而不是`sonic-"
"swss`。这个类中除了消息通信的封装以外，还提供了很多和服务实现相关的公共函数，"
"比如，日志文件等等。\n"
"```"
msgstr ""
"```admonish note\n"
"注意：由于这一层是服务层，所以其代码是在`sonic-swss`的仓库中，而不是`sonic-"
"swss`。这个类中除了消息通信的封装以外，还提供了很多和服务实现相关的公共函数，"
"比如，日志文件等等。\n"
"```"

#: src/4-2-3-orch-layer.md:13
msgid ""
"可以看到，Orch主要是封装了`SubscriberStateTable`和`ConsumerStateTable`来简化"
"和统一消息的订阅，核心代码非常简单，就是根据不同的数据库类型来创建不同的"
"Consumer，如下："
msgstr ""
"可以看到，Orch主要是封装了`SubscriberStateTable`和`ConsumerStateTable`来简化"
"和统一消息的订阅，核心代码非常简单，就是根据不同的数据库类型来创建不同的"
"Consumer，如下："

#: src/4-2-3-orch-layer.md:15
msgid ""
"```cpp\n"
"void Orch::addConsumer(DBConnector *db, string tableName, int pri)\n"
"{\n"
"    if (db->getDbId() == CONFIG_DB || db->getDbId() == STATE_DB || db-"
">getDbId() == CHASSIS_APP_DB) {\n"
"        addExecutor(\n"
"            new Consumer(\n"
"                new SubscriberStateTable(db, tableName, TableConsumable::"
"DEFAULT_POP_BATCH_SIZE, pri),\n"
"                this,\n"
"                tableName));\n"
"    } else {\n"
"        addExecutor(\n"
"            new Consumer(\n"
"                new ConsumerStateTable(db, tableName, gBatchSize, pri),\n"
"                this,\n"
"                tableName));\n"
"    }\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"void Orch::addConsumer(DBConnector *db, string tableName, int pri)\n"
"{\n"
"    if (db->getDbId() == CONFIG_DB || db->getDbId() == STATE_DB || db-"
">getDbId() == CHASSIS_APP_DB) {\n"
"        addExecutor(\n"
"            new Consumer(\n"
"                new SubscriberStateTable(db, tableName, TableConsumable::"
"DEFAULT_POP_BATCH_SIZE, pri),\n"
"                this,\n"
"                tableName));\n"
"    } else {\n"
"        addExecutor(\n"
"            new Consumer(\n"
"                new ConsumerStateTable(db, tableName, gBatchSize, pri),\n"
"                this,\n"
"                tableName));\n"
"    }\n"
"}\n"
"```"

#: src/4-3-event-polling-and-error-handling.md:1
msgid "# 事件分发和错误处理"
msgstr "# 事件分发和错误处理"

#: src/4-3-event-polling-and-error-handling.md:3
msgid "## 基于epoll的事件分发机制"
msgstr "## 基于epoll的事件分发机制"

#: src/4-3-event-polling-and-error-handling.md:5
msgid "和很多的Linux服务一样，SONiC底层使用了epoll作为事件分发机制："
msgstr "和很多的Linux服务一样，SONiC底层使用了epoll作为事件分发机制："

#: src/4-3-event-polling-and-error-handling.md:7
msgid ""
"- 所有需要支持事件分发的类都需要继承`Selectable`类，并实现两个最核心的函数："
"`int getFd();`（用于返回epoll能用来监听事件的fd）和`uint64_t readData()`（用"
"于在监听到事件到来之后进行读取）。而对于一般服务而言，这个fd就是redis通信使用"
"的fd，所以`getFd()`函数的调用，都会被最终转发到Redis的库中。\n"
"- 所有需要参与事件分发的对象，都需要注册到`Select`类中，这个类会将所有的"
"`Selectable`对象的fd注册到epoll中，并在事件到来时调用`Selectable`的"
"`readData()`函数。"
msgstr ""
"- 所有需要支持事件分发的类都需要继承`Selectable`类，并实现两个最核心的函数："
"`int getFd();`（用于返回epoll能用来监听事件的fd）和`uint64_t readData()`（用"
"于在监听到事件到来之后进行读取）。而对于一般服务而言，这个fd就是redis通信使用"
"的fd，所以`getFd()`函数的调用，都会被最终转发到Redis的库中。\n"
"- 所有需要参与事件分发的对象，都需要注册到`Select`类中，这个类会将所有的"
"`Selectable`对象的fd注册到epoll中，并在事件到来时调用`Selectable`的"
"`readData()`函数。"

#: src/4-3-event-polling-and-error-handling.md:10
msgid "其类图如下："
msgstr "其类图如下："

#: src/4-3-event-polling-and-error-handling.md:14
msgid "在Select类中，我们可以很容易的找到其最核心的代码，实现也非常的简单："
msgstr "在Select类中，我们可以很容易的找到其最核心的代码，实现也非常的简单："

#: src/4-3-event-polling-and-error-handling.md:16
msgid ""
"```cpp\n"
"int Select::poll_descriptors(Selectable **c, unsigned int timeout, bool "
"interrupt_on_signal = false)\n"
"{\n"
"    int sz_selectables = static_cast<int>(m_objects.size());\n"
"    std::vector<struct epoll_event> events(sz_selectables);\n"
"    int ret;\n"
"\n"
"    while(true) {\n"
"        ret = ::epoll_wait(m_epoll_fd, events.data(), sz_selectables, "
"timeout);\n"
"        // ...\n"
"    }\n"
"    // ...\n"
"\n"
"    for (int i = 0; i < ret; ++i)\n"
"    {\n"
"        int fd = events[i].data.fd;\n"
"        Selectable* sel = m_objects[fd];\n"
"\n"
"        sel->readData();\n"
"        // error handling here ...\n"
"\n"
"        m_ready.insert(sel);\n"
"    }\n"
"\n"
"    while (!m_ready.empty())\n"
"    {\n"
"        auto sel = *m_ready.begin();\n"
"        m_ready.erase(sel);\n"
"        \n"
"        // After update callback ...\n"
"        return Select::OBJECT;\n"
"    }\n"
"\n"
"    return Select::TIMEOUT;\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"int Select::poll_descriptors(Selectable **c, unsigned int timeout, bool "
"interrupt_on_signal = false)\n"
"{\n"
"    int sz_selectables = static_cast<int>(m_objects.size());\n"
"    std::vector<struct epoll_event> events(sz_selectables);\n"
"    int ret;\n"
"\n"
"    while(true) {\n"
"        ret = ::epoll_wait(m_epoll_fd, events.data(), sz_selectables, "
"timeout);\n"
"        // ...\n"
"    }\n"
"    // ...\n"
"\n"
"    for (int i = 0; i < ret; ++i)\n"
"    {\n"
"        int fd = events[i].data.fd;\n"
"        Selectable* sel = m_objects[fd];\n"
"\n"
"        sel->readData();\n"
"        // error handling here ...\n"
"\n"
"        m_ready.insert(sel);\n"
"    }\n"
"\n"
"    while (!m_ready.empty())\n"
"    {\n"
"        auto sel = *m_ready.begin();\n"
"        m_ready.erase(sel);\n"
"        \n"
"        // After update callback ...\n"
"        return Select::OBJECT;\n"
"    }\n"
"\n"
"    return Select::TIMEOUT;\n"
"}\n"
"```"

#: src/4-3-event-polling-and-error-handling.md:53
msgid ""
"然而，问题来了…… 回调呢？我们上面提过，`readData()`只是把消息读出来放在一个待"
"处理队列中，并不会真正的处理消息，真正的消息处理需要调用`pops()`函数，将消息"
"拿出来处理，所以什么地方会调用每一个上层封装的消息处理呢？"
msgstr ""
"然而，问题来了…… 回调呢？我们上面提过，`readData()`只是把消息读出来放在一个待"
"处理队列中，并不会真正的处理消息，真正的消息处理需要调用`pops()`函数，将消息"
"拿出来处理，所以什么地方会调用每一个上层封装的消息处理呢？"

#: src/4-3-event-polling-and-error-handling.md:55
msgid ""
"这里我们还是找到我们的老朋友`portmgrd`的`main`函数，从下面简化的代码中，我们"
"可以看到和一般的Event Loop实现不同，SONiC中，最后的事件处理不是通过回调来实现"
"的，而是需要最外层的Event Loop来主动调用完成："
msgstr ""
"这里我们还是找到我们的老朋友`portmgrd`的`main`函数，从下面简化的代码中，我们"
"可以看到和一般的Event Loop实现不同，SONiC中，最后的事件处理不是通过回调来实现"
"的，而是需要最外层的Event Loop来主动调用完成："

#: src/4-3-event-polling-and-error-handling.md:57
msgid ""
"```cpp\n"
"int main(int argc, char **argv)\n"
"{\n"
"    // ...\n"
"\n"
"    // Create PortMgr, which implements Orch interface.\n"
"    PortMgr portmgr(&cfgDb, &appDb, &stateDb, cfg_port_tables);\n"
"    vector<Orch *> cfgOrchList = {&portmgr};\n"
"\n"
"    // Create Select object for event loop and add PortMgr to it.\n"
"    swss::Select s;\n"
"    for (Orch *o : cfgOrchList) {\n"
"        s.addSelectables(o->getSelectables());\n"
"    }\n"
"\n"
"    // Event loop\n"
"    while (true)\n"
"    {\n"
"        Selectable *sel;\n"
"        int ret;\n"
"\n"
"        // When anyone of the selectables gets signaled, select() will call\n"
"        // into readData() and fetch all events, then return.\n"
"        ret = s.select(&sel, SELECT_TIMEOUT);\n"
"        // ...\n"
"\n"
"        // Then, we call into execute() explicitly to process all events.\n"
"        auto *c = (Executor *)sel;\n"
"        c->execute();\n"
"    }\n"
"    return -1;\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"int main(int argc, char **argv)\n"
"{\n"
"    // ...\n"
"\n"
"    // Create PortMgr, which implements Orch interface.\n"
"    PortMgr portmgr(&cfgDb, &appDb, &stateDb, cfg_port_tables);\n"
"    vector<Orch *> cfgOrchList = {&portmgr};\n"
"\n"
"    // Create Select object for event loop and add PortMgr to it.\n"
"    swss::Select s;\n"
"    for (Orch *o : cfgOrchList) {\n"
"        s.addSelectables(o->getSelectables());\n"
"    }\n"
"\n"
"    // Event loop\n"
"    while (true)\n"
"    {\n"
"        Selectable *sel;\n"
"        int ret;\n"
"\n"
"        // When anyone of the selectables gets signaled, select() will call\n"
"        // into readData() and fetch all events, then return.\n"
"        ret = s.select(&sel, SELECT_TIMEOUT);\n"
"        // ...\n"
"\n"
"        // Then, we call into execute() explicitly to process all events.\n"
"        auto *c = (Executor *)sel;\n"
"        c->execute();\n"
"    }\n"
"    return -1;\n"
"}\n"
"```"

#: src/4-3-event-polling-and-error-handling.md:91
msgid "## 错误处理"
msgstr "## 错误处理"

#: src/4-3-event-polling-and-error-handling.md:93
msgid ""
"关于Event Loop我们还有一个问题，那就是错误处理，比如，如果Redis的命令执行出错"
"了，连接断开了，故障了等等的情况下，我们的服务会发生什么呢？"
msgstr ""
"关于Event Loop我们还有一个问题，那就是错误处理，比如，如果Redis的命令执行出错"
"了，连接断开了，故障了等等的情况下，我们的服务会发生什么呢？"

#: src/4-3-event-polling-and-error-handling.md:95
msgid ""
"从代码上来看，SONiC中的错误处理是非常简单的，就是直接抛出异常（比如，获取命令"
"执行结果的代码，如下），然后在Event Loop中捕获异常，打印日志，接着继续执行。"
msgstr ""
"从代码上来看，SONiC中的错误处理是非常简单的，就是直接抛出异常（比如，获取命令"
"执行结果的代码，如下），然后在Event Loop中捕获异常，打印日志，接着继续执行。"

#: src/4-3-event-polling-and-error-handling.md:97
msgid ""
"```cpp\n"
"RedisReply::RedisReply(RedisContext *ctx, const RedisCommand& command)\n"
"{\n"
"    int rc = redisAppendFormattedCommand(ctx->getContext(), command.c_str(), "
"command.length());\n"
"    if (rc != REDIS_OK)\n"
"    {\n"
"        // The only reason of error is REDIS_ERR_OOM (Out of memory)\n"
"        // ref: https://github.com/redis/hiredis/blob/master/hiredis.c\n"
"        throw bad_alloc();\n"
"    }\n"
"\n"
"    rc = redisGetReply(ctx->getContext(), (void**)&m_reply);\n"
"    if (rc != REDIS_OK)\n"
"    {\n"
"        throw RedisError(\"Failed to redisGetReply with \" + string(command."
"c_str()), ctx->getContext());\n"
"    }\n"
"    guard([&]{checkReply();}, command.c_str());\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"RedisReply::RedisReply(RedisContext *ctx, const RedisCommand& command)\n"
"{\n"
"    int rc = redisAppendFormattedCommand(ctx->getContext(), command.c_str(), "
"command.length());\n"
"    if (rc != REDIS_OK)\n"
"    {\n"
"        // The only reason of error is REDIS_ERR_OOM (Out of memory)\n"
"        // ref: https://github.com/redis/hiredis/blob/master/hiredis.c\n"
"        throw bad_alloc();\n"
"    }\n"
"\n"
"    rc = redisGetReply(ctx->getContext(), (void**)&m_reply);\n"
"    if (rc != REDIS_OK)\n"
"    {\n"
"        throw RedisError(\"Failed to redisGetReply with \" + string(command."
"c_str()), ctx->getContext());\n"
"    }\n"
"    guard([&]{checkReply();}, command.c_str());\n"
"}\n"
"```"

#: src/4-3-event-polling-and-error-handling.md:117
msgid ""
"关于异常和错误的种类及其原因，在代码里面并没有看到用于统计和Telemetry的代码，"
"所以监控上说是比较薄弱的。另外还需要考虑数据出错的场景，比如数据库写到一半突"
"然断开导致的脏数据，不过简单的重启相关的`*syncd`和`*mgrd`服务可能可以解决此类"
"问题，因为启动时会进行全量同步。"
msgstr ""
"关于异常和错误的种类及其原因，在代码里面并没有看到用于统计和Telemetry的代码，"
"所以监控上说是比较薄弱的。另外还需要考虑数据出错的场景，比如数据库写到一半突"
"然断开导致的脏数据，不过简单的重启相关的`*syncd`和`*mgrd`服务可能可以解决此类"
"问题，因为启动时会进行全量同步。"

#: src/5-workflows.md:1
msgid "# 工作流"
msgstr "# 工作流"

#: src/5-workflows.md:3
msgid "这一章，我们来看一下SONiC中一些比较有代表性的工作流。"
msgstr "这一章，我们来看一下SONiC中一些比较有代表性的工作流。"

#: src/5-workflows.md:5
msgid ""
"```admonish note\n"
"为了方便阅读和理解，所有的代码都只是列出了最核心的代码来展现流程，并不是完整"
"的代码，如果需要查看完整代码，请参考[仓库中的原始代码](./3-1-code-repos."
"html)。\n"
"\n"
"另外，每个代码块的开头都给出了相关文件的路径，其使用的是仓库均为SONiC的主仓"
"库：[sonic-buildimage](https://github.com/sonic-net/sonic-buildimage)。\n"
"```"
msgstr ""
"```admonish note\n"
"为了方便阅读和理解，所有的代码都只是列出了最核心的代码来展现流程，并不是完整"
"的代码，如果需要查看完整代码，请参考[仓库中的原始代码](./3-1-code-repos."
"html)。\n"
"\n"
"另外，每个代码块的开头都给出了相关文件的路径，其使用的是仓库均为SONiC的主仓"
"库：[sonic-buildimage](https://github.com/sonic-net/sonic-buildimage)。\n"
"```"

#: src/5-1-syncd-sai-workflow.md:1
msgid "# Syncd工作流"
msgstr "# Syncd工作流"

#: src/5-1-syncd-sai-workflow.md:3
msgid ""
"[Syncd容器](./2-3-key-containers.html#asic管理容器syncd)是SONiC中专门负责管理"
"ASIC的容器，其中核心进程`syncd`负责与Redis数据库沟通，加载SAI并与其交互，以完"
"成ASIC的初始化，配置和状态上报的处理等等。"
msgstr ""
"[Syncd容器](./2-3-key-containers.html#asic管理容器syncd)是SONiC中专门负责管理"
"ASIC的容器，其中核心进程`syncd`负责与Redis数据库沟通，加载SAI并与其交互，以完"
"成ASIC的初始化，配置和状态上报的处理等等。"

#: src/5-1-syncd-sai-workflow.md:5
msgid ""
"由于SONiC中大量的工作流最后都需要通过Syncd和SAI来和ASIC进行交互，所以这一部分"
"也就成为了这些工作流的公共部分，所以，在展开其他工作流之前，我们先来看一下"
"Syncd和SAI是如何工作的。"
msgstr ""
"由于SONiC中大量的工作流最后都需要通过Syncd和SAI来和ASIC进行交互，所以这一部分"
"也就成为了这些工作流的公共部分，所以，在展开其他工作流之前，我们先来看一下"
"Syncd和SAI是如何工作的。"

#: src/5-1-syncd-sai-workflow.md:7
msgid "## Syncd启动流程"
msgstr "## Syncd启动流程"

#: src/5-1-syncd-sai-workflow.md:9
msgid ""
"`syncd`进程的入口在`syncd_main.cpp`中的`syncd_main`函数，其启动的整体流程大致"
"分为两部分。"
msgstr ""
"`syncd`进程的入口在`syncd_main.cpp`中的`syncd_main`函数，其启动的整体流程大致"
"分为两部分。"

#: src/5-1-syncd-sai-workflow.md:11
msgid "第一部分是创建各个对象，并进行初始化："
msgstr "第一部分是创建各个对象，并进行初始化："

#: src/5-1-syncd-sai-workflow.md:13
msgid ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant SDM as syncd_main\n"
"    participant SD as Syncd\n"
"    participant SAI as VendorSai\n"
"\n"
"    SDM->>+SD: 调用构造函数\n"
"    SD->>SD: 加载和解析命令行参数和配置文件\n"
"    SD->>SD: 创建数据库相关对象，如：<br/>ASIC_DB Connector和"
"FlexCounterManager\n"
"    SD->>SD: 创建MDIO IPC服务器\n"
"    SD->>SD: 创建SAI上报处理逻辑\n"
"    SD->>SD: 创建RedisSelectableChannel用于接收Redis通知\n"
"    SD->>-SAI: 初始化SAI\n"
"```"
msgstr ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant SDM as syncd_main\n"
"    participant SD as Syncd\n"
"    participant SAI as VendorSai\n"
"\n"
"    SDM->>+SD: 调用构造函数\n"
"    SD->>SD: 加载和解析命令行参数和配置文件\n"
"    SD->>SD: 创建数据库相关对象，如：<br/>ASIC_DB Connector和"
"FlexCounterManager\n"
"    SD->>SD: 创建MDIO IPC服务器\n"
"    SD->>SD: 创建SAI上报处理逻辑\n"
"    SD->>SD: 创建RedisSelectableChannel用于接收Redis通知\n"
"    SD->>-SAI: 初始化SAI\n"
"```"

#: src/5-1-syncd-sai-workflow.md:29
msgid "第二个部分是启动主循环，并且处理初始化事件："
msgstr "第二个部分是启动主循环，并且处理初始化事件："

#: src/5-1-syncd-sai-workflow.md:31
msgid ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant SDM as syncd_main\n"
"    participant SD as Syncd\n"
"    participant SAI as VendorSai\n"
"    participant NP as NotificationProcessor\n"
"    participant MIS as MdioIpcServer\n"
"\n"
"    SDM->>+SD: 启动主线程循环\n"
"    SD->>NP: 启动SAI上报处理线程\n"
"    NP->>NP: 开始通知处理循环\n"
"    SD->>MIS: 启动MDIO IPC服务器线程\n"
"    MIS->>MIS: 开始MDIO IPC服务器事件循环\n"
"    SD->>SD: 初始化并启动事件分发机制，开始主循环\n"
"\n"
"    loop 处理事件\n"
"        alt 如果是创建Switch的事件或者是WarmBoot\n"
"            SD->>SAI: 创建Switch对象，设置通知回调\n"
"        else 如果是其他事件\n"
"            SD->>SD: 处理事件\n"
"        end\n"
"    end\n"
"\n"
"    SD->>-SDM: 退出主循环返回\n"
"```"
msgstr ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant SDM as syncd_main\n"
"    participant SD as Syncd\n"
"    participant SAI as VendorSai\n"
"    participant NP as NotificationProcessor\n"
"    participant MIS as MdioIpcServer\n"
"\n"
"    SDM->>+SD: 启动主线程循环\n"
"    SD->>NP: 启动SAI上报处理线程\n"
"    NP->>NP: 开始通知处理循环\n"
"    SD->>MIS: 启动MDIO IPC服务器线程\n"
"    MIS->>MIS: 开始MDIO IPC服务器事件循环\n"
"    SD->>SD: 初始化并启动事件分发机制，开始主循环\n"
"\n"
"    loop 处理事件\n"
"        alt 如果是创建Switch的事件或者是WarmBoot\n"
"            SD->>SAI: 创建Switch对象，设置通知回调\n"
"        else 如果是其他事件\n"
"            SD->>SD: 处理事件\n"
"        end\n"
"    end\n"
"\n"
"    SD->>-SDM: 退出主循环返回\n"
"```"

#: src/5-1-syncd-sai-workflow.md:58
msgid "然后我们再从代码的角度来更加仔细的看一下这个流程。"
msgstr "然后我们再从代码的角度来更加仔细的看一下这个流程。"

#: src/5-1-syncd-sai-workflow.md:60
msgid "### syncd_main函数"
msgstr "### syncd_main函数"

#: src/5-1-syncd-sai-workflow.md:62
msgid ""
"`syncd_main`函数本身非常简单，主要逻辑就是创建Syncd对象，然后调用其`run`方"
"法："
msgstr ""
"`syncd_main`函数本身非常简单，主要逻辑就是创建Syncd对象，然后调用其`run`方"
"法："

#: src/5-1-syncd-sai-workflow.md:64
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/syncd_main.cpp\n"
"int syncd_main(int argc, char **argv)\n"
"{\n"
"    auto vendorSai = std::make_shared<VendorSai>();\n"
"    auto syncd = std::make_shared<Syncd>(vendorSai, commandLineOptions, "
"isWarmStart);\n"
"    syncd->run();\n"
"    return EXIT_SUCCESS;\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/syncd_main.cpp\n"
"int syncd_main(int argc, char **argv)\n"
"{\n"
"    auto vendorSai = std::make_shared<VendorSai>();\n"
"    auto syncd = std::make_shared<Syncd>(vendorSai, commandLineOptions, "
"isWarmStart);\n"
"    syncd->run();\n"
"    return EXIT_SUCCESS;\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:75
msgid ""
"其中，`Syncd`对象的构造函数负责初始化`Syncd`中的各个功能，而`run`方法则负责启"
"动Syncd的主循环。"
msgstr ""
"其中，`Syncd`对象的构造函数负责初始化`Syncd`中的各个功能，而`run`方法则负责启"
"动Syncd的主循环。"

#: src/5-1-syncd-sai-workflow.md:77
msgid "### Syncd构造函数"
msgstr "### Syncd构造函数"

#: src/5-1-syncd-sai-workflow.md:79
msgid ""
"`Syncd`对象的构造函数负责创建或初始化`Syncd`中的各个功能，比如用于连接数据库"
"的对象，统计管理，和ASIC通知的处理逻辑等等，其主要代码如下："
msgstr ""
"`Syncd`对象的构造函数负责创建或初始化`Syncd`中的各个功能，比如用于连接数据库"
"的对象，统计管理，和ASIC通知的处理逻辑等等，其主要代码如下："

#: src/5-1-syncd-sai-workflow.md:81
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"Syncd::Syncd(\n"
"        _In_ std::shared_ptr<sairedis::SaiInterface> vendorSai,\n"
"        _In_ std::shared_ptr<CommandLineOptions> cmd,\n"
"        _In_ bool isWarmStart):\n"
"    m_vendorSai(vendorSai),\n"
"    ...\n"
"{\n"
"    ...\n"
"\n"
"    // Load context config\n"
"    auto ccc = sairedis::ContextConfigContainer::"
"loadFromFile(m_commandLineOptions->m_contextConfig.c_str());\n"
"    m_contextConfig = ccc->get(m_commandLineOptions->m_globalContext);\n"
"    ...\n"
"\n"
"    // Create FlexCounter manager\n"
"    m_manager = std::make_shared<FlexCounterManager>(m_vendorSai, "
"m_contextConfig->m_dbCounters);\n"
"\n"
"    // Create DB related objects\n"
"    m_dbAsic = std::make_shared<swss::DBConnector>(m_contextConfig-"
">m_dbAsic, 0);\n"
"    m_mdioIpcServer = std::make_shared<MdioIpcServer>(m_vendorSai, "
"m_commandLineOptions->m_globalContext);\n"
"    m_selectableChannel = std::make_shared<sairedis::"
"RedisSelectableChannel>(m_dbAsic, ASIC_STATE_TABLE, REDIS_TABLE_GETRESPONSE, "
"TEMP_PREFIX, modifyRedis);\n"
"\n"
"    // Create notification processor and handler\n"
"    m_notifications = std::"
"make_shared<RedisNotificationProducer>(m_contextConfig->m_dbAsic);\n"
"    m_client = std::make_shared<RedisClient>(m_dbAsic);\n"
"    m_processor = std::make_shared<NotificationProcessor>(m_notifications, "
"m_client, std::bind(&Syncd::syncProcessNotification, this, _1));\n"
"\n"
"    m_handler = std::make_shared<NotificationHandler>(m_processor);\n"
"    m_sn.onFdbEvent = std::bind(&NotificationHandler::onFdbEvent, m_handler."
"get(), _1, _2);\n"
"    m_sn.onNatEvent = std::bind(&NotificationHandler::onNatEvent, m_handler."
"get(), _1, _2);\n"
"    // Init many other event handlers here\n"
"    m_handler->setSwitchNotifications(m_sn.getSwitchNotifications());\n"
"    ...\n"
"\n"
"    // Initialize SAI\n"
"    sai_status_t status = vendorSai->initialize(0, &m_test_services);\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"Syncd::Syncd(\n"
"        _In_ std::shared_ptr<sairedis::SaiInterface> vendorSai,\n"
"        _In_ std::shared_ptr<CommandLineOptions> cmd,\n"
"        _In_ bool isWarmStart):\n"
"    m_vendorSai(vendorSai),\n"
"    ...\n"
"{\n"
"    ...\n"
"\n"
"    // Load context config\n"
"    auto ccc = sairedis::ContextConfigContainer::"
"loadFromFile(m_commandLineOptions->m_contextConfig.c_str());\n"
"    m_contextConfig = ccc->get(m_commandLineOptions->m_globalContext);\n"
"    ...\n"
"\n"
"    // Create FlexCounter manager\n"
"    m_manager = std::make_shared<FlexCounterManager>(m_vendorSai, "
"m_contextConfig->m_dbCounters);\n"
"\n"
"    // Create DB related objects\n"
"    m_dbAsic = std::make_shared<swss::DBConnector>(m_contextConfig-"
">m_dbAsic, 0);\n"
"    m_mdioIpcServer = std::make_shared<MdioIpcServer>(m_vendorSai, "
"m_commandLineOptions->m_globalContext);\n"
"    m_selectableChannel = std::make_shared<sairedis::"
"RedisSelectableChannel>(m_dbAsic, ASIC_STATE_TABLE, REDIS_TABLE_GETRESPONSE, "
"TEMP_PREFIX, modifyRedis);\n"
"\n"
"    // Create notification processor and handler\n"
"    m_notifications = std::"
"make_shared<RedisNotificationProducer>(m_contextConfig->m_dbAsic);\n"
"    m_client = std::make_shared<RedisClient>(m_dbAsic);\n"
"    m_processor = std::make_shared<NotificationProcessor>(m_notifications, "
"m_client, std::bind(&Syncd::syncProcessNotification, this, _1));\n"
"\n"
"    m_handler = std::make_shared<NotificationHandler>(m_processor);\n"
"    m_sn.onFdbEvent = std::bind(&NotificationHandler::onFdbEvent, m_handler."
"get(), _1, _2);\n"
"    m_sn.onNatEvent = std::bind(&NotificationHandler::onNatEvent, m_handler."
"get(), _1, _2);\n"
"    // Init many other event handlers here\n"
"    m_handler->setSwitchNotifications(m_sn.getSwitchNotifications());\n"
"    ...\n"
"\n"
"    // Initialize SAI\n"
"    sai_status_t status = vendorSai->initialize(0, &m_test_services);\n"
"    ...\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:123
msgid "### SAI的初始化与VendorSai"
msgstr "### SAI的初始化与VendorSai"

#: src/5-1-syncd-sai-workflow.md:125
msgid ""
"`Syncd`初始化的最后也是最重要的一步，就是对SAI进行初始化。[在核心组件的SAI介"
"绍中，我们简单的展示了SAI的初始化，实现，以及它是如何为SONiC提供不同平台的支"
"持](./2-4-sai-intro.html)，所以这里我们主要来看看`Syncd`是如何对SAI进行封装和"
"调用的。"
msgstr ""
"`Syncd`初始化的最后也是最重要的一步，就是对SAI进行初始化。[在核心组件的SAI介"
"绍中，我们简单的展示了SAI的初始化，实现，以及它是如何为SONiC提供不同平台的支"
"持](./2-4-sai-intro.html)，所以这里我们主要来看看`Syncd`是如何对SAI进行封装和"
"调用的。"

#: src/5-1-syncd-sai-workflow.md:127
msgid ""
"`Syncd`使用`VendorSai`来对SAI的所有API进行封装，方便上层调用。其初始化过程也"
"非常直接，基本就是对上面两个函数的直接调用和错误处理，如下："
msgstr ""
"`Syncd`使用`VendorSai`来对SAI的所有API进行封装，方便上层调用。其初始化过程也"
"非常直接，基本就是对上面两个函数的直接调用和错误处理，如下："

#: src/5-1-syncd-sai-workflow.md:129
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/VendorSai.cpp\n"
"sai_status_t VendorSai::initialize(\n"
"        _In_ uint64_t flags,\n"
"        _In_ const sai_service_method_table_t *service_method_table)\n"
"{\n"
"    ...\n"
"    \n"
"    // Initialize SAI\n"
"    memcpy(&m_service_method_table, service_method_table, "
"sizeof(m_service_method_table));\n"
"    auto status = sai_api_initialize(flags, service_method_table);\n"
"\n"
"    // If SAI is initialized successfully, query all SAI API methods.\n"
"    // sai_metadata_api_query will also update all extern global sai_*_api "
"variables, so we can also use\n"
"    // sai_metadata_get_object_type_info to get methods for a specific SAI "
"object type.\n"
"    if (status == SAI_STATUS_SUCCESS) {\n"
"        memset(&m_apis, 0, sizeof(m_apis));\n"
"        int failed = sai_metadata_apis_query(sai_api_query, &m_apis);\n"
"        ...\n"
"    }\n"
"    ...\n"
"\n"
"    return status;\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/VendorSai.cpp\n"
"sai_status_t VendorSai::initialize(\n"
"        _In_ uint64_t flags,\n"
"        _In_ const sai_service_method_table_t *service_method_table)\n"
"{\n"
"    ...\n"
"    \n"
"    // Initialize SAI\n"
"    memcpy(&m_service_method_table, service_method_table, "
"sizeof(m_service_method_table));\n"
"    auto status = sai_api_initialize(flags, service_method_table);\n"
"\n"
"    // If SAI is initialized successfully, query all SAI API methods.\n"
"    // sai_metadata_api_query will also update all extern global sai_*_api "
"variables, so we can also use\n"
"    // sai_metadata_get_object_type_info to get methods for a specific SAI "
"object type.\n"
"    if (status == SAI_STATUS_SUCCESS) {\n"
"        memset(&m_apis, 0, sizeof(m_apis));\n"
"        int failed = sai_metadata_apis_query(sai_api_query, &m_apis);\n"
"        ...\n"
"    }\n"
"    ...\n"
"\n"
"    return status;\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:155
msgid ""
"当获取好所有的SAI API之后，我们就可以通过`VendorSai`对象来调用SAI的API了。当"
"前调用SAI的API方式主要有两种。"
msgstr ""
"当获取好所有的SAI API之后，我们就可以通过`VendorSai`对象来调用SAI的API了。当"
"前调用SAI的API方式主要有两种。"

#: src/5-1-syncd-sai-workflow.md:157
msgid ""
"第一种是通过`sai_object_type_into_t`来调用，它类似于为所有的SAI Object实现了"
"一个虚表，如下："
msgstr ""
"第一种是通过`sai_object_type_into_t`来调用，它类似于为所有的SAI Object实现了"
"一个虚表，如下："

#: src/5-1-syncd-sai-workflow.md:159
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/VendorSai.cpp\n"
"sai_status_t VendorSai::set(\n"
"        _In_ sai_object_type_t objectType,\n"
"        _In_ sai_object_id_t objectId,\n"
"        _In_ const sai_attribute_t *attr)\n"
"{\n"
"    ...\n"
"\n"
"    auto info = sai_metadata_get_object_type_info(objectType);\n"
"    sai_object_meta_key_t mk = { .objecttype = objectType, .objectkey = { ."
"key = { .object_id = objectId } } };\n"
"    return info->set(&mk, attr);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/VendorSai.cpp\n"
"sai_status_t VendorSai::set(\n"
"        _In_ sai_object_type_t objectType,\n"
"        _In_ sai_object_id_t objectId,\n"
"        _In_ const sai_attribute_t *attr)\n"
"{\n"
"    ...\n"
"\n"
"    auto info = sai_metadata_get_object_type_info(objectType);\n"
"    sai_object_meta_key_t mk = { .objecttype = objectType, .objectkey = { ."
"key = { .object_id = objectId } } };\n"
"    return info->set(&mk, attr);\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:174
msgid ""
"另外一种是通过保存在`VendorSai`对象中的`m_apis`来调用，这种方式更加直接，但是"
"调用前需要先根据SAI Object的类型来调用不同的API。"
msgstr ""
"另外一种是通过保存在`VendorSai`对象中的`m_apis`来调用，这种方式更加直接，但是"
"调用前需要先根据SAI Object的类型来调用不同的API。"

#: src/5-1-syncd-sai-workflow.md:176
msgid ""
"```cpp\n"
"sai_status_t VendorSai::getStatsExt(\n"
"        _In_ sai_object_type_t object_type,\n"
"        _In_ sai_object_id_t object_id,\n"
"        _In_ uint32_t number_of_counters,\n"
"        _In_ const sai_stat_id_t *counter_ids,\n"
"        _In_ sai_stats_mode_t mode,\n"
"        _Out_ uint64_t *counters)\n"
"{\n"
"    sai_status_t (*ptr)(\n"
"            _In_ sai_object_id_t port_id,\n"
"            _In_ uint32_t number_of_counters,\n"
"            _In_ const sai_stat_id_t *counter_ids,\n"
"            _In_ sai_stats_mode_t mode,\n"
"            _Out_ uint64_t *counters);\n"
"\n"
"    switch ((int)object_type)\n"
"    {\n"
"        case SAI_OBJECT_TYPE_PORT:\n"
"            ptr = m_apis.port_api->get_port_stats_ext;\n"
"            break;\n"
"        case SAI_OBJECT_TYPE_ROUTER_INTERFACE:\n"
"            ptr = m_apis.router_interface_api-"
">get_router_interface_stats_ext;\n"
"            break;\n"
"        case SAI_OBJECT_TYPE_POLICER:\n"
"            ptr = m_apis.policer_api->get_policer_stats_ext;\n"
"            break;\n"
"        ...\n"
"\n"
"        default:\n"
"            SWSS_LOG_ERROR(\"not implemented, FIXME\");\n"
"            return SAI_STATUS_FAILURE;\n"
"    }\n"
"\n"
"    return ptr(object_id, number_of_counters, counter_ids, mode, counters);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"sai_status_t VendorSai::getStatsExt(\n"
"        _In_ sai_object_type_t object_type,\n"
"        _In_ sai_object_id_t object_id,\n"
"        _In_ uint32_t number_of_counters,\n"
"        _In_ const sai_stat_id_t *counter_ids,\n"
"        _In_ sai_stats_mode_t mode,\n"
"        _Out_ uint64_t *counters)\n"
"{\n"
"    sai_status_t (*ptr)(\n"
"            _In_ sai_object_id_t port_id,\n"
"            _In_ uint32_t number_of_counters,\n"
"            _In_ const sai_stat_id_t *counter_ids,\n"
"            _In_ sai_stats_mode_t mode,\n"
"            _Out_ uint64_t *counters);\n"
"\n"
"    switch ((int)object_type)\n"
"    {\n"
"        case SAI_OBJECT_TYPE_PORT:\n"
"            ptr = m_apis.port_api->get_port_stats_ext;\n"
"            break;\n"
"        case SAI_OBJECT_TYPE_ROUTER_INTERFACE:\n"
"            ptr = m_apis.router_interface_api-"
">get_router_interface_stats_ext;\n"
"            break;\n"
"        case SAI_OBJECT_TYPE_POLICER:\n"
"            ptr = m_apis.policer_api->get_policer_stats_ext;\n"
"            break;\n"
"        ...\n"
"\n"
"        default:\n"
"            SWSS_LOG_ERROR(\"not implemented, FIXME\");\n"
"            return SAI_STATUS_FAILURE;\n"
"    }\n"
"\n"
"    return ptr(object_id, number_of_counters, counter_ids, mode, counters);\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:214
msgid "可以明显看出，第一种调用方式代码要精炼和直观许多。"
msgstr "可以明显看出，第一种调用方式代码要精炼和直观许多。"

#: src/5-1-syncd-sai-workflow.md:216
msgid "### Syncd主循环"
msgstr "### Syncd主循环"

#: src/5-1-syncd-sai-workflow.md:218
msgid ""
"`Syncd`的主循环也是使用的SONiC中标准的[事件分发](./4-3-event-polling-and-"
"error-handling.html)机制：在启动时，`Syncd`会将所有用于事件处理的`Selectable`"
"对象注册到用于获取事件的`Select`对象中，然后在主循环中调用`Select`的`select`"
"方法，等待事件的发生。核心代码如下："
msgstr ""
"`Syncd`的主循环也是使用的SONiC中标准的[事件分发](./4-3-event-polling-and-"
"error-handling.html)机制：在启动时，`Syncd`会将所有用于事件处理的`Selectable`"
"对象注册到用于获取事件的`Select`对象中，然后在主循环中调用`Select`的`select`"
"方法，等待事件的发生。核心代码如下："

#: src/5-1-syncd-sai-workflow.md:220
msgid ""
"```c\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"void Syncd::run()\n"
"{\n"
"    volatile bool runMainLoop = true;\n"
"    std::shared_ptr<swss::Select> s = std::make_shared<swss::Select>();\n"
"    onSyncdStart(m_commandLineOptions->m_startType == "
"SAI_START_TYPE_WARM_BOOT);\n"
"\n"
"    // Start notification processing thread\n"
"    m_processor->startNotificationsProcessingThread();\n"
"\n"
"    // Start MDIO threads\n"
"    for (auto& sw: m_switches) { m_mdioIpcServer->setSwitchId(sw.second-"
">getRid()); }\n"
"    m_mdioIpcServer->startMdioThread();\n"
"\n"
"    // Registering selectable for event polling\n"
"    s->addSelectable(m_selectableChannel.get());\n"
"    s->addSelectable(m_restartQuery.get());\n"
"    s->addSelectable(m_flexCounter.get());\n"
"    s->addSelectable(m_flexCounterGroup.get());\n"
"\n"
"    // Main event loop\n"
"    while (runMainLoop)\n"
"    {\n"
"        swss::Selectable *sel = NULL;\n"
"        int result = s->select(&sel);\n"
"\n"
"        ...\n"
"        if (sel == m_restartQuery.get()) {\n"
"            // Handling switch restart event and restart switch here.\n"
"        } else if (sel == m_flexCounter.get()) {\n"
"            processFlexCounterEvent(*(swss::ConsumerTable*)sel);\n"
"        } else if (sel == m_flexCounterGroup.get()) {\n"
"            processFlexCounterGroupEvent(*(swss::ConsumerTable*)sel);\n"
"        } else if (sel == m_selectableChannel.get()) {\n"
"            // Handle redis updates here.\n"
"            processEvent(*m_selectableChannel.get());\n"
"        } else {\n"
"            SWSS_LOG_ERROR(\"select failed: %d\", result);\n"
"        }\n"
"        ...\n"
"    }\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```c\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"void Syncd::run()\n"
"{\n"
"    volatile bool runMainLoop = true;\n"
"    std::shared_ptr<swss::Select> s = std::make_shared<swss::Select>();\n"
"    onSyncdStart(m_commandLineOptions->m_startType == "
"SAI_START_TYPE_WARM_BOOT);\n"
"\n"
"    // Start notification processing thread\n"
"    m_processor->startNotificationsProcessingThread();\n"
"\n"
"    // Start MDIO threads\n"
"    for (auto& sw: m_switches) { m_mdioIpcServer->setSwitchId(sw.second-"
">getRid()); }\n"
"    m_mdioIpcServer->startMdioThread();\n"
"\n"
"    // Registering selectable for event polling\n"
"    s->addSelectable(m_selectableChannel.get());\n"
"    s->addSelectable(m_restartQuery.get());\n"
"    s->addSelectable(m_flexCounter.get());\n"
"    s->addSelectable(m_flexCounterGroup.get());\n"
"\n"
"    // Main event loop\n"
"    while (runMainLoop)\n"
"    {\n"
"        swss::Selectable *sel = NULL;\n"
"        int result = s->select(&sel);\n"
"\n"
"        ...\n"
"        if (sel == m_restartQuery.get()) {\n"
"            // Handling switch restart event and restart switch here.\n"
"        } else if (sel == m_flexCounter.get()) {\n"
"            processFlexCounterEvent(*(swss::ConsumerTable*)sel);\n"
"        } else if (sel == m_flexCounterGroup.get()) {\n"
"            processFlexCounterGroupEvent(*(swss::ConsumerTable*)sel);\n"
"        } else if (sel == m_selectableChannel.get()) {\n"
"            // Handle redis updates here.\n"
"            processEvent(*m_selectableChannel.get());\n"
"        } else {\n"
"            SWSS_LOG_ERROR(\"select failed: %d\", result);\n"
"        }\n"
"        ...\n"
"    }\n"
"    ...\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:266
msgid ""
"其中，`m_selectableChannel`就是主要负责处理Redis数据库中的事件的对象。它使用"
"[ProducerTable / ConsumerTable](./4-2-2-redis-messaging-layer."
"md#producertable--consumertable)的方式与Redis数据库进行交互，所以，所有"
"`orchagent`发送过来的操作都会以三元组的形式保存在Redis中的list中，等待`Syncd`"
"的处理。其核心定义如下："
msgstr ""
"其中，`m_selectableChannel`就是主要负责处理Redis数据库中的事件的对象。它使用"
"[ProducerTable / ConsumerTable](./4-2-2-redis-messaging-layer."
"md#producertable--consumertable)的方式与Redis数据库进行交互，所以，所有"
"`orchagent`发送过来的操作都会以三元组的形式保存在Redis中的list中，等待`Syncd`"
"的处理。其核心定义如下："

#: src/5-1-syncd-sai-workflow.md:268
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/meta/RedisSelectableChannel.h\n"
"class RedisSelectableChannel: public SelectableChannel\n"
"{\n"
"    public:\n"
"        RedisSelectableChannel(\n"
"                _In_ std::shared_ptr<swss::DBConnector> dbAsic,\n"
"                _In_ const std::string& asicStateTable,\n"
"                _In_ const std::string& getResponseTable,\n"
"                _In_ const std::string& tempPrefix,\n"
"                _In_ bool modifyRedis);\n"
"\n"
"    public: // SelectableChannel overrides\n"
"        virtual bool empty() override;\n"
"        ...\n"
"\n"
"    public: // Selectable overrides\n"
"        virtual int getFd() override;\n"
"        virtual uint64_t readData() override;\n"
"        ...\n"
"\n"
"    private:\n"
"        std::shared_ptr<swss::DBConnector> m_dbAsic;\n"
"        std::shared_ptr<swss::ConsumerTable> m_asicState;\n"
"        std::shared_ptr<swss::ProducerTable> m_getResponse;\n"
"        ...\n"
"};\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/meta/RedisSelectableChannel.h\n"
"class RedisSelectableChannel: public SelectableChannel\n"
"{\n"
"    public:\n"
"        RedisSelectableChannel(\n"
"                _In_ std::shared_ptr<swss::DBConnector> dbAsic,\n"
"                _In_ const std::string& asicStateTable,\n"
"                _In_ const std::string& getResponseTable,\n"
"                _In_ const std::string& tempPrefix,\n"
"                _In_ bool modifyRedis);\n"
"\n"
"    public: // SelectableChannel overrides\n"
"        virtual bool empty() override;\n"
"        ...\n"
"\n"
"    public: // Selectable overrides\n"
"        virtual int getFd() override;\n"
"        virtual uint64_t readData() override;\n"
"        ...\n"
"\n"
"    private:\n"
"        std::shared_ptr<swss::DBConnector> m_dbAsic;\n"
"        std::shared_ptr<swss::ConsumerTable> m_asicState;\n"
"        std::shared_ptr<swss::ProducerTable> m_getResponse;\n"
"        ...\n"
"};\n"
"```"

#: src/5-1-syncd-sai-workflow.md:297
msgid "另外，在主循环启动时，`Syncd`还会额外启动两个线程："
msgstr "另外，在主循环启动时，`Syncd`还会额外启动两个线程："

#: src/5-1-syncd-sai-workflow.md:299
msgid ""
"- 用于接收ASIC上报通知的通知处理线程：`m_processor-"
">startNotificationsProcessingThread();`\n"
"- 用于处理MDIO通信的MDIO IPC处理线程：`m_mdioIpcServer->startMdioThread();`"
msgstr ""
"- 用于接收ASIC上报通知的通知处理线程：`m_processor-"
">startNotificationsProcessingThread();`\n"
"- 用于处理MDIO通信的MDIO IPC处理线程：`m_mdioIpcServer->startMdioThread();`"

#: src/5-1-syncd-sai-workflow.md:302
msgid ""
"它们的细节我们在初始化的部分不做过多展开，等后面介绍相关工作流时再来详细介"
"绍。"
msgstr ""
"它们的细节我们在初始化的部分不做过多展开，等后面介绍相关工作流时再来详细介"
"绍。"

#: src/5-1-syncd-sai-workflow.md:304
msgid "### 创建Switch对象，初始化通知机制"
msgstr "### 创建Switch对象，初始化通知机制"

#: src/5-1-syncd-sai-workflow.md:306
msgid ""
"在主循环启动后，`Syncd`就会开始调用SAI的API来创建Switch对象，这里的入口有两"
"个，一个是ASIC_DB收到创建Switch的通知，另外一个是Warm Boot时，`Syncd`来主动调"
"用，但是创建Switch这一步的内部流程都类似。"
msgstr ""
"在主循环启动后，`Syncd`就会开始调用SAI的API来创建Switch对象，这里的入口有两"
"个，一个是ASIC_DB收到创建Switch的通知，另外一个是Warm Boot时，`Syncd`来主动调"
"用，但是创建Switch这一步的内部流程都类似。"

#: src/5-1-syncd-sai-workflow.md:308
msgid ""
"在这一步中间，有一个很重要的步骤，就是初始化SAI内部实现中的通知回调，将我们之"
"前已经创建好的通知处理逻辑传递给SAI的实现，比如FDB的事件等等。这些回调函数会"
"被当做Switch的属性（Attributes）通过参数的形式传给SAI的`create_switch`方法，"
"SAI的实现会将其保存起来，这样就可以在事件发生时调用回调函数，来通知`Syncd`"
"了。这里的核心代码如下："
msgstr ""
"在这一步中间，有一个很重要的步骤，就是初始化SAI内部实现中的通知回调，将我们之"
"前已经创建好的通知处理逻辑传递给SAI的实现，比如FDB的事件等等。这些回调函数会"
"被当做Switch的属性（Attributes）通过参数的形式传给SAI的`create_switch`方法，"
"SAI的实现会将其保存起来，这样就可以在事件发生时调用回调函数，来通知`Syncd`"
"了。这里的核心代码如下："

#: src/5-1-syncd-sai-workflow.md:310
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"sai_status_t Syncd::processQuadEvent(\n"
"        _In_ sai_common_api_t api,\n"
"        _In_ const swss::KeyOpFieldsValuesTuple &kco)\n"
"{\n"
"    // Parse event into SAI object\n"
"    sai_object_meta_key_t metaKey;\n"
"    ...\n"
"\n"
"    SaiAttributeList list(metaKey.objecttype, values, false);\n"
"    sai_attribute_t *attr_list = list.get_attr_list();\n"
"    uint32_t attr_count = list.get_attr_count();\n"
"\n"
"    // Update notifications pointers in attribute list\n"
"    if (metaKey.objecttype == SAI_OBJECT_TYPE_SWITCH && (api == "
"SAI_COMMON_API_CREATE || api == SAI_COMMON_API_SET))\n"
"    {\n"
"        m_handler->updateNotificationsPointers(attr_count, attr_list);\n"
"    }\n"
"\n"
"    if (isInitViewMode())\n"
"    {\n"
"        // ProcessQuadEventInInitViewMode will eventually call into "
"VendorSai, which calls create_swtich function in SAI.\n"
"        sai_status_t status = processQuadEventInInitViewMode(metaKey."
"objecttype, strObjectId, api, attr_count, attr_list);\n"
"        syncUpdateRedisQuadEvent(status, api, kco);\n"
"        return status;\n"
"    }\n"
"    ...\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/NotificationHandler.cpp\n"
"void NotificationHandler::updateNotificationsPointers(_In_ uint32_t "
"attr_count, _In_ sai_attribute_t *attr_list) const\n"
"{\n"
"    for (uint32_t index = 0; index < attr_count; ++index) {\n"
"        ...\n"
"\n"
"        sai_attribute_t &attr = attr_list[index];\n"
"        switch (attr.id) {\n"
"            ...\n"
"\n"
"            case SAI_SWITCH_ATTR_SHUTDOWN_REQUEST_NOTIFY:\n"
"                attr.value.ptr = (void*)m_switchNotifications."
"on_switch_shutdown_request;\n"
"                break;\n"
"\n"
"            case SAI_SWITCH_ATTR_FDB_EVENT_NOTIFY:\n"
"                attr.value.ptr = (void*)m_switchNotifications.on_fdb_event;\n"
"                break;\n"
"            ...\n"
"        }\n"
"        ...\n"
"    }\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"// Call stack: processQuadEvent\n"
"//          -> processQuadEventInInitViewMode\n"
"//          -> processQuadInInitViewModeCreate\n"
"//          -> onSwitchCreateInInitViewMode\n"
"void Syncd::onSwitchCreateInInitViewMode(_In_ sai_object_id_t switchVid, "
"_In_ uint32_t attr_count, _In_ const sai_attribute_t *attr_list)\n"
"{\n"
"    if (m_switches.find(switchVid) == m_switches.end()) {\n"
"        sai_object_id_t switchRid;\n"
"        sai_status_t status;\n"
"        status = m_vendorSai->create(SAI_OBJECT_TYPE_SWITCH, &switchRid, 0, "
"attr_count, attr_list);\n"
"        ...\n"
"\n"
"        m_switches[switchVid] = std::make_shared<SaiSwitch>(switchVid, "
"switchRid, m_client, m_translator, m_vendorSai);\n"
"        m_mdioIpcServer->setSwitchId(switchRid);\n"
"        ...\n"
"    }\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"sai_status_t Syncd::processQuadEvent(\n"
"        _In_ sai_common_api_t api,\n"
"        _In_ const swss::KeyOpFieldsValuesTuple &kco)\n"
"{\n"
"    // Parse event into SAI object\n"
"    sai_object_meta_key_t metaKey;\n"
"    ...\n"
"\n"
"    SaiAttributeList list(metaKey.objecttype, values, false);\n"
"    sai_attribute_t *attr_list = list.get_attr_list();\n"
"    uint32_t attr_count = list.get_attr_count();\n"
"\n"
"    // Update notifications pointers in attribute list\n"
"    if (metaKey.objecttype == SAI_OBJECT_TYPE_SWITCH && (api == "
"SAI_COMMON_API_CREATE || api == SAI_COMMON_API_SET))\n"
"    {\n"
"        m_handler->updateNotificationsPointers(attr_count, attr_list);\n"
"    }\n"
"\n"
"    if (isInitViewMode())\n"
"    {\n"
"        // ProcessQuadEventInInitViewMode will eventually call into "
"VendorSai, which calls create_swtich function in SAI.\n"
"        sai_status_t status = processQuadEventInInitViewMode(metaKey."
"objecttype, strObjectId, api, attr_count, attr_list);\n"
"        syncUpdateRedisQuadEvent(status, api, kco);\n"
"        return status;\n"
"    }\n"
"    ...\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/NotificationHandler.cpp\n"
"void NotificationHandler::updateNotificationsPointers(_In_ uint32_t "
"attr_count, _In_ sai_attribute_t *attr_list) const\n"
"{\n"
"    for (uint32_t index = 0; index < attr_count; ++index) {\n"
"        ...\n"
"\n"
"        sai_attribute_t &attr = attr_list[index];\n"
"        switch (attr.id) {\n"
"            ...\n"
"\n"
"            case SAI_SWITCH_ATTR_SHUTDOWN_REQUEST_NOTIFY:\n"
"                attr.value.ptr = (void*)m_switchNotifications."
"on_switch_shutdown_request;\n"
"                break;\n"
"\n"
"            case SAI_SWITCH_ATTR_FDB_EVENT_NOTIFY:\n"
"                attr.value.ptr = (void*)m_switchNotifications.on_fdb_event;\n"
"                break;\n"
"            ...\n"
"        }\n"
"        ...\n"
"    }\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"// Call stack: processQuadEvent\n"
"//          -> processQuadEventInInitViewMode\n"
"//          -> processQuadInInitViewModeCreate\n"
"//          -> onSwitchCreateInInitViewMode\n"
"void Syncd::onSwitchCreateInInitViewMode(_In_ sai_object_id_t switchVid, "
"_In_ uint32_t attr_count, _In_ const sai_attribute_t *attr_list)\n"
"{\n"
"    if (m_switches.find(switchVid) == m_switches.end()) {\n"
"        sai_object_id_t switchRid;\n"
"        sai_status_t status;\n"
"        status = m_vendorSai->create(SAI_OBJECT_TYPE_SWITCH, &switchRid, 0, "
"attr_count, attr_list);\n"
"        ...\n"
"\n"
"        m_switches[switchVid] = std::make_shared<SaiSwitch>(switchVid, "
"switchRid, m_client, m_translator, m_vendorSai);\n"
"        m_mdioIpcServer->setSwitchId(switchRid);\n"
"        ...\n"
"    }\n"
"    ...\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:384
msgid "从Mellanox的SAI实现，我们可以看到其具体的保存的方法："
msgstr "从Mellanox的SAI实现，我们可以看到其具体的保存的方法："

#: src/5-1-syncd-sai-workflow.md:386
msgid ""
"```cpp\n"
"static sai_status_t mlnx_create_switch(_Out_ sai_object_id_t     * "
"switch_id,\n"
"                                       _In_ uint32_t               "
"attr_count,\n"
"                                       _In_ const sai_attribute_t "
"*attr_list)\n"
"{\n"
"    ...\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_SWITCH_STATE_CHANGE_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_switch_state_change = "
"(sai_switch_state_change_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_SHUTDOWN_REQUEST_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_switch_shutdown_request =\n"
"            (sai_switch_shutdown_request_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_FDB_EVENT_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_fdb_event = "
"(sai_fdb_event_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_PORT_STATE_CHANGE_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_port_state_change = "
"(sai_port_state_change_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_PACKET_EVENT_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_packet_event = "
"(sai_packet_event_notification_fn)attr_val->ptr;\n"
"    }\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"static sai_status_t mlnx_create_switch(_Out_ sai_object_id_t     * "
"switch_id,\n"
"                                       _In_ uint32_t               "
"attr_count,\n"
"                                       _In_ const sai_attribute_t "
"*attr_list)\n"
"{\n"
"    ...\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_SWITCH_STATE_CHANGE_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_switch_state_change = "
"(sai_switch_state_change_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_SHUTDOWN_REQUEST_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_switch_shutdown_request =\n"
"            (sai_switch_shutdown_request_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_FDB_EVENT_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_fdb_event = "
"(sai_fdb_event_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_PORT_STATE_CHANGE_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_port_state_change = "
"(sai_port_state_change_notification_fn)attr_val->ptr;\n"
"    }\n"
"\n"
"    status = find_attrib_in_list(attr_count, attr_list, "
"SAI_SWITCH_ATTR_PACKET_EVENT_NOTIFY, &attr_val, &attr_idx);\n"
"    if (!SAI_ERR(status)) {\n"
"        g_notification_callbacks.on_packet_event = "
"(sai_packet_event_notification_fn)attr_val->ptr;\n"
"    }\n"
"    ...\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:422
msgid "## ASIC状态更新"
msgstr "## ASIC状态更新"

#: src/5-1-syncd-sai-workflow.md:424
msgid ""
"ASIC状态更新是`Syncd`中最重要的工作流之一，当`orchagent`发现任何变化并开始修"
"改ASIC_DB时，就会触发该工作流，通过SAI来对ASIC进行更新。在了解了`Syncd`的主循"
"环之后，理解ASIC状态更新的工作流就很简单了。"
msgstr ""
"ASIC状态更新是`Syncd`中最重要的工作流之一，当`orchagent`发现任何变化并开始修"
"改ASIC_DB时，就会触发该工作流，通过SAI来对ASIC进行更新。在了解了`Syncd`的主循"
"环之后，理解ASIC状态更新的工作流就很简单了。"

#: src/5-1-syncd-sai-workflow.md:426
msgid "所有的步骤都发生在主线程一个线程中，顺序执行，总结成时序图如下："
msgstr "所有的步骤都发生在主线程一个线程中，顺序执行，总结成时序图如下："

#: src/5-1-syncd-sai-workflow.md:428
msgid ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant SD as Syncd\n"
"    participant RSC as RedisSelectableChannel\n"
"    participant SAI as VendorSai\n"
"    participant R as Redis\n"
"\n"
"    loop 主线程循环\n"
"        SD->>RSC: 收到epoll通知，通知获取所有到来的消息\n"
"        RSC->>R: 通过ConsumerTable获取所有到来的消息\n"
"\n"
"        critical 给Syncd加锁\n"
"            loop 所有收到的消息\n"
"                SD->>RSC: 获取一个消息\n"
"                SD->>SD: 解析消息，获取操作类型和操作对象\n"
"                SD->>SAI: 调用对应的SAI API，更新ASIC\n"
"                SD->>RSC: 发送调用结果给Redis\n"
"                RSC->>R: 将调用结果写入Redis\n"
"            end\n"
"        end\n"
"    end\n"
"```"
msgstr ""
"```mermaid\n"
"sequenceDiagram\n"
"    autonumber\n"
"    participant SD as Syncd\n"
"    participant RSC as RedisSelectableChannel\n"
"    participant SAI as VendorSai\n"
"    participant R as Redis\n"
"\n"
"    loop 主线程循环\n"
"        SD->>RSC: 收到epoll通知，通知获取所有到来的消息\n"
"        RSC->>R: 通过ConsumerTable获取所有到来的消息\n"
"\n"
"        critical 给Syncd加锁\n"
"            loop 所有收到的消息\n"
"                SD->>RSC: 获取一个消息\n"
"                SD->>SD: 解析消息，获取操作类型和操作对象\n"
"                SD->>SAI: 调用对应的SAI API，更新ASIC\n"
"                SD->>RSC: 发送调用结果给Redis\n"
"                RSC->>R: 将调用结果写入Redis\n"
"            end\n"
"        end\n"
"    end\n"
"```"

#: src/5-1-syncd-sai-workflow.md:452
msgid ""
"首先，`orchagent`通过Redis发送过来的操作会被`RedisSelectableChannel`对象接"
"收，然后在主循环中被处理。当`Syncd`处理到`m_selectableChannel`时，就会调用"
"`processEvent`方法来处理该操作。这几步的核心代码我们上面介绍主循环时已经介绍"
"过了，这里就不再赘述。"
msgstr ""
"首先，`orchagent`通过Redis发送过来的操作会被`RedisSelectableChannel`对象接"
"收，然后在主循环中被处理。当`Syncd`处理到`m_selectableChannel`时，就会调用"
"`processEvent`方法来处理该操作。这几步的核心代码我们上面介绍主循环时已经介绍"
"过了，这里就不再赘述。"

#: src/5-1-syncd-sai-workflow.md:454
msgid ""
"然后，`processEvent`会根据其中的操作类型，调用对应的SAI的API来对ASIC进行更"
"新。其逻辑是一个巨大的switch-case语句，如下："
msgstr ""
"然后，`processEvent`会根据其中的操作类型，调用对应的SAI的API来对ASIC进行更"
"新。其逻辑是一个巨大的switch-case语句，如下："

#: src/5-1-syncd-sai-workflow.md:456
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"void Syncd::processEvent(_In_ sairedis::SelectableChannel& consumer)\n"
"{\n"
"    // Loop all operations in the queue\n"
"    std::lock_guard<std::mutex> lock(m_mutex);\n"
"    do {\n"
"        swss::KeyOpFieldsValuesTuple kco;\n"
"        consumer.pop(kco, isInitViewMode());\n"
"        processSingleEvent(kco);\n"
"    } while (!consumer.empty());\n"
"}\n"
"\n"
"sai_status_t Syncd::processSingleEvent(_In_ const swss::"
"KeyOpFieldsValuesTuple &kco)\n"
"{\n"
"    auto& op = kfvOp(kco);\n"
"    ...\n"
"\n"
"    if (op == REDIS_ASIC_STATE_COMMAND_CREATE)\n"
"        return processQuadEvent(SAI_COMMON_API_CREATE, kco);\n"
"\n"
"    if (op == REDIS_ASIC_STATE_COMMAND_REMOVE)\n"
"        return processQuadEvent(SAI_COMMON_API_REMOVE, kco);\n"
"    \n"
"    ...\n"
"}\n"
"\n"
"sai_status_t Syncd::processQuadEvent(\n"
"        _In_ sai_common_api_t api,\n"
"        _In_ const swss::KeyOpFieldsValuesTuple &kco)\n"
"{\n"
"    // Parse operation\n"
"    const std::string& key = kfvKey(kco);\n"
"    const std::string& strObjectId = key.substr(key.find(\":\") + 1);\n"
"\n"
"    sai_object_meta_key_t metaKey;\n"
"    sai_deserialize_object_meta_key(key, metaKey);\n"
"\n"
"    auto& values = kfvFieldsValues(kco);\n"
"    SaiAttributeList list(metaKey.objecttype, values, false);\n"
"    sai_attribute_t *attr_list = list.get_attr_list();\n"
"    uint32_t attr_count = list.get_attr_count();\n"
"    ...\n"
"\n"
"    auto info = sai_metadata_get_object_type_info(metaKey.objecttype);\n"
"\n"
"    // Process the operation\n"
"    sai_status_t status;\n"
"    if (info->isnonobjectid) {\n"
"        status = processEntry(metaKey, api, attr_count, attr_list);\n"
"    } else {\n"
"        status = processOid(metaKey.objecttype, strObjectId, api, "
"attr_count, attr_list);\n"
"    }\n"
"\n"
"    // Send response\n"
"    if (api == SAI_COMMON_API_GET) {\n"
"        sai_object_id_t switchVid = VidManager::switchIdQuery(metaKey."
"objectkey.key.object_id);\n"
"        sendGetResponse(metaKey.objecttype, strObjectId, switchVid, status, "
"attr_count, attr_list);\n"
"        ...\n"
"    } else {\n"
"        sendApiResponse(api, status);\n"
"    }\n"
"\n"
"    syncUpdateRedisQuadEvent(status, api, kco);\n"
"    return status;\n"
"}\n"
"\n"
"sai_status_t Syncd::processEntry(_In_ sai_object_meta_key_t metaKey, _In_ "
"sai_common_api_t api,\n"
"                                 _In_ uint32_t attr_count, _In_ "
"sai_attribute_t *attr_list)\n"
"{\n"
"    ...\n"
"\n"
"    switch (api)\n"
"    {\n"
"        case SAI_COMMON_API_CREATE:\n"
"            return m_vendorSai->create(metaKey, SAI_NULL_OBJECT_ID, "
"attr_count, attr_list);\n"
"\n"
"        case SAI_COMMON_API_REMOVE:\n"
"            return m_vendorSai->remove(metaKey);\n"
"        ...\n"
"\n"
"        default:\n"
"            SWSS_LOG_THROW(\"api %s not supported\", "
"sai_serialize_common_api(api).c_str());\n"
"    }\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"void Syncd::processEvent(_In_ sairedis::SelectableChannel& consumer)\n"
"{\n"
"    // Loop all operations in the queue\n"
"    std::lock_guard<std::mutex> lock(m_mutex);\n"
"    do {\n"
"        swss::KeyOpFieldsValuesTuple kco;\n"
"        consumer.pop(kco, isInitViewMode());\n"
"        processSingleEvent(kco);\n"
"    } while (!consumer.empty());\n"
"}\n"
"\n"
"sai_status_t Syncd::processSingleEvent(_In_ const swss::"
"KeyOpFieldsValuesTuple &kco)\n"
"{\n"
"    auto& op = kfvOp(kco);\n"
"    ...\n"
"\n"
"    if (op == REDIS_ASIC_STATE_COMMAND_CREATE)\n"
"        return processQuadEvent(SAI_COMMON_API_CREATE, kco);\n"
"\n"
"    if (op == REDIS_ASIC_STATE_COMMAND_REMOVE)\n"
"        return processQuadEvent(SAI_COMMON_API_REMOVE, kco);\n"
"    \n"
"    ...\n"
"}\n"
"\n"
"sai_status_t Syncd::processQuadEvent(\n"
"        _In_ sai_common_api_t api,\n"
"        _In_ const swss::KeyOpFieldsValuesTuple &kco)\n"
"{\n"
"    // Parse operation\n"
"    const std::string& key = kfvKey(kco);\n"
"    const std::string& strObjectId = key.substr(key.find(\":\") + 1);\n"
"\n"
"    sai_object_meta_key_t metaKey;\n"
"    sai_deserialize_object_meta_key(key, metaKey);\n"
"\n"
"    auto& values = kfvFieldsValues(kco);\n"
"    SaiAttributeList list(metaKey.objecttype, values, false);\n"
"    sai_attribute_t *attr_list = list.get_attr_list();\n"
"    uint32_t attr_count = list.get_attr_count();\n"
"    ...\n"
"\n"
"    auto info = sai_metadata_get_object_type_info(metaKey.objecttype);\n"
"\n"
"    // Process the operation\n"
"    sai_status_t status;\n"
"    if (info->isnonobjectid) {\n"
"        status = processEntry(metaKey, api, attr_count, attr_list);\n"
"    } else {\n"
"        status = processOid(metaKey.objecttype, strObjectId, api, "
"attr_count, attr_list);\n"
"    }\n"
"\n"
"    // Send response\n"
"    if (api == SAI_COMMON_API_GET) {\n"
"        sai_object_id_t switchVid = VidManager::switchIdQuery(metaKey."
"objectkey.key.object_id);\n"
"        sendGetResponse(metaKey.objecttype, strObjectId, switchVid, status, "
"attr_count, attr_list);\n"
"        ...\n"
"    } else {\n"
"        sendApiResponse(api, status);\n"
"    }\n"
"\n"
"    syncUpdateRedisQuadEvent(status, api, kco);\n"
"    return status;\n"
"}\n"
"\n"
"sai_status_t Syncd::processEntry(_In_ sai_object_meta_key_t metaKey, _In_ "
"sai_common_api_t api,\n"
"                                 _In_ uint32_t attr_count, _In_ "
"sai_attribute_t *attr_list)\n"
"{\n"
"    ...\n"
"\n"
"    switch (api)\n"
"    {\n"
"        case SAI_COMMON_API_CREATE:\n"
"            return m_vendorSai->create(metaKey, SAI_NULL_OBJECT_ID, "
"attr_count, attr_list);\n"
"\n"
"        case SAI_COMMON_API_REMOVE:\n"
"            return m_vendorSai->remove(metaKey);\n"
"        ...\n"
"\n"
"        default:\n"
"            SWSS_LOG_THROW(\"api %s not supported\", "
"sai_serialize_common_api(api).c_str());\n"
"    }\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:543
msgid "## ASIC状态变更上报"
msgstr "## ASIC状态变更上报"

#: src/5-1-syncd-sai-workflow.md:545
msgid ""
"反过来，当ASIC状态发生任何变化，或者需要上报数据，它也会通过SAI来通知我们，此"
"时Syncd会监听这些通知，然后通过ASIC_DB上报给orchagent。其主要工作流如下："
msgstr ""
"反过来，当ASIC状态发生任何变化，或者需要上报数据，它也会通过SAI来通知我们，此"
"时Syncd会监听这些通知，然后通过ASIC_DB上报给orchagent。其主要工作流如下："

#: src/5-1-syncd-sai-workflow.md:547
msgid ""
"```mermaid\n"
"sequenceDiagram\n"
"    participant SAI as SAI Impl\n"
"    participant NP as NotificationProcessor\n"
"    participant SD as Syncd\n"
"    participant RNP as RedisNotificationProducer\n"
"    participant R as Redis\n"
"\n"
"    loop SAI实现事件处理线程\n"
"        SAI->>SAI: 通过ASIC SDK获取事件\n"
"        SAI->>SAI: 解析事件，并转换成SAI通知对象\n"
"        SAI->>NP: 将通知对象序列化，<br/>并发送给通知处理线程的队列中\n"
"    end\n"
"\n"
"    loop 通知处理线程消息循环\n"
"        NP->>NP: 从队列中获取通知\n"
"        NP->>SD: 获取Syncd锁\n"
"        critical 给Syncd加锁\n"
"            NP->>NP: 反序列化通知对象，并做一些处理\n"
"            NP->>RNP: 重新序列化通知对象，并请求发送\n"
"            RNP->>R: 将通知以NotificationProducer<br/>的形式写入ASIC_DB\n"
"        end\n"
"    end\n"
"```"
msgstr ""
"```mermaid\n"
"sequenceDiagram\n"
"    participant SAI as SAI Impl\n"
"    participant NP as NotificationProcessor\n"
"    participant SD as Syncd\n"
"    participant RNP as RedisNotificationProducer\n"
"    participant R as Redis\n"
"\n"
"    loop SAI实现事件处理线程\n"
"        SAI->>SAI: 通过ASIC SDK获取事件\n"
"        SAI->>SAI: 解析事件，并转换成SAI通知对象\n"
"        SAI->>NP: 将通知对象序列化，<br/>并发送给通知处理线程的队列中\n"
"    end\n"
"\n"
"    loop 通知处理线程消息循环\n"
"        NP->>NP: 从队列中获取通知\n"
"        NP->>SD: 获取Syncd锁\n"
"        critical 给Syncd加锁\n"
"            NP->>NP: 反序列化通知对象，并做一些处理\n"
"            NP->>RNP: 重新序列化通知对象，并请求发送\n"
"            RNP->>R: 将通知以NotificationProducer<br/>的形式写入ASIC_DB\n"
"        end\n"
"    end\n"
"```"

#: src/5-1-syncd-sai-workflow.md:572
msgid ""
"这里我们也来看一下具体的实现。为了更加深入的理解，我们还是借助开源的Mellanox"
"的SAI实现来进行分析。"
msgstr ""
"这里我们也来看一下具体的实现。为了更加深入的理解，我们还是借助开源的Mellanox"
"的SAI实现来进行分析。"

#: src/5-1-syncd-sai-workflow.md:574
msgid ""
"最开始，SAI的实现需要接受到ASIC的通知，这一步是通过ASIC的SDK来实现的，"
"Mellanox的SAI会创建一个事件处理线程（event_thread），然后使用`select`函数来获"
"取并处理ASIC发送过来的通知，核心代码如下："
msgstr ""
"最开始，SAI的实现需要接受到ASIC的通知，这一步是通过ASIC的SDK来实现的，"
"Mellanox的SAI会创建一个事件处理线程（event_thread），然后使用`select`函数来获"
"取并处理ASIC发送过来的通知，核心代码如下："

#: src/5-1-syncd-sai-workflow.md:576
msgid ""
"```cpp\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_switch.c\n"
"static void event_thread_func(void *context)\n"
"{\n"
"#define MAX_PACKET_SIZE MAX(g_resource_limits.port_mtu_max, "
"SX_HOST_EVENT_BUFFER_SIZE_MAX)\n"
"\n"
"    sx_status_t                         status;\n"
"    sx_api_handle_t                     api_handle;\n"
"    sx_user_channel_t                   port_channel, callback_channel;\n"
"    fd_set                              descr_set;\n"
"    int                                 ret_val;\n"
"    sai_object_id_t                     switch_id = "
"(sai_object_id_t)context;\n"
"    sai_port_oper_status_notification_t port_data;\n"
"    sai_fdb_event_notification_data_t  *fdb_events = NULL;\n"
"    sai_attribute_t                    *attr_list = NULL;\n"
"    ...\n"
"\n"
"    // Init SDK API\n"
"    if (SX_STATUS_SUCCESS != (status = sx_api_open(sai_log_cb, "
"&api_handle))) {\n"
"        if (g_notification_callbacks.on_switch_shutdown_request) {\n"
"            g_notification_callbacks.on_switch_shutdown_request(switch_id);\n"
"        }\n"
"        return;\n"
"    }\n"
"\n"
"    if (SX_STATUS_SUCCESS != (status = sx_api_host_ifc_open(api_handle, "
"&port_channel.channel.fd))) {\n"
"        goto out;\n"
"    }\n"
"    ...\n"
"\n"
"    // Register for port and channel notifications\n"
"    port_channel.type = SX_USER_CHANNEL_TYPE_FD;\n"
"    if (SX_STATUS_SUCCESS != (status = "
"sx_api_host_ifc_trap_id_register_set(api_handle, SX_ACCESS_CMD_REGISTER, "
"DEFAULT_ETH_SWID, SX_TRAP_ID_PUDE, &port_channel))) {\n"
"        goto out;\n"
"    }\n"
"    ...\n"
"    for (uint32_t ii = 0; ii < (sizeof(mlnx_trap_ids) / "
"sizeof(*mlnx_trap_ids)); ii++) {\n"
"        status = sx_api_host_ifc_trap_id_register_set(api_handle, "
"SX_ACCESS_CMD_REGISTER, DEFAULT_ETH_SWID, mlnx_trap_ids[ii], "
"&callback_channel);\n"
"    }\n"
"\n"
"    while (!event_thread_asked_to_stop) {\n"
"        FD_ZERO(&descr_set);\n"
"        FD_SET(port_channel.channel.fd.fd, &descr_set);\n"
"        FD_SET(callback_channel.channel.fd.fd, &descr_set);\n"
"        ...\n"
"\n"
"        ret_val = select(FD_SETSIZE, &descr_set, NULL, NULL, &timeout);\n"
"        if (ret_val > 0) {\n"
"            // Port state change event\n"
"            if (FD_ISSET(port_channel.channel.fd.fd, &descr_set)) {\n"
"                // Parse port state event here ...\n"
"                if (g_notification_callbacks.on_port_state_change) {\n"
"                    g_notification_callbacks.on_port_state_change(1, "
"&port_data);\n"
"                }\n"
"            }\n"
"\n"
"            if (FD_ISSET(callback_channel.channel.fd.fd, &descr_set)) {\n"
"                // Receive notification event.\n"
"                packet_size = MAX_PACKET_SIZE;\n"
"                if (SX_STATUS_SUCCESS != (status = "
"sx_lib_host_ifc_recv(&callback_channel.channel.fd, p_packet, &packet_size, "
"receive_info))) {\n"
"                    goto out;\n"
"                }\n"
"\n"
"                // BFD packet event\n"
"                if (SX_TRAP_ID_BFD_PACKET_EVENT == receive_info->trap_id) {\n"
"                    const struct bfd_packet_event *event = (const struct "
"bfd_packet_event*)p_packet;\n"
"                    // Parse and check event valid here ...\n"
"                    status = mlnx_switch_bfd_packet_handle(event);\n"
"                    continue;\n"
"                }\n"
"\n"
"                // Same way to handle BFD timeout event, Bulk counter ready "
"event. Emiited.\n"
"\n"
"                // FDB event and packet event handling\n"
"                if (receive_info->trap_id == SX_TRAP_ID_FDB_EVENT) {\n"
"                    trap_name = \"FDB event\";\n"
"                } else if (SAI_STATUS_SUCCESS != (status = "
"mlnx_translate_sdk_trap_to_sai(receive_info->trap_id, &trap_name, "
"&trap_oid))) {\n"
"                    continue;\n"
"                }\n"
"\n"
"                if (SX_TRAP_ID_FDB_EVENT == receive_info->trap_id) {\n"
"                    // Parse FDB events here ...\n"
"\n"
"                    if (g_notification_callbacks.on_fdb_event) {\n"
"                        g_notification_callbacks.on_fdb_event(event_count, "
"fdb_events);\n"
"                    }\n"
"\n"
"                    continue;\n"
"                }\n"
"\n"
"                // Packet event handling\n"
"                status = mlnx_get_hostif_packet_data(receive_info, "
"&attrs_num, callback_data);\n"
"                if (g_notification_callbacks.on_packet_event) {\n"
"                    g_notification_callbacks.on_packet_event(switch_id, "
"packet_size, p_packet, attrs_num, callback_data);\n"
"                }\n"
"            }\n"
"        }\n"
"    }\n"
"\n"
"out:\n"
"    ...\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: platform/mellanox/mlnx-sai/SAI-Implementation/mlnx_sai/src/"
"mlnx_sai_switch.c\n"
"static void event_thread_func(void *context)\n"
"{\n"
"#define MAX_PACKET_SIZE MAX(g_resource_limits.port_mtu_max, "
"SX_HOST_EVENT_BUFFER_SIZE_MAX)\n"
"\n"
"    sx_status_t                         status;\n"
"    sx_api_handle_t                     api_handle;\n"
"    sx_user_channel_t                   port_channel, callback_channel;\n"
"    fd_set                              descr_set;\n"
"    int                                 ret_val;\n"
"    sai_object_id_t                     switch_id = "
"(sai_object_id_t)context;\n"
"    sai_port_oper_status_notification_t port_data;\n"
"    sai_fdb_event_notification_data_t  *fdb_events = NULL;\n"
"    sai_attribute_t                    *attr_list = NULL;\n"
"    ...\n"
"\n"
"    // Init SDK API\n"
"    if (SX_STATUS_SUCCESS != (status = sx_api_open(sai_log_cb, "
"&api_handle))) {\n"
"        if (g_notification_callbacks.on_switch_shutdown_request) {\n"
"            g_notification_callbacks.on_switch_shutdown_request(switch_id);\n"
"        }\n"
"        return;\n"
"    }\n"
"\n"
"    if (SX_STATUS_SUCCESS != (status = sx_api_host_ifc_open(api_handle, "
"&port_channel.channel.fd))) {\n"
"        goto out;\n"
"    }\n"
"    ...\n"
"\n"
"    // Register for port and channel notifications\n"
"    port_channel.type = SX_USER_CHANNEL_TYPE_FD;\n"
"    if (SX_STATUS_SUCCESS != (status = "
"sx_api_host_ifc_trap_id_register_set(api_handle, SX_ACCESS_CMD_REGISTER, "
"DEFAULT_ETH_SWID, SX_TRAP_ID_PUDE, &port_channel))) {\n"
"        goto out;\n"
"    }\n"
"    ...\n"
"    for (uint32_t ii = 0; ii < (sizeof(mlnx_trap_ids) / "
"sizeof(*mlnx_trap_ids)); ii++) {\n"
"        status = sx_api_host_ifc_trap_id_register_set(api_handle, "
"SX_ACCESS_CMD_REGISTER, DEFAULT_ETH_SWID, mlnx_trap_ids[ii], "
"&callback_channel);\n"
"    }\n"
"\n"
"    while (!event_thread_asked_to_stop) {\n"
"        FD_ZERO(&descr_set);\n"
"        FD_SET(port_channel.channel.fd.fd, &descr_set);\n"
"        FD_SET(callback_channel.channel.fd.fd, &descr_set);\n"
"        ...\n"
"\n"
"        ret_val = select(FD_SETSIZE, &descr_set, NULL, NULL, &timeout);\n"
"        if (ret_val > 0) {\n"
"            // Port state change event\n"
"            if (FD_ISSET(port_channel.channel.fd.fd, &descr_set)) {\n"
"                // Parse port state event here ...\n"
"                if (g_notification_callbacks.on_port_state_change) {\n"
"                    g_notification_callbacks.on_port_state_change(1, "
"&port_data);\n"
"                }\n"
"            }\n"
"\n"
"            if (FD_ISSET(callback_channel.channel.fd.fd, &descr_set)) {\n"
"                // Receive notification event.\n"
"                packet_size = MAX_PACKET_SIZE;\n"
"                if (SX_STATUS_SUCCESS != (status = "
"sx_lib_host_ifc_recv(&callback_channel.channel.fd, p_packet, &packet_size, "
"receive_info))) {\n"
"                    goto out;\n"
"                }\n"
"\n"
"                // BFD packet event\n"
"                if (SX_TRAP_ID_BFD_PACKET_EVENT == receive_info->trap_id) {\n"
"                    const struct bfd_packet_event *event = (const struct "
"bfd_packet_event*)p_packet;\n"
"                    // Parse and check event valid here ...\n"
"                    status = mlnx_switch_bfd_packet_handle(event);\n"
"                    continue;\n"
"                }\n"
"\n"
"                // Same way to handle BFD timeout event, Bulk counter ready "
"event. Emiited.\n"
"\n"
"                // FDB event and packet event handling\n"
"                if (receive_info->trap_id == SX_TRAP_ID_FDB_EVENT) {\n"
"                    trap_name = \"FDB event\";\n"
"                } else if (SAI_STATUS_SUCCESS != (status = "
"mlnx_translate_sdk_trap_to_sai(receive_info->trap_id, &trap_name, "
"&trap_oid))) {\n"
"                    continue;\n"
"                }\n"
"\n"
"                if (SX_TRAP_ID_FDB_EVENT == receive_info->trap_id) {\n"
"                    // Parse FDB events here ...\n"
"\n"
"                    if (g_notification_callbacks.on_fdb_event) {\n"
"                        g_notification_callbacks.on_fdb_event(event_count, "
"fdb_events);\n"
"                    }\n"
"\n"
"                    continue;\n"
"                }\n"
"\n"
"                // Packet event handling\n"
"                status = mlnx_get_hostif_packet_data(receive_info, "
"&attrs_num, callback_data);\n"
"                if (g_notification_callbacks.on_packet_event) {\n"
"                    g_notification_callbacks.on_packet_event(switch_id, "
"packet_size, p_packet, attrs_num, callback_data);\n"
"                }\n"
"            }\n"
"        }\n"
"    }\n"
"\n"
"out:\n"
"    ...\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:680
msgid ""
"接下来，我们用FDB事件来举例，当ASIC收到FDB事件，就会被上面的事件处理循环获取"
"到，并调用`g_notification_callbacks.on_fdb_event`函数来处理。这个函数接下来就"
"会调用到`Syncd`初始化时设置好的`NotificationHandler::onFdbEvent`函数，这个函"
"数会将该事件序列化后，通过消息队列转发给通知处理线程来进行处理："
msgstr ""
"接下来，我们用FDB事件来举例，当ASIC收到FDB事件，就会被上面的事件处理循环获取"
"到，并调用`g_notification_callbacks.on_fdb_event`函数来处理。这个函数接下来就"
"会调用到`Syncd`初始化时设置好的`NotificationHandler::onFdbEvent`函数，这个函"
"数会将该事件序列化后，通过消息队列转发给通知处理线程来进行处理："

#: src/5-1-syncd-sai-workflow.md:682
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationHandler.cpp\n"
"void NotificationHandler::onFdbEvent(_In_ uint32_t count, _In_ const "
"sai_fdb_event_notification_data_t *data)\n"
"{\n"
"    std::string s = sai_serialize_fdb_event_ntf(count, data);\n"
"    enqueueNotification(SAI_SWITCH_NOTIFICATION_NAME_FDB_EVENT, s);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationHandler.cpp\n"
"void NotificationHandler::onFdbEvent(_In_ uint32_t count, _In_ const "
"sai_fdb_event_notification_data_t *data)\n"
"{\n"
"    std::string s = sai_serialize_fdb_event_ntf(count, data);\n"
"    enqueueNotification(SAI_SWITCH_NOTIFICATION_NAME_FDB_EVENT, s);\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:691
msgid ""
"而此时通知处理线程会被唤醒，从消息队列中取出该事件，然后通过`Syncd`获取到"
"`Syncd`的锁，再开始处理该通知："
msgstr ""
"而此时通知处理线程会被唤醒，从消息队列中取出该事件，然后通过`Syncd`获取到"
"`Syncd`的锁，再开始处理该通知："

#: src/5-1-syncd-sai-workflow.md:693
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::ntf_process_function()\n"
"{\n"
"    std::mutex ntf_mutex;\n"
"    std::unique_lock<std::mutex> ulock(ntf_mutex);\n"
"\n"
"    while (m_runThread) {\n"
"        // When notification arrives, it will signal this condition "
"variable.\n"
"        m_cv.wait(ulock);\n"
"\n"
"        // Process notifications in the queue.\n"
"        swss::KeyOpFieldsValuesTuple item;\n"
"        while (m_notificationQueue->tryDequeue(item)) {\n"
"            processNotification(item);\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"// Call from NotificationProcessor::processNotification\n"
"void Syncd::syncProcessNotification(_In_ const swss::KeyOpFieldsValuesTuple& "
"item)\n"
"{\n"
"    std::lock_guard<std::mutex> lock(m_mutex);\n"
"    m_processor->syncProcessNotification(item);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::ntf_process_function()\n"
"{\n"
"    std::mutex ntf_mutex;\n"
"    std::unique_lock<std::mutex> ulock(ntf_mutex);\n"
"\n"
"    while (m_runThread) {\n"
"        // When notification arrives, it will signal this condition "
"variable.\n"
"        m_cv.wait(ulock);\n"
"\n"
"        // Process notifications in the queue.\n"
"        swss::KeyOpFieldsValuesTuple item;\n"
"        while (m_notificationQueue->tryDequeue(item)) {\n"
"            processNotification(item);\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/Syncd.cpp\n"
"// Call from NotificationProcessor::processNotification\n"
"void Syncd::syncProcessNotification(_In_ const swss::KeyOpFieldsValuesTuple& "
"item)\n"
"{\n"
"    std::lock_guard<std::mutex> lock(m_mutex);\n"
"    m_processor->syncProcessNotification(item);\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:721
msgid ""
"接下来就是事件的分发和处理了，`syncProcessNotification`函数是一系列的`if-"
"else`语句，根据事件的类型，调用不同的处理函数来处理该事件："
msgstr ""
"接下来就是事件的分发和处理了，`syncProcessNotification`函数是一系列的`if-"
"else`语句，根据事件的类型，调用不同的处理函数来处理该事件："

#: src/5-1-syncd-sai-workflow.md:723
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::syncProcessNotification( _In_ const swss::"
"KeyOpFieldsValuesTuple& item)\n"
"{\n"
"    std::string notification = kfvKey(item);\n"
"    std::string data = kfvOp(item);\n"
"\n"
"    if (notification == SAI_SWITCH_NOTIFICATION_NAME_SWITCH_STATE_CHANGE) {\n"
"        handle_switch_state_change(data);\n"
"    } else if (notification == SAI_SWITCH_NOTIFICATION_NAME_FDB_EVENT) {\n"
"        handle_fdb_event(data);\n"
"    } else if ...\n"
"    } else {\n"
"        SWSS_LOG_ERROR(\"unknown notification: %s\", notification.c_str());\n"
"    }\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::syncProcessNotification( _In_ const swss::"
"KeyOpFieldsValuesTuple& item)\n"
"{\n"
"    std::string notification = kfvKey(item);\n"
"    std::string data = kfvOp(item);\n"
"\n"
"    if (notification == SAI_SWITCH_NOTIFICATION_NAME_SWITCH_STATE_CHANGE) {\n"
"        handle_switch_state_change(data);\n"
"    } else if (notification == SAI_SWITCH_NOTIFICATION_NAME_FDB_EVENT) {\n"
"        handle_fdb_event(data);\n"
"    } else if ...\n"
"    } else {\n"
"        SWSS_LOG_ERROR(\"unknown notification: %s\", notification.c_str());\n"
"    }\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:741
msgid ""
"而每个事件处理函数都类似，他们会对发送过来的事件进行反序列化，然后调用真正的"
"处理逻辑发送通知，比如，fdb事件对应的`handle_fdb_event`函数和"
"`process_on_fdb_event`："
msgstr ""
"而每个事件处理函数都类似，他们会对发送过来的事件进行反序列化，然后调用真正的"
"处理逻辑发送通知，比如，fdb事件对应的`handle_fdb_event`函数和"
"`process_on_fdb_event`："

#: src/5-1-syncd-sai-workflow.md:743
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::handle_fdb_event(_In_ const std::string &data)\n"
"{\n"
"    uint32_t count;\n"
"    sai_fdb_event_notification_data_t *fdbevent = NULL;\n"
"    sai_deserialize_fdb_event_ntf(data, count, &fdbevent);\n"
"\n"
"    process_on_fdb_event(count, fdbevent);\n"
"\n"
"    sai_deserialize_free_fdb_event_ntf(count, fdbevent);\n"
"}\n"
"\n"
"void NotificationProcessor::process_on_fdb_event( _In_ uint32_t count, _In_ "
"sai_fdb_event_notification_data_t *data)\n"
"{\n"
"    for (uint32_t i = 0; i < count; i++) {\n"
"        sai_fdb_event_notification_data_t *fdb = &data[i];\n"
"        // Check FDB event notification data here\n"
"\n"
"        fdb->fdb_entry.switch_id = m_translator->translateRidToVid(fdb-"
">fdb_entry.switch_id, SAI_NULL_OBJECT_ID);\n"
"        fdb->fdb_entry.bv_id = m_translator->translateRidToVid(fdb-"
">fdb_entry.bv_id, fdb->fdb_entry.switch_id, true);\n"
"        m_translator->translateRidToVid(SAI_OBJECT_TYPE_FDB_ENTRY, fdb-"
">fdb_entry.switch_id, fdb->attr_count, fdb->attr, true);\n"
"\n"
"        ...\n"
"    }\n"
"\n"
"    // Send notification\n"
"    std::string s = sai_serialize_fdb_event_ntf(count, data);\n"
"    sendNotification(SAI_SWITCH_NOTIFICATION_NAME_FDB_EVENT, s);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::handle_fdb_event(_In_ const std::string &data)\n"
"{\n"
"    uint32_t count;\n"
"    sai_fdb_event_notification_data_t *fdbevent = NULL;\n"
"    sai_deserialize_fdb_event_ntf(data, count, &fdbevent);\n"
"\n"
"    process_on_fdb_event(count, fdbevent);\n"
"\n"
"    sai_deserialize_free_fdb_event_ntf(count, fdbevent);\n"
"}\n"
"\n"
"void NotificationProcessor::process_on_fdb_event( _In_ uint32_t count, _In_ "
"sai_fdb_event_notification_data_t *data)\n"
"{\n"
"    for (uint32_t i = 0; i < count; i++) {\n"
"        sai_fdb_event_notification_data_t *fdb = &data[i];\n"
"        // Check FDB event notification data here\n"
"\n"
"        fdb->fdb_entry.switch_id = m_translator->translateRidToVid(fdb-"
">fdb_entry.switch_id, SAI_NULL_OBJECT_ID);\n"
"        fdb->fdb_entry.bv_id = m_translator->translateRidToVid(fdb-"
">fdb_entry.bv_id, fdb->fdb_entry.switch_id, true);\n"
"        m_translator->translateRidToVid(SAI_OBJECT_TYPE_FDB_ENTRY, fdb-"
">fdb_entry.switch_id, fdb->attr_count, fdb->attr, true);\n"
"\n"
"        ...\n"
"    }\n"
"\n"
"    // Send notification\n"
"    std::string s = sai_serialize_fdb_event_ntf(count, data);\n"
"    sendNotification(SAI_SWITCH_NOTIFICATION_NAME_FDB_EVENT, s);\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:775
msgid ""
"具体发送事件的逻辑就非常直接了，最终就是通过[NotificationProducer](./4-2-2-"
"redis-messaging-layer.html#notificationproducer--notificationconsumer)来发送"
"通知到ASIC_DB中："
msgstr ""
"具体发送事件的逻辑就非常直接了，最终就是通过[NotificationProducer](./4-2-2-"
"redis-messaging-layer.html#notificationproducer--notificationconsumer)来发送"
"通知到ASIC_DB中："

#: src/5-1-syncd-sai-workflow.md:777
msgid ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::sendNotification(_In_ const std::string& op, "
"_In_ const std::string& data)\n"
"{\n"
"    std::vector<swss::FieldValueTuple> entry;\n"
"    sendNotification(op, data, entry);\n"
"}\n"
"\n"
"void NotificationProcessor::sendNotification(_In_ const std::string& op, "
"_In_ const std::string& data, _In_ std::vector<swss::FieldValueTuple> "
"entry)\n"
"{\n"
"    m_notifications->send(op, data, entry);\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/RedisNotificationProducer.cpp\n"
"void RedisNotificationProducer::send(_In_ const std::string& op, _In_ const "
"std::string& data, _In_ const std::vector<swss::FieldValueTuple>& values)\n"
"{\n"
"    std::vector<swss::FieldValueTuple> vals = values;\n"
"\n"
"    // The m_notificationProducer is created in the ctor of "
"RedisNotificationProducer as below:\n"
"    // m_notificationProducer = std::make_shared<swss::"
"NotificationProducer>(m_db.get(), "
"REDIS_TABLE_NOTIFICATIONS_PER_DB(dbName));\n"
"    m_notificationProducer->send(op, data, vals);\n"
"}\n"
"```"
msgstr ""
"```cpp\n"
"// File: src/sonic-sairedis/syncd/NotificationProcessor.cpp\n"
"void NotificationProcessor::sendNotification(_In_ const std::string& op, "
"_In_ const std::string& data)\n"
"{\n"
"    std::vector<swss::FieldValueTuple> entry;\n"
"    sendNotification(op, data, entry);\n"
"}\n"
"\n"
"void NotificationProcessor::sendNotification(_In_ const std::string& op, "
"_In_ const std::string& data, _In_ std::vector<swss::FieldValueTuple> "
"entry)\n"
"{\n"
"    m_notifications->send(op, data, entry);\n"
"}\n"
"\n"
"// File: src/sonic-sairedis/syncd/RedisNotificationProducer.cpp\n"
"void RedisNotificationProducer::send(_In_ const std::string& op, _In_ const "
"std::string& data, _In_ const std::vector<swss::FieldValueTuple>& values)\n"
"{\n"
"    std::vector<swss::FieldValueTuple> vals = values;\n"
"\n"
"    // The m_notificationProducer is created in the ctor of "
"RedisNotificationProducer as below:\n"
"    // m_notificationProducer = std::make_shared<swss::"
"NotificationProducer>(m_db.get(), "
"REDIS_TABLE_NOTIFICATIONS_PER_DB(dbName));\n"
"    m_notificationProducer->send(op, data, vals);\n"
"}\n"
"```"

#: src/5-1-syncd-sai-workflow.md:801
msgid "到此，`Syncd`中的通知上报的流程就结束了。"
msgstr "到此，`Syncd`中的通知上报的流程就结束了。"

#: src/5-1-syncd-sai-workflow.md:805
msgid ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-sairedis][SONiCSAIRedis]\n"
"3. [Github repo: Nvidia (Mellanox) SAI implementation][MnlxSAI]"
msgstr ""
"1. [SONiC Architecture][SONiCArch]\n"
"2. [Github repo: sonic-sairedis][SONiCSAIRedis]\n"
"3. [Github repo: Nvidia (Mellanox) SAI implementation][MnlxSAI]"

#: src/5-2-bgp-workflow.md:1
msgid "# BGP工作流"
msgstr "# BGP工作流"

#: src/5-2-bgp-workflow.md:3
msgid "## BGP创建和更新"
msgstr "## BGP创建和更新"

#: src/5-2-bgp-workflow.md:5
msgid "## BGP删除"
msgstr "## BGP删除"

#: src/6-boot.md:1
msgid "# 启动流程"
msgstr "# 启动流程"

#: src/6-1-normal-boot.md:1
msgid "# 正常启动"
msgstr "# 正常启动"

#: src/6-2-fast-boot.md:1
msgid "# 快速启动"
msgstr "# 快速启动"

#: src/6-3-warm-boot.md:1
msgid "# 热启动"
msgstr "# 热启动"
